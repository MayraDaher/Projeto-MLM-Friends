{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jhQCTd_r27gF"
      },
      "source": [
        "# Projeto Final de SBC\n",
        "\n",
        "> Este notebook está organizado em seções navegáveis.\n",
        "\n",
        "Implementação e treinamento de um Transformer e Modelo Oculto de Markov para \"dada uma frase, complete onde há a máscara com base em algo que um dos personagens da série de TV Friends responderia\".\n",
        "\n",
        "**Grupo** Mayra Daher e Samantha Medeiros.\n",
        "\n",
        "## Sobre os dados e a implementação\n",
        "A base de dados utilizada são as falas dos 6 personagens principais da série, cada um possuindo seu próprio arquivo `.txt` com todas as frases ditas por eles ao longo da série. A base de dados completa pode ser acessada no seguinte **[Dataset Kaggle](https://www.kaggle.com/datasets/blessondensil294/friends-tv-series-screenplay-script)**.\n",
        "\n",
        "## Como executar este notebook?\n",
        "1. Baixe as dependências;\n",
        "2. Execute cada uma das células de código;\n",
        "3. E execute o bloco de código da seção \"Main\".\n",
        "\n",
        "## Importante se atentar\n",
        "- Se estiver utilizando o ambiente Google Colab, certifique-se de executar a célular correspondente;\n",
        "- Verifique se o caminho dos arquivos;\n",
        "- Certique-se de que todos os arquivos necessários para a execução deste notebook estejam presentes.\n",
        "\n",
        "## Referências\n",
        "1. [Jonathan Hui. Speech Recognition - GMM, HMMM](https://jonathan-hui.medium.com/speech-recognition-gmm-hmm-8bb5eff8b196)\n",
        "2. [Ankur Singh. End-to-end Masked Language Modeling with BERT](https://keras.io/examples/nlp/masked_language_modeling/#create)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iU0K_z8f27gI"
      },
      "source": [
        "# **Implementação BERT** (parte 1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yODY8IM9x3NO"
      },
      "source": [
        "## BERT model (Pretraining Model)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LBT27vWq27gJ"
      },
      "source": [
        "### Dependências"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fGsJGkg76WMa"
      },
      "outputs": [],
      "source": [
        "#setup de ambiente\n",
        "!pip install -q keras-nlp tensorflow tensorflow-hub\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.layers import TextVectorization\n",
        "import keras_nlp\n",
        "from google.colab import files\n",
        "import numpy as np\n",
        "import os\n",
        "import re\n",
        "\n",
        "\n",
        "os.makedirs(\"checkpoints\", exist_ok=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ATTs6Fn-27gL"
      },
      "source": [
        "### Carregando Base de Dados"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "6B1Fjljx9k36",
        "outputId": "6bce67f6-1ef0-4308-cb03-46fe8d66feb5"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-a30575ef-d726-4f62-bd15-6b81c29f2ccf\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-a30575ef-d726-4f62-bd15-6b81c29f2ccf\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saving S01E01 Monica Gets A Roommate.txt to S01E01 Monica Gets A Roommate.txt\n",
            "Saving S01E02 The Sonogram At The End.txt to S01E02 The Sonogram At The End.txt\n",
            "Saving S01E03 The Thumb.txt to S01E03 The Thumb.txt\n",
            "Saving S01E04 George Stephanopoulos.txt to S01E04 George Stephanopoulos.txt\n",
            "Saving S01E05 The East German Laundry Detergent.txt to S01E05 The East German Laundry Detergent.txt\n",
            "Saving S01E06 The Butt.txt to S01E06 The Butt.txt\n",
            "Saving S01E07 The Blackout.txt to S01E07 The Blackout.txt\n",
            "Saving S01E08 Nana Dies Twice.txt to S01E08 Nana Dies Twice.txt\n",
            "Saving S01E09 Underdog Gets Away.txt to S01E09 Underdog Gets Away.txt\n",
            "Saving S01E10 The Monkey.txt to S01E10 The Monkey.txt\n",
            "Saving S01E11 Mrs. Bing.txt to S01E11 Mrs. Bing.txt\n",
            "Saving S01E12 The Dozen Lasagnas.txt to S01E12 The Dozen Lasagnas.txt\n",
            "Saving S01E13 The Boobies.txt to S01E13 The Boobies.txt\n",
            "Saving S01E14 The Candy Hearts.txt to S01E14 The Candy Hearts.txt\n",
            "Saving S01E15 The Stoned Guy.txt to S01E15 The Stoned Guy.txt\n",
            "Saving S01E16 The Two Parts Part I.txt to S01E16 The Two Parts Part I.txt\n",
            "Saving S01E17 The Two Parts Part II.txt to S01E17 The Two Parts Part II.txt\n",
            "Saving S01E18 All The Poker.txt to S01E18 All The Poker.txt\n",
            "Saving S01E19 The Monkey Gets Away.txt to S01E19 The Monkey Gets Away.txt\n",
            "Saving S01E20 The Evil Orthodontist.txt to S01E20 The Evil Orthodontist.txt\n",
            "Saving S01E21 The Fake Monica.txt to S01E21 The Fake Monica.txt\n",
            "Saving S01E22 The Ick Factor.txt to S01E22 The Ick Factor.txt\n",
            "Saving S01E23 The Birth.txt to S01E23 The Birth.txt\n",
            "Saving S01E24 Rachel Finds Out.txt to S01E24 Rachel Finds Out.txt\n",
            "Saving S02E01 Rosss New Girlfriend.txt to S02E01 Rosss New Girlfriend.txt\n",
            "Saving S02E02 The Breast Milk.txt to S02E02 The Breast Milk.txt\n",
            "Saving S02E03 Heckles Dies.txt to S02E03 Heckles Dies.txt\n",
            "Saving S02E04 Phoebes Husband.txt to S02E04 Phoebes Husband.txt\n",
            "Saving S02E05 Five Steaks And An Eggplant.txt to S02E05 Five Steaks And An Eggplant.txt\n",
            "Saving S02E06 The Baby On The Bus.txt to S02E06 The Baby On The Bus.txt\n",
            "Saving S02E07 Ross Finds Out.txt to S02E07 Ross Finds Out.txt\n",
            "Saving S02E08 The List.txt to S02E08 The List.txt\n",
            "Saving S02E09 Phoebes Dad.txt to S02E09 Phoebes Dad.txt\n",
            "Saving S02E10 Russ.txt to S02E10 Russ.txt\n",
            "Saving S02E11 The Lesbian Wedding.txt to S02E11 The Lesbian Wedding.txt\n",
            "Saving S02E12-S02E13 The Superbowl.txt to S02E12-S02E13 The Superbowl.txt\n",
            "Saving S02E14 The Prom Video.txt to S02E14 The Prom Video.txt\n",
            "Saving S02E15 Ross And Rachel... You Know.txt to S02E15 Ross And Rachel... You Know.txt\n",
            "Saving S02E16 Joey Moves Out.txt to S02E16 Joey Moves Out.txt\n",
            "Saving S02E17 Eddie Moves In.txt to S02E17 Eddie Moves In.txt\n",
            "Saving S02E18 Dr. Ramoray Dies.txt to S02E18 Dr. Ramoray Dies.txt\n",
            "Saving S02E19 Eddie Wont Go.txt to S02E19 Eddie Wont Go.txt\n",
            "Saving S02E20 Old Yeller Dies.txt to S02E20 Old Yeller Dies.txt\n",
            "Saving S02E21 The Bullies.txt to S02E21 The Bullies.txt\n",
            "Saving S02E22 The Two Parties.txt to S02E22 The Two Parties.txt\n",
            "Saving S02E23 The Chicken Pox.txt to S02E23 The Chicken Pox.txt\n",
            "Saving S02E24 Barry And Mindys Wedding.txt to S02E24 Barry And Mindys Wedding.txt\n",
            "Saving S03E01 The Princess Leia Fantasy.txt to S03E01 The Princess Leia Fantasy.txt\n",
            "Saving S03E02 No Ones Ready.txt to S03E02 No Ones Ready.txt\n",
            "Saving S03E03 The Jam.txt to S03E03 The Jam.txt\n",
            "Saving S03E04 The Metaphorical Tunnel.txt to S03E04 The Metaphorical Tunnel.txt\n",
            "Saving S03E05 Frank Jr..txt to S03E05 Frank Jr..txt\n",
            "Saving S03E06 The Flashback.txt to S03E06 The Flashback.txt\n",
            "Saving S03E07 The Race Car Bed.txt to S03E07 The Race Car Bed.txt\n",
            "Saving S03E08 The Giant Poking Device.txt to S03E08 The Giant Poking Device.txt\n",
            "Saving S03E09 The Football.txt to S03E09 The Football.txt\n",
            "Saving S03E10 Rachel Quits.txt to S03E10 Rachel Quits.txt\n",
            "Saving S03E11 Chandler Cant Remember Which Sister.txt to S03E11 Chandler Cant Remember Which Sister.txt\n",
            "Saving S03E12 All The Jealousy.txt to S03E12 All The Jealousy.txt\n",
            "Saving S03E13 Monica And Richard Are Just Friends.txt to S03E13 Monica And Richard Are Just Friends.txt\n",
            "Saving S03E14 Phoebes Ex-Partner.txt to S03E14 Phoebes Ex-Partner.txt\n",
            "Saving S03E15 Ross And Rachel Take A Break.txt to S03E15 Ross And Rachel Take A Break.txt\n",
            "Saving S03E16 The Morning After.txt to S03E16 The Morning After.txt\n",
            "Saving S03E17 The Ski Trip.txt to S03E17 The Ski Trip.txt\n",
            "Saving S03E18 The Hypnosis Tape.txt to S03E18 The Hypnosis Tape.txt\n",
            "Saving S03E19 The Tiny T-Shirt.txt to S03E19 The Tiny T-Shirt.txt\n",
            "Saving S03E20 The Dollhouse.txt to S03E20 The Dollhouse.txt\n",
            "Saving S03E21 The Chick And The Duck.txt to S03E21 The Chick And The Duck.txt\n",
            "Saving S03E22 The Screamer.txt to S03E22 The Screamer.txt\n",
            "Saving S03E23 Rosss Thing.txt to S03E23 Rosss Thing.txt\n",
            "Saving S03E24 The Ultimate Fighting Champion.txt to S03E24 The Ultimate Fighting Champion.txt\n",
            "Saving s03E25 At The Beach.txt to s03E25 At The Beach.txt\n",
            "Saving S04E01 The Jellyfish.txt to S04E01 The Jellyfish.txt\n",
            "Saving S04E02 The Cat.txt to S04E02 The Cat.txt\n",
            "Saving S04E03 The Cuffs.txt to S04E03 The Cuffs.txt\n",
            "Saving S04E04 The Ballroom Dancing.txt to S04E04 The Ballroom Dancing.txt\n",
            "Saving S04E05 Joeys New Girlfriend.txt to S04E05 Joeys New Girlfriend.txt\n",
            "Saving S04E06 The Dirty Girl.txt to S04E06 The Dirty Girl.txt\n",
            "Saving S04E07 Chandler Crosses The Line.txt to S04E07 Chandler Crosses The Line.txt\n",
            "Saving S04E08 Chandler In A Box.txt to S04E08 Chandler In A Box.txt\n",
            "Saving S04E09 Theyre Going To Party.txt to S04E09 Theyre Going To Party.txt\n",
            "Saving S04E10 The Girl From Poughkeepsie.txt to S04E10 The Girl From Poughkeepsie.txt\n",
            "Saving S04E11 Phoebes Uterus.txt to S04E11 Phoebes Uterus.txt\n",
            "Saving S04E12 The Embryos.txt to S04E12 The Embryos.txt\n",
            "Saving S04E13 Rachels Crush.txt to S04E13 Rachels Crush.txt\n",
            "Saving S04E14 Joeys Dirty Day.txt to S04E14 Joeys Dirty Day.txt\n",
            "Saving S04E15 All The Rugby.txt to S04E15 All The Rugby.txt\n",
            "Saving S04E16 The Fake Party.txt to S04E16 The Fake Party.txt\n",
            "Saving S04E17 The Free Porn.txt to S04E17 The Free Porn.txt\n",
            "Saving S04E18 Rachels New Dress.txt to S04E18 Rachels New Dress.txt\n",
            "Saving S04E19 All The Haste.txt to S04E19 All The Haste.txt\n",
            "Saving S04E20 The Wedding Dresses.txt to S04E20 The Wedding Dresses.txt\n",
            "Saving S04E21 The Invitation.txt to S04E21 The Invitation.txt\n",
            "Saving S04E22 The Worst Best Man Ever.txt to S04E22 The Worst Best Man Ever.txt\n",
            "Saving S04E23 Rosss Wedding.txt to S04E23 Rosss Wedding.txt\n",
            "Saving S05E01 Ross Says Rachel.txt to S05E01 Ross Says Rachel.txt\n",
            "Saving S05E02 All The Kissing.txt to S05E02 All The Kissing.txt\n",
            "Saving S05E03 Hundredth.txt to S05E03 Hundredth.txt\n",
            "Saving S05E04 Phoebe Hates PBS.txt to S05E04 Phoebe Hates PBS.txt\n",
            "Saving S05E05 The Kips.txt to S05E05 The Kips.txt\n",
            "Saving S05E06 The Yeti.txt to S05E06 The Yeti.txt\n",
            "Saving S05E07 Ross Moves In.txt to S05E07 Ross Moves In.txt\n",
            "Saving S05E08 The Thanksgiving Flashbacks.txt to S05E08 The Thanksgiving Flashbacks.txt\n",
            "Saving S05E09 Rosss Sandwich.txt to S05E09 Rosss Sandwich.txt\n",
            "Saving S05E10 The Inappropriate Sister.txt to S05E10 The Inappropriate Sister.txt\n",
            "Saving S05E11 All The Resolutions.txt to S05E11 All The Resolutions.txt\n",
            "Saving S05E12 Chandlers Work Laugh.txt to S05E12 Chandlers Work Laugh.txt\n",
            "Saving S05E13 Joeys Bag.txt to S05E13 Joeys Bag.txt\n",
            "Saving S05E14 Everybody Finds Out.txt to S05E14 Everybody Finds Out.txt\n",
            "Saving S05E15 The Girl Who Hits Joey.txt to S05E15 The Girl Who Hits Joey.txt\n",
            "Saving S05E16 The Cop.txt to S05E16 The Cop.txt\n",
            "Saving S05E17 Rachels Inadvertant Kiss.txt to S05E17 Rachels Inadvertant Kiss.txt\n",
            "Saving S05E18 Rachel Smokes.txt to S05E18 Rachel Smokes.txt\n",
            "Saving S05E19 Ross Cant Flirt.txt to S05E19 Ross Cant Flirt.txt\n",
            "Saving S05E20 The Ride Along.txt to S05E20 The Ride Along.txt\n",
            "Saving S05E21 The Ball.txt to S05E21 The Ball.txt\n",
            "Saving S05E22 Joeys Big Break.txt to S05E22 Joeys Big Break.txt\n",
            "Saving S05E23 In Vegas.txt to S05E23 In Vegas.txt\n",
            "Saving S06E01 Vegas.txt to S06E01 Vegas.txt\n",
            "Saving S06E02 Ross Hugs Rachel.txt to S06E02 Ross Hugs Rachel.txt\n",
            "Saving S06E03 Rosss Denial.txt to S06E03 Rosss Denial.txt\n",
            "Saving S06E04 Joey Loses His Insurance.txt to S06E04 Joey Loses His Insurance.txt\n",
            "Saving S06E05 Joeys Porsche.txt to S06E05 Joeys Porsche.txt\n",
            "Saving S06E06 On The Last Night.txt to S06E06 On The Last Night.txt\n",
            "Saving S06E07 Phoebe Runs.txt to S06E07 Phoebe Runs.txt\n",
            "Saving S06E08 Rosss Teeth.txt to S06E08 Rosss Teeth.txt\n",
            "Saving S06E09 Ross Got High.txt to S06E09 Ross Got High.txt\n",
            "Saving S06E10 The Routine.txt to S06E10 The Routine.txt\n",
            "Saving S06E11 The Apothecary Table.txt to S06E11 The Apothecary Table.txt\n",
            "Saving S06E12 The Joke.txt to S06E12 The Joke.txt\n",
            "Saving S06E13 Rachels Sister.txt to S06E13 Rachels Sister.txt\n",
            "Saving S06E14 Chandler Cant Cry.txt to S06E14 Chandler Cant Cry.txt\n",
            "Saving S06E15-S06E16 That Could Have Been Part I  II.txt to S06E15-S06E16 That Could Have Been Part I  II.txt\n",
            "Saving S06E17 Unagi.txt to S06E17 Unagi.txt\n",
            "Saving S06E18 Ross Dates A Student.txt to S06E18 Ross Dates A Student.txt\n",
            "Saving S06E19 Joeys Fridge.txt to S06E19 Joeys Fridge.txt\n",
            "Saving S06E20 Mac And C.H.E.E.S.E..txt to S06E20 Mac And C.H.E.E.S.E..txt\n",
            "Saving S06E21 Ross Meets Elizabeths Dad.txt to S06E21 Ross Meets Elizabeths Dad.txt\n",
            "Saving S06E22 Pauls The Man.txt to S06E22 Pauls The Man.txt\n",
            "Saving S06E23 The Ring.txt to S06E23 The Ring.txt\n",
            "Saving S06E24 The Proposal Part I  II.txt to S06E24 The Proposal Part I  II.txt\n",
            "Saving S07E01 Monicas Thunder.txt to S07E01 Monicas Thunder.txt\n",
            "Saving S07E02 Rachels Book.txt to S07E02 Rachels Book.txt\n",
            "Saving S07E03 Phoebes Cookies.txt to S07E03 Phoebes Cookies.txt\n",
            "Saving S07E04 Rachels Assistant.txt to S07E04 Rachels Assistant.txt\n",
            "Saving S07E05 The Engagement Picture.txt to S07E05 The Engagement Picture.txt\n",
            "Saving S07E06 The Nap Partners.txt to S07E06 The Nap Partners.txt\n",
            "Saving S07E07 Rosss Library Book.txt to S07E07 Rosss Library Book.txt\n",
            "Saving S07E08 Chandler Doesnt Like Dogs.txt to S07E08 Chandler Doesnt Like Dogs.txt\n",
            "Saving S07E09 All The Candy.txt to S07E09 All The Candy.txt\n",
            "Saving S07E10 The Huliday Armadillo.txt to S07E10 The Huliday Armadillo.txt\n",
            "Saving S07E11 All The Cheesecakes.txt to S07E11 All The Cheesecakes.txt\n",
            "Saving S07E12 Theyre Up All Night.txt to S07E12 Theyre Up All Night.txt\n",
            "Saving S07E13 Rosita Dies.txt to S07E13 Rosita Dies.txt\n",
            "Saving S07E14 They All Turn Thirty.txt to S07E14 They All Turn Thirty.txt\n",
            "Saving S07E15 Joeys New Brain.txt to S07E15 Joeys New Brain.txt\n",
            "Saving S07E16 The Truth About London.txt to S07E16 The Truth About London.txt\n",
            "Saving S07E17 The Cheap Wedding Dress.txt to S07E17 The Cheap Wedding Dress.txt\n",
            "Saving S07E18 Joeys Award.txt to S07E18 Joeys Award.txt\n",
            "Saving S07E19 Ross And Monicas Cousin.txt to S07E19 Ross And Monicas Cousin.txt\n",
            "Saving S07E20 Rachels Big Kiss.txt to S07E20 Rachels Big Kiss.txt\n",
            "Saving S07E21 The Vows.txt to S07E21 The Vows.txt\n",
            "Saving S07E22 Chandlers Dad.txt to S07E22 Chandlers Dad.txt\n",
            "Saving S07E23 Chandler And Monicas Wedding.txt to S07E23 Chandler And Monicas Wedding.txt\n",
            "Saving S07E24 Friends Special The Stuff Youve Never Seen.txt to S07E24 Friends Special The Stuff Youve Never Seen.txt\n",
            "Saving S08E01 I Do.txt to S08E01 I Do.txt\n",
            "Saving S08E02 The Red Sweater.txt to S08E02 The Red Sweater.txt\n",
            "Saving S08E03 Rachel Tells....txt to S08E03 Rachel Tells....txt\n",
            "Saving S08E04 The Videotape.txt to S08E04 The Videotape.txt\n",
            "Saving S08E05 Rachels Date.txt to S08E05 Rachels Date.txt\n",
            "Saving S08E06 The Halloween Party.txt to S08E06 The Halloween Party.txt\n",
            "Saving S08E07 The Stain.txt to S08E07 The Stain.txt\n",
            "Saving S08E08 The Stripper.txt to S08E08 The Stripper.txt\n",
            "Saving S08E09 The Rumor.txt to S08E09 The Rumor.txt\n",
            "Saving S08E10 Monicas Boots.txt to S08E10 Monicas Boots.txt\n",
            "Saving S08E11 Rosss Step Forward.txt to S08E11 Rosss Step Forward.txt\n",
            "Saving S08E12 Joey Dates Rachel.txt to S08E12 Joey Dates Rachel.txt\n",
            "Saving S08E13 Chandler Takes A Bath.txt to S08E13 Chandler Takes A Bath.txt\n",
            "Saving S08E14 The Secret Closet.txt to S08E14 The Secret Closet.txt\n",
            "Saving S08E15 The Birthing Video.txt to S08E15 The Birthing Video.txt\n",
            "Saving S08E16 Joey Tells Rachel.txt to S08E16 Joey Tells Rachel.txt\n",
            "Saving S08E17 The Tea Leaves.txt to S08E17 The Tea Leaves.txt\n",
            "Saving S08E18 In Massapequa.txt to S08E18 In Massapequa.txt\n",
            "Saving S08E19 Joeys Interview.txt to S08E19 Joeys Interview.txt\n",
            "Saving S08E20 The Baby Shower.txt to S08E20 The Baby Shower.txt\n",
            "Saving S08E21 The Cooking Class.txt to S08E21 The Cooking Class.txt\n",
            "Saving S08E22 Rachel Is Late.txt to S08E22 Rachel Is Late.txt\n",
            "Saving S08E23 Rachel Has A Baby.txt to S08E23 Rachel Has A Baby.txt\n",
            "Saving S09E01 No One Proposes.txt to S09E01 No One Proposes.txt\n",
            "Saving S09E02 Emma Cries.txt to S09E02 Emma Cries.txt\n",
            "Saving S09E03 The Pediatrician.txt to S09E03 The Pediatrician.txt\n",
            "Saving S09E04 The Sharks.txt to S09E04 The Sharks.txt\n",
            "Saving S09E05 Phoebes Birthday Dinner.txt to S09E05 Phoebes Birthday Dinner.txt\n",
            "Saving S09E06 The Male Nanny.txt to S09E06 The Male Nanny.txt\n",
            "Saving S09E07 Rosss Inappropriate Song.txt to S09E07 Rosss Inappropriate Song.txt\n",
            "Saving S09E08 Rachels Other Sister.txt to S09E08 Rachels Other Sister.txt\n",
            "Saving S09E09 Rachels Phone Number.txt to S09E09 Rachels Phone Number.txt\n",
            "Saving S09E10 Christmas In Tulsa.txt to S09E10 Christmas In Tulsa.txt\n",
            "Saving S09E11 Rachel Goes Back To Work.txt to S09E11 Rachel Goes Back To Work.txt\n",
            "Saving S09E12 Phoebes Rats.txt to S09E12 Phoebes Rats.txt\n",
            "Saving S09E13 Monica Sings.txt to S09E13 Monica Sings.txt\n",
            "Saving S09E14 The Blind Dates.txt to S09E14 The Blind Dates.txt\n",
            "Saving S09E15 The Mugging.txt to S09E15 The Mugging.txt\n",
            "Saving S09E16 The Boob Job.txt to S09E16 The Boob Job.txt\n",
            "Saving S09E17 The Memorial Service.txt to S09E17 The Memorial Service.txt\n",
            "Saving S09E18 The Lottery.txt to S09E18 The Lottery.txt\n",
            "Saving S09E19 Rachels Dream.txt to S09E19 Rachels Dream.txt\n",
            "Saving S09E20 The Soap Opera Party.txt to S09E20 The Soap Opera Party.txt\n",
            "Saving S09E21 The Fertility Test.txt to S09E21 The Fertility Test.txt\n",
            "Saving S09E22 The Donor.txt to S09E22 The Donor.txt\n",
            "Saving S09E23-S09E24 In Barbados.txt to S09E23-S09E24 In Barbados.txt\n",
            "Saving S10E01 Joey and Rachel Kiss.txt to S10E01 Joey and Rachel Kiss.txt\n",
            "Saving S10E02 Ross Is Fine.txt to S10E02 Ross Is Fine.txt\n",
            "Saving S10E03 Rosss Tan.txt to S10E03 Rosss Tan.txt\n",
            "Saving S10E04 The Cake.txt to S10E04 The Cake.txt\n",
            "Saving S10E05 Rachels Sister Babysits.txt to S10E05 Rachels Sister Babysits.txt\n",
            "Saving S10E06 Rosss Grant.txt to S10E06 Rosss Grant.txt\n",
            "Saving S10E07 The Home Study.txt to S10E07 The Home Study.txt\n",
            "Saving S10E08 The Late Thanksgiving.txt to S10E08 The Late Thanksgiving.txt\n",
            "Saving S10E09 The Birth Mother.txt to S10E09 The Birth Mother.txt\n",
            "Saving S10E10 Chandler Gets Caught.txt to S10E10 Chandler Gets Caught.txt\n",
            "Saving S10E11 The Stripper Cries.txt to S10E11 The Stripper Cries.txt\n",
            "Saving S10E12 Phoebes Wedding.txt to S10E12 Phoebes Wedding.txt\n",
            "Saving S10E13 Joey Speaks French.txt to S10E13 Joey Speaks French.txt\n",
            "Saving S10E14 Princess Consuela.txt to S10E14 Princess Consuela.txt\n",
            "Saving S10E15 Estelle Dies.txt to S10E15 Estelle Dies.txt\n",
            "Saving S10E16 Rachels Going Away Party.txt to S10E16 Rachels Going Away Party.txt\n",
            "Saving S10E17-S10E18 The Last One Part I  II.txt to S10E17-S10E18 The Last One Part I  II.txt\n"
          ]
        }
      ],
      "source": [
        "#uploado manual das legendas\n",
        "uploaded = files.upload()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e2Y-xT4s27gM"
      },
      "source": [
        "### Extração de Falas por Personagem"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NKXJ6UtM9tkX"
      },
      "outputs": [],
      "source": [
        "#Leitura e Extração das Falas dos Arquivos .txt\n",
        "\n",
        "import os\n",
        "import re\n",
        "\n",
        "#Resetar as variáveis\n",
        "personagens_principais = [\"phoebe\", \"chandler\", \"rachel\", \"monica\", \"ross\", \"joey\"]\n",
        "falas_por_personagem = {nome.upper(): [] for nome in personagens_principais}\n",
        "\n",
        "arquivos_legendas = sorted([f for f in os.listdir(\"/content\") if f.endswith(\".txt\")])\n",
        "\n",
        "for nome_arquivo in arquivos_legendas:\n",
        "    with open(nome_arquivo, \"r\", encoding=\"utf-8\") as f:\n",
        "        for linha in f:\n",
        "            linha = linha.strip()\n",
        "\n",
        "            for personagem in personagens_principais:\n",
        "                if linha.lower().startswith(personagem + \":\"):\n",
        "                    fala = linha.split(\":\", 1)[1].strip()\n",
        "                    fala = re.sub(r\"\\([^)]*\\)\", \"\", fala)  # remove parênteses\n",
        "                    fala = fala.lower()\n",
        "                    if fala:\n",
        "                        falas_por_personagem[personagem.upper()].append(fala)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QOpCvFT3CN6W",
        "outputId": "6118511c-3b00-452b-a133-f7a6ecac2241"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Personagens disponíveis em falas_por_personagem:\n",
            "dict_keys(['PHOEBE', 'CHANDLER', 'RACHEL', 'MONICA', 'ROSS', 'JOEY'])\n"
          ]
        }
      ],
      "source": [
        "print(\"Personagens disponíveis em falas_por_personagem:\")\n",
        "print(falas_por_personagem.keys())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_NqdWWA_B3NT",
        "outputId": "bb9bac38-f895-48cb-b59e-fb815e2c071b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "falas do RACHEL:\n",
            "- oh god monica hi! thank god! i just went to your building and you weren't there and then this guy with a big hammer said you might be here and you are, you are!\n",
            "- hi, sure!\n",
            "- oh god... well, it started about a half hour before the wedding. i was in the room where we were keeping all the presents, and i was looking at this gravy boat. this really gorgeous lamauge gravy boat. when all of a sudden- sweet 'n' lo?- i realized that i was more turned on by this gravy boat than by barry! and then i got really freaked out, and that's when it hit me: how much barry looks like mr. potato head. y'know, i mean, i always knew looked familiar, but... anyway, i just had to get out of there, and i started wondering 'why am i doing this, and who am i doing this for?'.  so anyway i just didn't know where to go, and i know that you and i have kinda drifted apart, but you're the only person i knew who lived here in the city.\n",
            "- ooh, i was kinda hoping that wouldn't be an issue... [scene: monica's apartment, everyone is there and watching a spanish soap on tv and are trying to figure out what is going on.]\n",
            "-  daddy, i just... i can't marry him! i'm sorry. i just don't love him. well, it matters to me!\n",
            "- c'mon daddy, listen to me! it's like, it's like, all of my life, everyone has always told me, 'you're a shoe! you're a shoe, you're a shoe, you're a shoe!'. and today i just stopped and i said, 'what if i don't wanna be a shoe? what if i wanna be a- a purse, y'know? or a- or a hat! no, i'm not saying i want you to buy me a hat, i'm saying i am a ha- it's a metaphor, daddy!\n",
            "- look daddy, it's my life. well maybe i'll just stay here with monica.\n",
            "- well, maybe that's my decision. well, maybe i don't need your money. wait!! wait, i said maybe!!\n",
            "- i'm all better now.\n",
            "- please, no, go, that'd be fine!\n"
          ]
        }
      ],
      "source": [
        "#Exibir algumas falas de Joey como exemplo\n",
        "print(\"falas do RACHEL:\")\n",
        "for fala in falas_por_personagem[\"RACHEL\"][:10]:\n",
        "    print(\"-\", fala)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q18DXmR527gO"
      },
      "source": [
        "### Análise Exploratória da Base de Dados"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 610
        },
        "id": "2T3zrN2nB4XH",
        "outputId": "905c7fe7-fa65-4516-a7ef-06960d4d9291"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Distribuição de falas por personagem:\n",
            "   PHOEBE: 7389 falas\n",
            " CHANDLER: 8381 falas\n",
            "   RACHEL: 9142 falas\n",
            "   MONICA: 8310 falas\n",
            "     ROSS: 9099 falas\n",
            "     JOEY: 8210 falas\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 1000x500 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "#Análise de Quantidade de Falas por Personagem\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "#listas\n",
        "nomes = list(falas_por_personagem.keys())\n",
        "quantidades = [len(falas_por_personagem[nome]) for nome in nomes]\n",
        "\n",
        "#Exibe em texto\n",
        "print(\"Distribuição de falas por personagem:\")\n",
        "for nome, qtd in zip(nomes, quantidades):\n",
        "    print(f\"{nome:>9}: {qtd} falas\")\n",
        "\n",
        "#gráfico\n",
        "plt.figure(figsize=(10, 5))\n",
        "plt.bar(nomes, quantidades, color='skyblue')\n",
        "plt.title(\"Quantidade de falas por personagem\")\n",
        "plt.xlabel(\"Personagem\")\n",
        "plt.ylabel(\"Número de falas\")\n",
        "plt.grid(axis=\"y\", linestyle=\"--\", alpha=0.5)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J1pJ2q6yD8WZ",
        "outputId": "f33e8290-35fc-47ea-a2db-7407bcc7bafa"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total de falas tagueadas: 50531\n",
            "Exemplo de falas com tags:\n",
            "- [PHOEBE] wait, does he eat chalk?\n",
            "- [PHOEBE] just, 'cause, i don't want her to go through what i went through with carl- oh!\n",
            "- [PHOEBE] no.\n",
            "- [PHOEBE] ooh! oh! \n",
            "- [PHOEBE] fine!  be murky!\n",
            "- [PHOEBE] if i let go of my hair, my head will fall off.\n"
          ]
        }
      ],
      "source": [
        "#Adicionar a tag [PERSONAGEM] no início de cada fala\n",
        "\n",
        "#lista única com a tag do personagem\n",
        "falas_tagged = []\n",
        "\n",
        "for personagem, falas in falas_por_personagem.items():\n",
        "    for fala in falas:\n",
        "        falas_tagged.append(f\"[{personagem}] {fala}\")\n",
        "\n",
        "print(f\"Total de falas tagueadas: {len(falas_tagged)}\")\n",
        "print(\"Exemplo de falas com tags:\")\n",
        "for fala in falas_tagged[:6]:\n",
        "    print(\"-\", fala)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0xX5MAAQEBVr",
        "outputId": "650ddbd9-341f-43f5-a9d7-9024fd8d89ce"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Todas as classes serão aumentadas para 18284 falas.\n",
            "Total de falas no dataset final: 109704\n",
            "Exemplos de falas balanceadas:\n",
            "- [CHANDLER]  wow! listen, we had a good run. what was it? four? five months? i mean, that's more than most people have in a lifetime! so, good-bye, take care, bye-bye then! \n",
            "- [CHANDLER] hey man, what's up?\n",
            "- [PHOEBE] oh can i? vegetarians never get to do the wishbone. it's really not fair either! you know, just because we don't eat the meat doesn't mean we don't like to play with the carcasses!\n",
            "- [JOEY] check it out, giants-cowboys. \n",
            "- [CHANDLER]  i don't, and i'm offended by the insinuation!\n",
            "- [MONICA] okay!\n"
          ]
        }
      ],
      "source": [
        "#NÃO EXECUTAR\n",
        "#Aplicando oversampling para equilibrar o número de falas\n",
        "\n",
        "from random import choices, shuffle\n",
        "\n",
        "#Tamanho da maior classe\n",
        "tamanho_maximo = max(len(falas) for falas in falas_por_personagem.values())\n",
        "print(f\"Todas as classes serão aumentadas para {tamanho_maximo} falas.\")\n",
        "\n",
        "#Lista final com as falas balanceadas\n",
        "falas_balanceadas = []\n",
        "\n",
        "#oversampling\n",
        "for personagem, falas in falas_por_personagem.items():\n",
        "    falas_expandida = choices(falas, k=tamanho_maximo)\n",
        "    falas_tagged = [f\"[{personagem}] {fala}\" for fala in falas_expandida]\n",
        "    falas_balanceadas.extend(falas_tagged)\n",
        "\n",
        "\n",
        "shuffle(falas_balanceadas)\n",
        "\n",
        "print(f\"Total de falas no dataset final: {len(falas_balanceadas)}\")\n",
        "print(\"Exemplos de falas balanceadas:\")\n",
        "for fala in falas_balanceadas[:6]:\n",
        "    print(\"-\", fala)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "YW1bFYvlGkxp",
        "outputId": "66203d26-0a8e-44d5-9533-6abec1b9e82e"
      },
      "outputs": [
        {
          "data": {
            "application/javascript": "\n    async function download(id, filename, size) {\n      if (!google.colab.kernel.accessAllowed) {\n        return;\n      }\n      const div = document.createElement('div');\n      const label = document.createElement('label');\n      label.textContent = `Downloading \"${filename}\": `;\n      div.appendChild(label);\n      const progress = document.createElement('progress');\n      progress.max = size;\n      div.appendChild(progress);\n      document.body.appendChild(div);\n\n      const buffers = [];\n      let downloaded = 0;\n\n      const channel = await google.colab.kernel.comms.open(id);\n      // Send a message to notify the kernel that we're ready.\n      channel.send({})\n\n      for await (const message of channel.messages) {\n        // Send a message to notify the kernel that we're ready.\n        channel.send({})\n        if (message.buffers) {\n          for (const buffer of message.buffers) {\n            buffers.push(buffer);\n            downloaded += buffer.byteLength;\n            progress.value = downloaded;\n          }\n        }\n      }\n      const blob = new Blob(buffers, {type: 'application/binary'});\n      const a = document.createElement('a');\n      a.href = window.URL.createObjectURL(blob);\n      a.download = filename;\n      div.appendChild(a);\n      a.click();\n      div.remove();\n    }\n  ",
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/javascript": "download(\"download_3ec9af81-b79c-497a-9b69-e8d37393ce98\", \"falas_balanceadas.txt\", 7041894)",
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "#NÃO EXECUTAR\n",
        "#Salvar o dataset balanceado (falas_balanceadas)\n",
        "with open(\"falas_balanceadas.txt\", \"w\", encoding=\"utf-8\") as f:\n",
        "    for linha in falas_balanceadas:\n",
        "        f.write(linha + \"\\n\")\n",
        "\n",
        "# Fazer o download do arquivo para o computador\n",
        "from google.colab import files\n",
        "files.download(\"falas_balanceadas.txt\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "UZV9-IJVXQHS",
        "outputId": "3539ec0e-74ed-4277-ac94-767dfee66db3"
      },
      "outputs": [
        {
          "data": {
            "application/javascript": "\n    async function download(id, filename, size) {\n      if (!google.colab.kernel.accessAllowed) {\n        return;\n      }\n      const div = document.createElement('div');\n      const label = document.createElement('label');\n      label.textContent = `Downloading \"${filename}\": `;\n      div.appendChild(label);\n      const progress = document.createElement('progress');\n      progress.max = size;\n      div.appendChild(progress);\n      document.body.appendChild(div);\n\n      const buffers = [];\n      let downloaded = 0;\n\n      const channel = await google.colab.kernel.comms.open(id);\n      // Send a message to notify the kernel that we're ready.\n      channel.send({})\n\n      for await (const message of channel.messages) {\n        // Send a message to notify the kernel that we're ready.\n        channel.send({})\n        if (message.buffers) {\n          for (const buffer of message.buffers) {\n            buffers.push(buffer);\n            downloaded += buffer.byteLength;\n            progress.value = downloaded;\n          }\n        }\n      }\n      const blob = new Blob(buffers, {type: 'application/binary'});\n      const a = document.createElement('a');\n      a.href = window.URL.createObjectURL(blob);\n      a.download = filename;\n      div.appendChild(a);\n      a.click();\n      div.remove();\n    }\n  ",
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/javascript": "download(\"download_145c0a4d-753f-43c9-bb0f-800ae08f7154\", \"falas_tagged.txt\", 3234287)",
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "#Salvar o dataset\n",
        "with open(\"falas_tagged.txt\", \"w\", encoding=\"utf-8\") as f:\n",
        "    for linha in falas_tagged:\n",
        "        f.write(linha + \"\\n\")\n",
        "\n",
        "#Fazer o download do arquivo para o computador\n",
        "from google.colab import files\n",
        "files.download(\"falas_tagged.txt\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wunoPlcB27gP"
      },
      "source": [
        "### TextVectorizer - Vetorização do texto em IDs de Tokens"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5XOEY6TtIa5D"
      },
      "source": [
        "Vamos usar TextVectorization layer para vetorizar o texto em tokens ids"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lSRQBoH4IYA1"
      },
      "outputs": [],
      "source": [
        "# criar a vectorize_layer incluindo o token especial [MASK]\n",
        "texts = falas_tagged\n",
        "\n",
        "# normalização\n",
        "def custom_standardization(input_string):\n",
        "    lowercase = tf.strings.lower(input_string)\n",
        "    clean_text = tf.strings.regex_replace(lowercase, r\"[^\\w\\s\\[\\]]\", \"\")  # mantém colchetes\n",
        "    return clean_text\n",
        "\n",
        "#criação da vectorize_layer\n",
        "def get_vectorize_layer(texts, vocab_size=30000, max_seq_length=128, special_tokens=[\"[MASK]\"]):\n",
        "    vectorize_layer = TextVectorization(\n",
        "        max_tokens=vocab_size,\n",
        "        output_mode=\"int\",\n",
        "        standardize=custom_standardization,\n",
        "        output_sequence_length=max_seq_length,\n",
        "    )\n",
        "    vectorize_layer.adapt(texts)\n",
        "\n",
        "    # Ajuste do vocabulário\n",
        "    vocab = vectorize_layer.get_vocabulary()\n",
        "    vocab = [tok for tok in vocab if tok not in [\"\", \"[UNK]\"] + special_tokens]\n",
        "    vocab = vocab[:vocab_size - len(special_tokens) - 2]\n",
        "    vocab_final = [\"\", \"[UNK]\"] + special_tokens + vocab\n",
        "    vectorize_layer.set_vocabulary(vocab_final)\n",
        "\n",
        "    # Envolve em um modelo Keras e salva\n",
        "    vectorize_model = keras.Sequential([vectorize_layer])\n",
        "    vectorize_model(tf.constant([\"exemplo de frase\"]))  # força a construção\n",
        "\n",
        "    path = \"vectorize_layer_model.keras\"\n",
        "    vectorize_model.save(path)\n",
        "    #files.download(path)\n",
        "\n",
        "    return vectorize_layer\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iZvgMJAkZB0C",
        "outputId": "2299f636-be22-4b34-f771-937686ec793b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ID do token [MASK]: 2\n"
          ]
        }
      ],
      "source": [
        "#criar a camada com os textos:\n",
        "vectorize_layer = get_vectorize_layer(falas_tagged)\n",
        "vocab = vectorize_layer.get_vocabulary()\n",
        "\n",
        "#Cria os dicionários\n",
        "id2token = dict(enumerate(vocab))\n",
        "token2id = {token: idx for idx, token in enumerate(vocab)}\n",
        "\n",
        "#Pega o ID do token [MASK]\n",
        "if \"[MASK]\" not in token2id:\n",
        "    raise ValueError(\"[MASK] token não está no vocabulário!\")\n",
        "\n",
        "mask_token_id = token2id[\"[MASK]\"]\n",
        "print(\"ID do token [MASK]:\", mask_token_id)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "fwWrDoEGOANY",
        "outputId": "bed03133-c5ea-4b16-8d1c-be2022f98c1c"
      },
      "outputs": [
        {
          "data": {
            "application/javascript": "\n    async function download(id, filename, size) {\n      if (!google.colab.kernel.accessAllowed) {\n        return;\n      }\n      const div = document.createElement('div');\n      const label = document.createElement('label');\n      label.textContent = `Downloading \"${filename}\": `;\n      div.appendChild(label);\n      const progress = document.createElement('progress');\n      progress.max = size;\n      div.appendChild(progress);\n      document.body.appendChild(div);\n\n      const buffers = [];\n      let downloaded = 0;\n\n      const channel = await google.colab.kernel.comms.open(id);\n      // Send a message to notify the kernel that we're ready.\n      channel.send({})\n\n      for await (const message of channel.messages) {\n        // Send a message to notify the kernel that we're ready.\n        channel.send({})\n        if (message.buffers) {\n          for (const buffer of message.buffers) {\n            buffers.push(buffer);\n            downloaded += buffer.byteLength;\n            progress.value = downloaded;\n          }\n        }\n      }\n      const blob = new Blob(buffers, {type: 'application/binary'});\n      const a = document.createElement('a');\n      a.href = window.URL.createObjectURL(blob);\n      a.download = filename;\n      div.appendChild(a);\n      a.click();\n      div.remove();\n    }\n  ",
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/javascript": "download(\"download_6bcd1588-64a6-441f-9bdb-c6df8de74a0e\", \"vectorize_layer_model.keras\", 276669)",
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Empacotar a camada em um modelo\n",
        "vectorize_model = keras.Sequential([vectorize_layer])\n",
        "\n",
        "# Executar uma previsão exemplo para construir o modelo\n",
        "vectorize_model(tf.constant([\"exemplo de texto\"]))\n",
        "\n",
        "# Salvar o modelo em disco\n",
        "vectorize_model.save(\"vectorize_layer_model.keras\")\n",
        "\n",
        "# Fazer o download para o computador\n",
        "files.download(\"vectorize_layer_model.keras\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SonLtIg5exmr"
      },
      "outputs": [],
      "source": [
        "#Aplica a vetorização nas falas\n",
        "def encode(texts, vectorize_layer):\n",
        "    encoded_texts = vectorize_layer(texts)\n",
        "    return encoded_texts.numpy()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mTiJKYDW27gR"
      },
      "source": [
        "### BERT-Style Masking"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V-Efd6IBg79T"
      },
      "outputs": [],
      "source": [
        "#Função para aplicar o BERT-style masking\n",
        "def get_masked_input_and_labels(encoded_texts, mask_token_id):\n",
        "    # 15% de probabilidade para máscara\n",
        "    inp_mask = np.random.rand(*encoded_texts.shape) < 0.15\n",
        "\n",
        "    # Não mascara tokens especiais (ID 0 = padding, 1 = OOV, 2 = MASK)\n",
        "    inp_mask[encoded_texts <= 2] = False\n",
        "\n",
        "    # Labels: -1 nos tokens que não serão previstos\n",
        "    labels = -1 * np.ones(encoded_texts.shape, dtype=int)\n",
        "    labels[inp_mask] = encoded_texts[inp_mask]\n",
        "\n",
        "    # Cópia da entrada original para aplicar modificações\n",
        "    encoded_texts_masked = np.copy(encoded_texts)\n",
        "\n",
        "    # 90% dos tokens selecionados viram [MASK]\n",
        "    inp_mask_2mask = inp_mask & (np.random.rand(*encoded_texts.shape) < 0.90)\n",
        "    encoded_texts_masked[inp_mask_2mask] = mask_token_id\n",
        "\n",
        "    # 10% viram tokens aleatórios\n",
        "    inp_mask_2random = inp_mask & (np.random.rand(*encoded_texts.shape) < 0.10)\n",
        "    encoded_texts_masked[inp_mask_2random] = np.random.randint(\n",
        "        3, len(vectorize_layer.get_vocabulary()), inp_mask_2random.sum()\n",
        "    )\n",
        "\n",
        "    # Pesos: só computa loss onde o label não é -1\n",
        "    sample_weights = np.ones(labels.shape, dtype=np.float32)\n",
        "    sample_weights[labels == -1] = 0\n",
        "\n",
        "    # y_labels would be same as encoded_texts i.e input tokens\n",
        "    y_labels = np.copy(encoded_texts)\n",
        "\n",
        "    return encoded_texts_masked, y_labels, sample_weights"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Nq7tea3qeITm"
      },
      "outputs": [],
      "source": [
        "#Codifica os textos\n",
        "x_all_encoded = encode(falas_tagged, vectorize_layer)\n",
        "\n",
        "#aplica o masking\n",
        "x_masked, y_labels, sample_weights = get_masked_input_and_labels(\n",
        "    x_all_encoded, mask_token_id\n",
        ")\n",
        "\n",
        "#Cria o dataset final\n",
        "mlm_ds = tf.data.Dataset.from_tensor_slices(\n",
        "    (x_masked, y_labels, sample_weights)\n",
        ").shuffle(1000).batch(32)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oL38RUBWjY8B",
        "outputId": "93f40c7d-262b-461b-9060-a1f99f7c2d5f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Entrada (com [MASK]): [  14    4   35    7    2 2401    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0]\n",
            "Rótulos corretos     : [  14    4   35    7  778 2401    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0]\n",
            "Pesos (sample_weights): [0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0.]\n"
          ]
        }
      ],
      "source": [
        "#Visualiza uma amostra do dataset\n",
        "for batch in mlm_ds.take(1):\n",
        "    input_ids, labels, weights = batch\n",
        "    print(\"Entrada (com [MASK]):\", input_ids[0].numpy())\n",
        "    print(\"Rótulos corretos     :\", labels[0].numpy())\n",
        "    print(\"Pesos (sample_weights):\", weights[0].numpy())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y_qkb_0Kjvtz"
      },
      "source": [
        "### Modelagem BERT"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DWgOaZFFjc4W"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "#Hiperparâmetros\n",
        "EMBED_DIM = 128\n",
        "NUM_HEAD = 4\n",
        "FF_DIM = 256\n",
        "NUM_LAYERS = 4\n",
        "VOCAB_SIZE = 30000\n",
        "MAX_LEN = 128\n",
        "LR = 1e-4\n",
        "\n",
        "#criar um bloco BERT\n",
        "def bert_module(query, key, value, i):\n",
        "    attention_output = layers.MultiHeadAttention(\n",
        "        num_heads=NUM_HEAD,\n",
        "        key_dim=EMBED_DIM // NUM_HEAD,\n",
        "        name=f\"encoder_{i}_multiheadattention\"\n",
        "    )(query, key, value)\n",
        "\n",
        "    attention_output = layers.Dropout(0.1, name=f\"encoder_{i}_att_dropout\")(attention_output)\n",
        "    attention_output = layers.LayerNormalization(epsilon=1e-4, name=f\"encoder_{i}_att_layernormalization\")(query + attention_output)\n",
        "\n",
        "    ffn = keras.Sequential([\n",
        "        layers.Dense(FF_DIM, activation=\"relu\"),\n",
        "        layers.Dense(EMBED_DIM)\n",
        "    ], name=f\"encoder_{i}_ffn\")\n",
        "\n",
        "    ffn_output = ffn(attention_output)\n",
        "    ffn_output = layers.Dropout(0.1, name=f\"encoder_{i}_ffn_dropout\")(ffn_output)\n",
        "    output = layers.LayerNormalization(epsilon=1e-4, name=f\"encoder_{i}_ffn_layernormalization\")(attention_output + ffn_output)\n",
        "\n",
        "    return output\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GDUiSEodkXMm"
      },
      "outputs": [],
      "source": [
        "#Função de perda e métrica\n",
        "loss_fn = keras.losses.SparseCategoricalCrossentropy(reduction=\"none\")\n",
        "loss_tracker = keras.metrics.Mean(name=\"loss\")\n",
        "\n",
        "#Modelo de linguagem mascarada\n",
        "class MaskedLanguageModel(keras.Model):\n",
        "    def compute_loss(self, x=None, y=None, y_pred=None, sample_weight=None):\n",
        "        loss = loss_fn(y, y_pred, sample_weight)\n",
        "        loss_tracker.update_state(loss, sample_weight=sample_weight)\n",
        "        return tf.reduce_sum(loss)\n",
        "\n",
        "    def compute_metrics(self, x, y, y_pred, sample_weight):\n",
        "        return {\"loss\": loss_tracker.result()}\n",
        "\n",
        "    @property\n",
        "    def metrics(self):\n",
        "        return [loss_tracker]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wIgzfkGEkn9D"
      },
      "outputs": [],
      "source": [
        "#Monta o Modelo BERT para MLM\n",
        "import keras_nlp\n",
        "\n",
        "def create_masked_language_bert_model():\n",
        "    inputs = layers.Input(shape=(MAX_LEN,), dtype=\"int64\", name=\"input_ids\")\n",
        "\n",
        "    # Word embeddings\n",
        "    word_embeddings = layers.Embedding(\n",
        "        input_dim=VOCAB_SIZE,\n",
        "        output_dim=EMBED_DIM,\n",
        "        name=\"word_embedding\"\n",
        "    )(inputs)\n",
        "\n",
        "    # Positional embeddings\n",
        "    position_embeddings = keras_nlp.layers.PositionEmbedding(\n",
        "        sequence_length=MAX_LEN,\n",
        "        name=\"position_embedding\"\n",
        "    )(word_embeddings)\n",
        "\n",
        "    # Soma dos embeddings\n",
        "    embeddings = word_embeddings + position_embeddings\n",
        "\n",
        "    # Encoder BERT\n",
        "    x = embeddings\n",
        "    for i in range(NUM_LAYERS):\n",
        "        x = bert_module(x, x, x, i)\n",
        "\n",
        "    # MLM head\n",
        "    outputs = layers.Dense(VOCAB_SIZE, activation=\"softmax\", name=\"mlm_cls\")(x)\n",
        "\n",
        "    # Modelo final\n",
        "    model = MaskedLanguageModel(inputs, outputs, name=\"friends_masked_bert_model\")\n",
        "    model.compile(optimizer=keras.optimizers.Adam(learning_rate=LR))\n",
        "\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6QaxgBFGk7OO"
      },
      "outputs": [],
      "source": [
        "#mlm_ds com os tensores\n",
        "mlm_ds = tf.data.Dataset.from_tensor_slices((x_masked, y_labels, sample_weights))\n",
        "mlm_ds = mlm_ds.shuffle(1000).batch(32)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "oo7BOOjglB0_",
        "outputId": "436d9455-d5da-4a55-feec-3edb465bc7a7"
      },
      "outputs": [
        {
          "data": {
            "application/javascript": "\n    async function download(id, filename, size) {\n      if (!google.colab.kernel.accessAllowed) {\n        return;\n      }\n      const div = document.createElement('div');\n      const label = document.createElement('label');\n      label.textContent = `Downloading \"${filename}\": `;\n      div.appendChild(label);\n      const progress = document.createElement('progress');\n      progress.max = size;\n      div.appendChild(progress);\n      document.body.appendChild(div);\n\n      const buffers = [];\n      let downloaded = 0;\n\n      const channel = await google.colab.kernel.comms.open(id);\n      // Send a message to notify the kernel that we're ready.\n      channel.send({})\n\n      for await (const message of channel.messages) {\n        // Send a message to notify the kernel that we're ready.\n        channel.send({})\n        if (message.buffers) {\n          for (const buffer of message.buffers) {\n            buffers.push(buffer);\n            downloaded += buffer.byteLength;\n            progress.value = downloaded;\n          }\n        }\n      }\n      const blob = new Blob(buffers, {type: 'application/binary'});\n      const a = document.createElement('a');\n      a.href = window.URL.createObjectURL(blob);\n      a.download = filename;\n      div.appendChild(a);\n      a.click();\n      div.remove();\n    }\n  ",
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/javascript": "download(\"download_7c2a5e2c-399e-47d5-82b9-7e9dd21c516e\", \"bert_mlm_friends.keras\", 33217814)",
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "#Cria o modelo e salva\n",
        "from google.colab import files\n",
        "\n",
        "\n",
        "mlm_model = create_masked_language_bert_model()\n",
        "mlm_model.save(\"bert_mlm_friends.keras\")\n",
        "\n",
        "#Faz download do arquivo\n",
        "files.download(\"bert_mlm_friends.keras\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ceyrbPJS27gS"
      },
      "source": [
        "### Treinamento do Modelo BERT"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 443
        },
        "id": "VVqm7yFLlFVO",
        "outputId": "750517a6-a576-407a-9adf-23fa3585ce84"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/saving/saving_lib.py:757: UserWarning: Skipping variable loading for optimizer 'adam', because it has 138 variables whereas the saved optimizer has 2 variables. \n",
            "  saveable.load_own_variables(weights_store.get(inner_path))\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m1580/1580\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 3.7310\n",
            "Epoch 1: loss improved from inf to 1.60996, saving model to checkpoints/bert_mlm_best.keras\n",
            "\u001b[1m1580/1580\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m67s\u001b[0m 23ms/step - loss: 3.7297\n",
            "Epoch 2/5\n",
            "\u001b[1m1575/1580\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.2968\n",
            "Epoch 2: loss improved from 1.60996 to 0.24415, saving model to checkpoints/bert_mlm_best.keras\n",
            "\u001b[1m1580/1580\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 12ms/step - loss: 0.2966\n",
            "Epoch 3/5\n",
            "\u001b[1m1576/1580\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.1813\n",
            "Epoch 3: loss improved from 0.24415 to 0.16393, saving model to checkpoints/bert_mlm_best.keras\n",
            "\u001b[1m1580/1580\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 12ms/step - loss: 0.1813\n",
            "Epoch 4/5\n",
            "\u001b[1m1576/1580\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.1427\n",
            "Epoch 4: loss improved from 0.16393 to 0.13262, saving model to checkpoints/bert_mlm_best.keras\n",
            "\u001b[1m1580/1580\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 12ms/step - loss: 0.1427\n",
            "Epoch 5/5\n",
            "\u001b[1m1576/1580\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.1218\n",
            "Epoch 5: loss improved from 0.13262 to 0.11404, saving model to checkpoints/bert_mlm_best.keras\n",
            "\u001b[1m1580/1580\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 12ms/step - loss: 0.1218\n"
          ]
        },
        {
          "data": {
            "application/javascript": "\n    async function download(id, filename, size) {\n      if (!google.colab.kernel.accessAllowed) {\n        return;\n      }\n      const div = document.createElement('div');\n      const label = document.createElement('label');\n      label.textContent = `Downloading \"${filename}\": `;\n      div.appendChild(label);\n      const progress = document.createElement('progress');\n      progress.max = size;\n      div.appendChild(progress);\n      document.body.appendChild(div);\n\n      const buffers = [];\n      let downloaded = 0;\n\n      const channel = await google.colab.kernel.comms.open(id);\n      // Send a message to notify the kernel that we're ready.\n      channel.send({})\n\n      for await (const message of channel.messages) {\n        // Send a message to notify the kernel that we're ready.\n        channel.send({})\n        if (message.buffers) {\n          for (const buffer of message.buffers) {\n            buffers.push(buffer);\n            downloaded += buffer.byteLength;\n            progress.value = downloaded;\n          }\n        }\n      }\n      const blob = new Blob(buffers, {type: 'application/binary'});\n      const a = document.createElement('a');\n      a.href = window.URL.createObjectURL(blob);\n      a.download = filename;\n      div.appendChild(a);\n      a.click();\n      div.remove();\n    }\n  ",
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/javascript": "download(\"download_5889c8c4-07a7-4d4d-80d2-58c664aab582\", \"bert_mlm_friends_trained.keras\", 99315427)",
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/javascript": "\n    async function download(id, filename, size) {\n      if (!google.colab.kernel.accessAllowed) {\n        return;\n      }\n      const div = document.createElement('div');\n      const label = document.createElement('label');\n      label.textContent = `Downloading \"${filename}\": `;\n      div.appendChild(label);\n      const progress = document.createElement('progress');\n      progress.max = size;\n      div.appendChild(progress);\n      document.body.appendChild(div);\n\n      const buffers = [];\n      let downloaded = 0;\n\n      const channel = await google.colab.kernel.comms.open(id);\n      // Send a message to notify the kernel that we're ready.\n      channel.send({})\n\n      for await (const message of channel.messages) {\n        // Send a message to notify the kernel that we're ready.\n        channel.send({})\n        if (message.buffers) {\n          for (const buffer of message.buffers) {\n            buffers.push(buffer);\n            downloaded += buffer.byteLength;\n            progress.value = downloaded;\n          }\n        }\n      }\n      const blob = new Blob(buffers, {type: 'application/binary'});\n      const a = document.createElement('a');\n      a.href = window.URL.createObjectURL(blob);\n      a.download = filename;\n      div.appendChild(a);\n      a.click();\n      div.remove();\n    }\n  ",
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/javascript": "download(\"download_c10cc3a8-2f8c-490a-a028-4c90b8bdb383\", \"bert_mlm_best.keras\", 99315427)",
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "#Treinamento do modelo com checkpoint baseado em loss\n",
        "from tensorflow import keras\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint\n",
        "from google.colab import files\n",
        "\n",
        "# Recarrega o modelo salvo\n",
        "mlm_model = keras.models.load_model(\n",
        "    \"bert_mlm_friends.keras\",\n",
        "    custom_objects={\"MaskedLanguageModel\": MaskedLanguageModel}\n",
        ")\n",
        "\n",
        "# Converte os dados para os tipos corretos\n",
        "x_masked = x_masked.astype(\"int32\")\n",
        "y_labels = y_labels.astype(\"int32\")\n",
        "sample_weights = np.ones(y_labels.shape, dtype=np.float32)\n",
        "sample_weights[y_labels == -1] = 0\n",
        "\n",
        "# Cria o dataset final para treinamento\n",
        "dataset = tf.data.Dataset.from_tensor_slices(\n",
        "    (x_masked, y_labels, sample_weights)\n",
        ").shuffle(1000).batch(32)\n",
        "\n",
        "# Callback para salvar o melhor modelo baseado no menor loss\n",
        "checkpoint_cb = ModelCheckpoint(\n",
        "    filepath=\"checkpoints/bert_mlm_best.keras\",\n",
        "    monitor=\"loss\",\n",
        "    save_best_only=True,\n",
        "    save_weights_only=False,\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "# Treinamento do modelo\n",
        "history = mlm_model.fit(\n",
        "    dataset,\n",
        "    epochs=5,\n",
        "    callbacks=[checkpoint_cb]\n",
        ")\n",
        "\n",
        "# Salva o modelo final (última época)\n",
        "mlm_model.save(\"bert_mlm_friends_trained.keras\")\n",
        "\n",
        "# Baixa os arquivos para o seu computador\n",
        "files.download(\"bert_mlm_friends_trained.keras\")\n",
        "files.download(\"checkpoints/bert_mlm_best.keras\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b7RBgT88vVgm"
      },
      "source": [
        "### Fine-tuning para Classificação de Personagem"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SR7L9Sz7wXsA"
      },
      "outputs": [],
      "source": [
        "!pip install -q tensorflow keras-nlp"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 374
        },
        "id": "appGS0Sgq84Y",
        "outputId": "d3a3f23c-cfe2-49b8-a26f-4aa2afd9b424"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/saving/saving_lib.py:757: UserWarning: Skipping variable loading for optimizer 'adam', because it has 138 variables whereas the saved optimizer has 2 variables. \n",
            "  saveable.load_own_variables(weights_store.get(inner_path))\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"friends_classifier\"</span>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1mModel: \"friends_classifier\"\u001b[0m\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ input_layer_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ functional_38 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Functional</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │     <span style=\"color: #00af00; text-decoration-color: #00af00\">4,386,304</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ global_max_pooling1d            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalMaxPooling1D</span>)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">8,256</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_9 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>)              │           <span style=\"color: #00af00; text-decoration-color: #00af00\">390</span> │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
              "</pre>\n"
            ],
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ input_layer_6 (\u001b[38;5;33mInputLayer\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ functional_38 (\u001b[38;5;33mFunctional\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │     \u001b[38;5;34m4,386,304\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ global_max_pooling1d            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
              "│ (\u001b[38;5;33mGlobalMaxPooling1D\u001b[0m)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_8 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │         \u001b[38;5;34m8,256\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_9 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m6\u001b[0m)              │           \u001b[38;5;34m390\u001b[0m │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">4,394,950</span> (16.77 MB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m4,394,950\u001b[0m (16.77 MB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">8,646</span> (33.77 KB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m8,646\u001b[0m (33.77 KB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">4,386,304</span> (16.73 MB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m4,386,304\u001b[0m (16.73 MB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "#Carregar modelo pré-treinado\n",
        "mlm_model = keras.models.load_model(\n",
        "    \"bert_mlm_friends.keras\",\n",
        "    custom_objects={\"MaskedLanguageModel\": MaskedLanguageModel}\n",
        ")\n",
        "\n",
        "#Extrai a base BERT até a última camada de encoder\n",
        "pretrained_bert_model = keras.Model(\n",
        "    mlm_model.input,\n",
        "    mlm_model.get_layer(\"encoder_3_ffn_layernormalization\").output\n",
        ")\n",
        "\n",
        "#Congela os pesos da BERT\n",
        "pretrained_bert_model.trainable = False\n",
        "\n",
        "#Cria o classificador\n",
        "def create_classifier_bert_model():\n",
        "    inputs = keras.Input(shape=(MAX_LEN,), dtype=\"int64\")\n",
        "    x = pretrained_bert_model(inputs)\n",
        "    x = layers.GlobalMaxPooling1D()(x)\n",
        "    x = layers.Dense(64, activation=\"relu\")(x)\n",
        "    outputs = layers.Dense(6, activation=\"softmax\")(x)  #6 classes (6 personagens)\n",
        "\n",
        "    model = keras.Model(inputs, outputs, name=\"friends_classifier\")\n",
        "    model.compile(\n",
        "        optimizer=keras.optimizers.Adam(),\n",
        "        loss=\"sparse_categorical_crossentropy\",\n",
        "        metrics=[\"accuracy\"]\n",
        "    )\n",
        "    return model\n",
        "\n",
        "#Instancia o classificador\n",
        "classifier_model = create_classifier_bert_model()\n",
        "classifier_model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZyYcmQ3027gT"
      },
      "source": [
        "### Preparar os datasets e pesos"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IGvCvhL6002D",
        "outputId": "a238e8aa-816d-46ce-e228-fddc9242d09d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Class weights: {0: np.float64(1.1397958608244516), 1: np.float64(1.004822271936366), 2: np.float64(0.921281735721774), 3: np.float64(1.0134376253509827), 4: np.float64(0.9255850162568119), 5: np.float64(1.0257815671944783)}\n"
          ]
        }
      ],
      "source": [
        "#Preparar os datasets e pesos\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.utils import class_weight\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import re\n",
        "\n",
        "# Mapeamento\n",
        "personagem2id = {\n",
        "    \"[PHOEBE]\": 0,\n",
        "    \"[CHANDLER]\": 1,\n",
        "    \"[RACHEL]\": 2,\n",
        "    \"[MONICA]\": 3,\n",
        "    \"[ROSS]\": 4,\n",
        "    \"[JOEY]\": 5,\n",
        "}\n",
        "\n",
        "#Extrai textos e rótulos\n",
        "textos = falas_tagged\n",
        "rotulos = [personagem2id[re.search(r\"\\[(.*?)\\]\", linha).group()] for linha in textos]\n",
        "\n",
        "# Divide em treino e teste\n",
        "x_train, x_test, y_train, y_test = train_test_split(\n",
        "    textos, rotulos, test_size=0.2, random_state=42, stratify=rotulos\n",
        ")\n",
        "\n",
        "# Vetoriza os textos\n",
        "x_train_vect = vectorize_layer(tf.constant(x_train))\n",
        "x_test_vect = vectorize_layer(tf.constant(x_test))\n",
        "\n",
        "# Converte rótulos\n",
        "y_train = tf.convert_to_tensor(y_train)\n",
        "y_test = tf.convert_to_tensor(y_test)\n",
        "\n",
        "# Cria datasets\n",
        "train_classifier_ds = tf.data.Dataset.from_tensor_slices((x_train_vect, y_train)).shuffle(1000).batch(32)\n",
        "test_classifier_ds = tf.data.Dataset.from_tensor_slices((x_test_vect, y_test)).batch(32)\n",
        "\n",
        "# Calcula pesos\n",
        "class_weights_array = class_weight.compute_class_weight(\n",
        "    class_weight=\"balanced\",\n",
        "    classes=np.unique(y_train.numpy()),\n",
        "    y=y_train.numpy()\n",
        ")\n",
        "class_weight_dict = {i: w for i, w in enumerate(class_weights_array)}\n",
        "print(\"Class weights:\", class_weight_dict)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zsxJv0bc27gV"
      },
      "source": [
        "### Treinamento do classificador com BERT congelado, class weights + checkpoint"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QjiEtIs8xRH4",
        "outputId": "352c07fb-b267-46e8-aa58-26df28277ecc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "\u001b[1m1264/1264\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.1818 - loss: 1.8720\n",
            "Epoch 1: val_accuracy improved from -inf to 0.36984, saving model to checkpoints/friends_classifier_epoch_01_valacc_0.37.keras\n",
            "\u001b[1m1264/1264\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 15ms/step - accuracy: 0.1818 - loss: 1.8720 - val_accuracy: 0.3698 - val_loss: 1.7352\n",
            "Epoch 2/5\n",
            "\u001b[1m1261/1264\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.2130 - loss: 1.7802\n",
            "Epoch 2: val_accuracy improved from 0.36984 to 0.48996, saving model to checkpoints/friends_classifier_epoch_02_valacc_0.49.keras\n",
            "\u001b[1m1264/1264\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - accuracy: 0.2130 - loss: 1.7802 - val_accuracy: 0.4900 - val_loss: 1.6740\n",
            "Epoch 3/5\n",
            "\u001b[1m1264/1264\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.2514 - loss: 1.7378\n",
            "Epoch 3: val_accuracy did not improve from 0.48996\n",
            "\u001b[1m1264/1264\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.2514 - loss: 1.7378 - val_accuracy: 0.3562 - val_loss: 1.5822\n",
            "Epoch 4/5\n",
            "\u001b[1m1252/1264\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.2728 - loss: 1.7039\n",
            "Epoch 4: val_accuracy did not improve from 0.48996\n",
            "\u001b[1m1264/1264\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.2728 - loss: 1.7038 - val_accuracy: 0.3454 - val_loss: 1.4868\n",
            "Epoch 5/5\n",
            "\u001b[1m1247/1264\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.2903 - loss: 1.6642\n",
            "Epoch 5: val_accuracy did not improve from 0.48996\n",
            "\u001b[1m1264/1264\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.2904 - loss: 1.6641 - val_accuracy: 0.3158 - val_loss: 1.4717\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x7c6f54558290>"
            ]
          },
          "execution_count": 32,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#Treinamento do classificador com BERT congelado, class weights + checkpoint\n",
        "\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint\n",
        "\n",
        "#Callback para salvar os melhores checkpoints com base na acurácia de validação\n",
        "checkpoint_cb = ModelCheckpoint(\n",
        "    filepath=\"checkpoints/friends_classifier_epoch_{epoch:02d}_valacc_{val_accuracy:.2f}.keras\",\n",
        "    monitor=\"val_accuracy\",\n",
        "    save_best_only=True,\n",
        "    save_weights_only=False,\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "# Treinamento\n",
        "classifier_model.fit(\n",
        "    train_classifier_ds,\n",
        "    validation_data=test_classifier_ds,\n",
        "    epochs=5,\n",
        "    class_weight=class_weight_dict,\n",
        "    callbacks=[checkpoint_cb]\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BAz_5zRa1wT4",
        "outputId": "9445a66b-e248-4d4d-8dac-7396a255c1a9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "\u001b[1m1264/1264\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.3131 - loss: 1.6373\n",
            "Epoch 1: val_accuracy improved from -inf to 0.45444, saving model to checkpoints/friends_classifier_epoch_01_valacc_0.45.keras\n",
            "\u001b[1m1264/1264\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 7ms/step - accuracy: 0.3131 - loss: 1.6373 - val_accuracy: 0.4544 - val_loss: 1.3642\n",
            "Epoch 2/5\n",
            "\u001b[1m1249/1264\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3233 - loss: 1.6184\n",
            "Epoch 2: val_accuracy improved from 0.45444 to 0.50698, saving model to checkpoints/friends_classifier_epoch_02_valacc_0.51.keras\n",
            "\u001b[1m1264/1264\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - accuracy: 0.3233 - loss: 1.6184 - val_accuracy: 0.5070 - val_loss: 1.3225\n",
            "Epoch 3/5\n",
            "\u001b[1m1251/1264\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3243 - loss: 1.6107\n",
            "Epoch 3: val_accuracy did not improve from 0.50698\n",
            "\u001b[1m1264/1264\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - accuracy: 0.3243 - loss: 1.6106 - val_accuracy: 0.4187 - val_loss: 1.3004\n",
            "Epoch 4/5\n",
            "\u001b[1m1258/1264\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3305 - loss: 1.5989\n",
            "Epoch 4: val_accuracy improved from 0.50698 to 0.67864, saving model to checkpoints/friends_classifier_epoch_04_valacc_0.68.keras\n",
            "\u001b[1m1264/1264\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - accuracy: 0.3305 - loss: 1.5989 - val_accuracy: 0.6786 - val_loss: 1.2256\n",
            "Epoch 5/5\n",
            "\u001b[1m1246/1264\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3293 - loss: 1.5944\n",
            "Epoch 5: val_accuracy did not improve from 0.67864\n",
            "\u001b[1m1264/1264\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - accuracy: 0.3293 - loss: 1.5944 - val_accuracy: 0.6743 - val_loss: 1.2297\n"
          ]
        }
      ],
      "source": [
        "#continuar treinamento\n",
        "\n",
        "#Callback para salvar os melhores checkpoints por acurácia de validação\n",
        "checkpoint_cb = ModelCheckpoint(\n",
        "    filepath=\"checkpoints/friends_classifier_epoch_{epoch:02d}_valacc_{val_accuracy:.2f}.keras\",\n",
        "    monitor=\"val_accuracy\",\n",
        "    save_best_only=True,\n",
        "    save_weights_only=False,\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "#Reexecutar o treinamento por mais 5 épocas\n",
        "history_more = classifier_model.fit(\n",
        "    x=x_train_vect,\n",
        "    y=y_train,\n",
        "    validation_data=(x_test_vect, y_test),\n",
        "    epochs=5,\n",
        "    batch_size=32,\n",
        "    class_weight=class_weight_dict,\n",
        "    callbacks=[checkpoint_cb]\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zs_zJihr27gW"
      },
      "source": [
        "### Matriz Confusão"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 879
        },
        "id": "IK3cHj1D3l-9",
        "outputId": "bbedad3f-1dc5-4b04-e78f-9d2dcddbbf79"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/saving/saving_lib.py:757: UserWarning: Skipping variable loading for optimizer 'adam', because it has 74 variables whereas the saved optimizer has 10 variables. \n",
            "  saveable.load_own_variables(weights_store.get(inner_path))\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 800x600 with 2 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Relatório de Classificação por personagem:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "      PHOEBE       0.78      1.00      0.88      1478\n",
            "    CHANDLER       1.00      0.22      0.36      1676\n",
            "      RACHEL       0.49      0.80      0.61      1829\n",
            "      MONICA       0.93      0.05      0.10      1662\n",
            "        ROSS       1.00      1.00      1.00      1820\n",
            "        JOEY       0.56      1.00      0.71      1642\n",
            "\n",
            "    accuracy                           0.68     10107\n",
            "   macro avg       0.79      0.68      0.61     10107\n",
            "weighted avg       0.79      0.68      0.61     10107\n",
            "\n"
          ]
        }
      ],
      "source": [
        "#gerar a matriz de confusão para entender quais personagens o modelo está confundindo mais\n",
        "\n",
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from tensorflow import keras\n",
        "\n",
        "best_model = keras.models.load_model(\"checkpoints/friends_classifier_epoch_04_valacc_0.68.keras\")\n",
        "\n",
        "# Previsões no conjunto de teste\n",
        "y_pred_probs = best_model.predict(x_test_vect, verbose=0)\n",
        "y_pred_classes = np.argmax(y_pred_probs, axis=1)\n",
        "\n",
        "# Rótulos reais\n",
        "y_true = y_test.numpy()\n",
        "\n",
        "# Rótulos dos personagens\n",
        "id2personagem = {\n",
        "    0: \"PHOEBE\",\n",
        "    1: \"CHANDLER\",\n",
        "    2: \"RACHEL\",\n",
        "    3: \"MONICA\",\n",
        "    4: \"ROSS\",\n",
        "    5: \"JOEY\"\n",
        "}\n",
        "labels = list(id2personagem.values())\n",
        "\n",
        "# Matriz de confusão\n",
        "cm = confusion_matrix(y_true, y_pred_classes)\n",
        "plt.figure(figsize=(8,6))\n",
        "sns.heatmap(cm, annot=True, fmt='d', cmap=\"Blues\", xticklabels=labels, yticklabels=labels)\n",
        "plt.xlabel(\"Predito\")\n",
        "plt.ylabel(\"Verdadeiro\")\n",
        "plt.title(\"Matriz de Confusão - Classificador Friends\")\n",
        "plt.show()\n",
        "\n",
        "# Relatório detalhado\n",
        "print(\"Relatório de Classificação por personagem:\")\n",
        "print(classification_report(y_true, y_pred_classes, target_names=labels))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_HtyOz_D27gW"
      },
      "source": [
        "### Ajustes e Treinamentos Adicionais para Melhorar o Desempenho do Classificador"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D82Lrpkw6Ehc",
        "outputId": "5971782c-6b4c-41f0-e7ca-0ce94bfbca98"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Pesos ajustados: {0: np.float64(1.1397958608244516), 1: np.float64(1.004822271936366), 2: np.float64(0.921281735721774), 3: np.float64(1.0134376253509827), 4: np.float64(0.9255850162568119), 5: np.float64(1.0257815671944783)}\n"
          ]
        }
      ],
      "source": [
        "# ajustar a class_weight para melhorar o desempenho com o classificador\n",
        "\n",
        "from sklearn.utils import class_weight\n",
        "import numpy as np\n",
        "\n",
        "y_train_np = y_train.numpy() if hasattr(y_train, 'numpy') else np.array(y_train)\n",
        "\n",
        "#Gera pesos balanceados com base nas classes reais de y_train\n",
        "class_weights = class_weight.compute_class_weight(\n",
        "    class_weight=\"balanced\",\n",
        "    classes=np.unique(y_train),\n",
        "    y=y_train\n",
        ")\n",
        "\n",
        "#Transforma em dicionário para passar ao modelo\n",
        "class_weight_dict = {i: weight for i, weight in enumerate(class_weights)}\n",
        "print(\"Pesos calculados para cada personagem:\", class_weight_dict)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T2ZECFjB6Mvg",
        "outputId": "187c3b91-99eb-4bcf-8eaa-92efd3382186"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "\u001b[1m1264/1264\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3350 - loss: 1.5905\n",
            "Epoch 1: val_accuracy improved from -inf to 0.48887, saving model to checkpoints/friends_classifier_epoch_01_valacc_0.49.keras\n",
            "\u001b[1m1264/1264\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - accuracy: 0.3350 - loss: 1.5905 - val_accuracy: 0.4889 - val_loss: 1.2774\n",
            "Epoch 2/5\n",
            "\u001b[1m1258/1264\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3303 - loss: 1.5916\n",
            "Epoch 2: val_accuracy improved from 0.48887 to 0.52617, saving model to checkpoints/friends_classifier_epoch_02_valacc_0.53.keras\n",
            "\u001b[1m1264/1264\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - accuracy: 0.3303 - loss: 1.5915 - val_accuracy: 0.5262 - val_loss: 1.1863\n",
            "Epoch 3/5\n",
            "\u001b[1m1255/1264\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3439 - loss: 1.5788\n",
            "Epoch 3: val_accuracy improved from 0.52617 to 0.65331, saving model to checkpoints/friends_classifier_epoch_03_valacc_0.65.keras\n",
            "\u001b[1m1264/1264\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - accuracy: 0.3439 - loss: 1.5789 - val_accuracy: 0.6533 - val_loss: 1.1967\n",
            "Epoch 4/5\n",
            "\u001b[1m1254/1264\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3430 - loss: 1.5779\n",
            "Epoch 4: val_accuracy did not improve from 0.65331\n",
            "\u001b[1m1264/1264\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - accuracy: 0.3430 - loss: 1.5779 - val_accuracy: 0.4641 - val_loss: 1.3347\n",
            "Epoch 5/5\n",
            "\u001b[1m1263/1264\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3346 - loss: 1.5823\n",
            "Epoch 5: val_accuracy did not improve from 0.65331\n",
            "\u001b[1m1264/1264\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - accuracy: 0.3346 - loss: 1.5823 - val_accuracy: 0.5464 - val_loss: 1.2037\n"
          ]
        }
      ],
      "source": [
        "#Treinamento com class_weight\n",
        "\n",
        "checkpoint_cb = ModelCheckpoint(\n",
        "    filepath=\"checkpoints/friends_classifier_epoch_{epoch:02d}_valacc_{val_accuracy:.2f}.keras\",\n",
        "    monitor=\"val_accuracy\",\n",
        "    save_best_only=True,\n",
        "    save_weights_only=False,\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "#Treinamento com os novos pesos\n",
        "history = classifier_model.fit(\n",
        "    x_train_vect,\n",
        "    y_train,\n",
        "    validation_data=(x_test_vect, y_test),\n",
        "    batch_size=32,\n",
        "    epochs=5,\n",
        "    class_weight=class_weight_dict,\n",
        "    callbacks=[checkpoint_cb]\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-Oh9UYzW7ltq",
        "outputId": "73bf0b2e-9451-46ce-bcb0-6d41a342a0b7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "\u001b[1m1249/1264\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3451 - loss: 1.5652\n",
            "Epoch 1: val_accuracy did not improve from 0.65331\n",
            "\u001b[1m1264/1264\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - accuracy: 0.3451 - loss: 1.5653 - val_accuracy: 0.4897 - val_loss: 1.1870\n",
            "Epoch 2/5\n",
            "\u001b[1m1251/1264\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3370 - loss: 1.5833\n",
            "Epoch 2: val_accuracy improved from 0.65331 to 0.80053, saving model to checkpoints/friends_classifier_epoch_02_valacc_0.80.keras\n",
            "\u001b[1m1264/1264\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - accuracy: 0.3370 - loss: 1.5833 - val_accuracy: 0.8005 - val_loss: 1.1762\n",
            "Epoch 3/5\n",
            "\u001b[1m1263/1264\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3417 - loss: 1.5696\n",
            "Epoch 3: val_accuracy improved from 0.80053 to 0.85228, saving model to checkpoints/friends_classifier_epoch_03_valacc_0.85.keras\n",
            "\u001b[1m1264/1264\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - accuracy: 0.3417 - loss: 1.5696 - val_accuracy: 0.8523 - val_loss: 1.1632\n",
            "Epoch 4/5\n",
            "\u001b[1m1247/1264\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3392 - loss: 1.5798\n",
            "Epoch 4: val_accuracy did not improve from 0.85228\n",
            "\u001b[1m1264/1264\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - accuracy: 0.3392 - loss: 1.5797 - val_accuracy: 0.7043 - val_loss: 1.1487\n",
            "Epoch 5/5\n",
            "\u001b[1m1260/1264\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3398 - loss: 1.5785\n",
            "Epoch 5: val_accuracy did not improve from 0.85228\n",
            "\u001b[1m1264/1264\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - accuracy: 0.3398 - loss: 1.5785 - val_accuracy: 0.6130 - val_loss: 1.2129\n"
          ]
        }
      ],
      "source": [
        "#Treinar por mais 5 épocas usando os mesmos pesos e callbacks\n",
        "history_more = classifier_model.fit(\n",
        "    x_train_vect,\n",
        "    y_train,\n",
        "    validation_data=(x_test_vect, y_test),\n",
        "    batch_size=32,\n",
        "    epochs=5,\n",
        "    class_weight=class_weight_dict,\n",
        "    callbacks=[checkpoint_cb]\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vdBCrGze7nqU",
        "outputId": "622c5893-911a-4ef5-d1b5-79a03a742945"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "\u001b[1m1264/1264\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.7740 - loss: 0.5909\n",
            "Epoch 1: val_accuracy improved from -inf to 1.00000, saving model to checkpoints/friends_finetuned_epoch_01_valacc_1.00.keras\n",
            "\u001b[1m1264/1264\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 26ms/step - accuracy: 0.7741 - loss: 0.5907 - val_accuracy: 1.0000 - val_loss: 0.0164\n",
            "Epoch 2/5\n",
            "\u001b[1m1261/1264\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9991 - loss: 0.0267\n",
            "Epoch 2: val_accuracy did not improve from 1.00000\n",
            "\u001b[1m1264/1264\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 8ms/step - accuracy: 0.9991 - loss: 0.0267 - val_accuracy: 1.0000 - val_loss: 0.0029\n",
            "Epoch 3/5\n",
            "\u001b[1m1259/1264\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9995 - loss: 0.0077\n",
            "Epoch 3: val_accuracy did not improve from 1.00000\n",
            "\u001b[1m1264/1264\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 8ms/step - accuracy: 0.9995 - loss: 0.0077 - val_accuracy: 1.0000 - val_loss: 8.5550e-04\n",
            "Epoch 4/5\n",
            "\u001b[1m1259/1264\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9999 - loss: 0.0031\n",
            "Epoch 4: val_accuracy did not improve from 1.00000\n",
            "\u001b[1m1264/1264\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 8ms/step - accuracy: 0.9999 - loss: 0.0031 - val_accuracy: 1.0000 - val_loss: 3.6847e-04\n",
            "Epoch 5/5\n",
            "\u001b[1m1257/1264\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 1.0000 - loss: 0.0015\n",
            "Epoch 5: val_accuracy did not improve from 1.00000\n",
            "\u001b[1m1264/1264\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 8ms/step - accuracy: 1.0000 - loss: 0.0015 - val_accuracy: 1.0000 - val_loss: 1.6895e-04\n"
          ]
        }
      ],
      "source": [
        "#Congelar menos camadas do BERT para tentar melhorar o desempenho do classificador\n",
        "\n",
        "#descongela o BERT\n",
        "pretrained_bert_model.trainable = True\n",
        "\n",
        "#Recompila o classificador com uma learning rate menor\n",
        "classifier_model.compile(\n",
        "    optimizer=keras.optimizers.Adam(learning_rate=1e-5),\n",
        "    loss=\"sparse_categorical_crossentropy\",\n",
        "    metrics=[\"accuracy\"]\n",
        ")\n",
        "\n",
        "#checkpoint\n",
        "checkpoint_cb = ModelCheckpoint(\n",
        "    filepath=\"checkpoints/friends_finetuned_epoch_{epoch:02d}_valacc_{val_accuracy:.2f}.keras\",\n",
        "    monitor=\"val_accuracy\",\n",
        "    save_best_only=True,\n",
        "    save_weights_only=False,\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "#treinamento\n",
        "history = classifier_model.fit(\n",
        "    train_classifier_ds,\n",
        "    validation_data=test_classifier_ds,\n",
        "    epochs=5,\n",
        "    class_weight=class_weight_dict,  # pesos ajustados\n",
        "    callbacks=[checkpoint_cb]\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "posY0IfF27gX"
      },
      "source": [
        "#### Nova matriz confusão"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 841
        },
        "id": "XSNuVbjb9mKx",
        "outputId": "fef48522-f744-4f17-e3ff-a6675c9fc18c"
      },
      "outputs": [
        {
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAApIAAAIjCAYAAACwHvu2AAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjAsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvlHJYcgAAAAlwSFlzAAAPYQAAD2EBqD+naQAAkNRJREFUeJzs3XdYFFfbBvB76UWaIGBBFAsIir1gr2DD3jVib9hjCTbQRLGjxhKNgg3FXmKiYjeK3SgWVKxYQEVAFOnM94cf+7ouKLvuMpT7915zvc6ZM2eePcyShzMzZySCIAggIiIiIlKQhtgBEBEREVH+xESSiIiIiJTCRJKIiIiIlMJEkoiIiIiUwkSSiIiIiJTCRJKIiIiIlMJEkoiIiIiUwkSSiIiIiJTCRJKIiIiIlMJEkvIsHx8fSCQStR5DIpHAx8dHrcfIbYsWLYKdnR00NTVRrVo1tRxj0qRJMDIygoeHB2JiYuDo6IgbN26o5Viqlhvn1becPn0aEokEp0+flinfsmULHBwcoK2tDVNTUwBA06ZN0bRp01yPMb98L8SMU6yfDVFew0SSsHHjRkgkEkgkEpw7d05uuyAIsLGxgUQiQfv27ZU6xrx587B///4fjDR/SE9PR0BAAJo2bYqiRYtCV1cXZcqUwcCBA3H16lW1Hjs4OBhTpkxBgwYNEBAQgHnz5qn8GB8/fsSaNWswZ84c3LlzBxYWFihSpAicnZ1VfixFJCUlwc/PD3Xr1oWJiQn09PRQsWJFjB49Gg8ePBA1tu+5d+8eBgwYgHLlyuHPP//EunXrxA4pVzx9+lT6u+frpV69emKHR0Q5oCV2AJR36OnpYdu2bWjYsKFM+ZkzZ/DixQvo6uoq3fa8efPQrVs3dOrUKcf7zJgxA7/88ovSxxRDYmIiunTpgiNHjqBx48aYNm0aihYtiqdPn2Lnzp3YtGkTIiIiUKpUKbUc/+TJk9DQ0MCGDRugo6OjlmPo6enh7t27sLW1xYQJE/Dq1StYW1tDQ0O8v0ujo6PRunVrXLt2De3bt0efPn1QpEgR3L9/H0FBQVi3bh1SUlJEi+9LjRs3RmJioszP5/Tp08jIyMDy5ctRvnx5aXlwcLAYIea63r17o23btjJlxYoV++5+iYmJ0NLif8aIxMRvIEm1bdsWu3btwooVK2R+OW/btg01a9ZEdHR0rsSRkJAAQ0NDaGlp5bv/SEyePBlHjhyBn58fxo8fL7PN29sbfn5+aj3+mzdvoK+vr7YkEgC0tLRga2srXS9RooTajpVTAwYMwH///Yfdu3eja9euMtt+/fVXTJ8+XaTI5GloaEBPT0+m7M2bNwAgvaSdSZ0/x9yS+X3+lho1aqBfv345ai8jIwMpKSnQ09OT60ciyn28tE1SvXv3xrt373Ds2DFpWUpKCnbv3o0+ffpkuc/ixYtRv359mJubQ19fHzVr1sTu3btl6kgkEiQkJGDTpk3Sy1YDBgwA8L/71e7evYs+ffrAzMxMOiL69b1sAwYMyPYy2Pfuk0pOTsaECRNQrFgxGBkZoUOHDnjx4kWWdV++fIlBgwbBysoKurq6cHJygr+///e6Dy9evMDatWvRqlUruSQSADQ1NTFp0iSZ0cj//vsPbdq0gbGxMYoUKYIWLVrg4sWLMvtl3npw/vx5TJw4EcWKFYOhoSE6d+6Mt2/fSutJJBIEBAQgISFB2i8bN26UXj7cuHGjXExf992HDx8wfvx4lClTBrq6urC0tESrVq1w/fp1aZ3Tp0+jW7duKF26NHR1dWFjY4MJEyYgMTFRrv2TJ0+iUaNGMDQ0hKmpKTp27IiwsLDv9qUiLl26hL///huDBw+WSyIBQFdXF4sXL/5mGwEBAWjevDksLS2hq6sLR0dHrFmzRq7e1atX4ebmBgsLC+jr66Ns2bIYNGiQTJ2goCDUrFkTRkZGMDY2RpUqVbB8+XLp9q/vkSxTpgy8vb0BfB6F+/JnktV9eElJSfDx8UHFihWhp6eH4sWLo0uXLnj06JG0Tk6+l4Bi3wtFztUzZ85g1KhRsLS0/OHRd4lEgtGjRyMwMBBOTk7Q1dXFkSNHpNu+/u7n5Pub+TPYuXMn5s6di1KlSkFPTw8tWrTAw4cP5WJYt24dypUrB319fdSpUwf//vtvlrH+/vvvcHJygoGBAczMzFCrVi1s27bthz4/UV6Xv4Z7SK3KlCkDFxcXbN++HW3atAEAHD58GO/fv0evXr2wYsUKuX2WL1+ODh06oG/fvkhJSUFQUBC6d++OQ4cOoV27dgA+P0QwZMgQ1KlTB8OGDQMAlCtXTqad7t27o0KFCpg3bx4EQcgyvuHDh6Nly5YyZUeOHEFgYCAsLS2/+dmGDBmCrVu3ok+fPqhfvz5Onjwpje9Lr1+/Rr169aT/8SpWrBgOHz6MwYMHIz4+PssEMdPhw4eRlpaGn3766ZuxZLpz5w4aNWoEY2NjTJkyBdra2li7di2aNm2KM2fOoG7dujL1x4wZAzMzM3h7e+Pp06dYtmwZRo8ejR07dgD43M/r1q3D5cuXsX79egBA/fr1cxRLphEjRmD37t0YPXo0HB0d8e7dO5w7dw5hYWGoUaMGAGDnzp1ITEzEqFGjULRoUVy+fBm///47Xrx4gV27dknbOn78ONq0aQM7Ozv4+PggMTERv//+Oxo0aIDr16+jTJkyCsWWnYMHDwJAjvs9K2vWrIGTkxM6dOgALS0t/PXXXxg1ahQyMjLg6ekJ4POooaurK4oVK4ZffvkFpqamePr0Kfbu3Stt59ixY+jduzdatGiBBQsWAADCwsJw/vx5jBs3LstjL1u2DJs3b8a+ffuwZs2ab95vmp6ejvbt2+PEiRPo1asXxo0bhw8fPuDYsWO4ffu29HuVk+8lkPPvhaLn6qhRo1CsWDHMmjULCQkJ3+3/T58+yV3xMDExgba2NoDPf5Ds3LkTo0ePhoWFRbbnjqLf3/nz50NDQwOTJk3C+/fvsXDhQvTt2xeXLl2S1tmwYQOGDx+O+vXrY/z48Xj8+DE6dOiAokWLwsbGRlrvzz//xNixY9GtWzeMGzcOSUlJCA0NxaVLl7L9Q5yoQBCo0AsICBAACFeuXBFWrlwpGBkZCZ8+fRIEQRC6d+8uNGvWTBAEQbC1tRXatWsns29mvUwpKSlC5cqVhebNm8uUGxoaCh4eHnLH9vb2FgAIvXv3znZbdsLDwwUTExOhVatWQlpaWrb1bty4IQAQRo0aJVPep08fAYDg7e0tLRs8eLBQvHhxITo6WqZur169BBMTE7nP+6UJEyYIAIT//vsv2zpf6tSpk6CjoyM8evRIWvbq1SvByMhIaNy4sbQs8+fTsmVLISMjQ+Z4mpqaQlxcnLTMw8NDMDQ0lDnOkydPBABCQECAXAxff34TExPB09Pzm3EnJCTIlfn6+goSiUR49uyZtKxatWqCpaWl8O7dO2nZzZs3BQ0NDaF///7fPIYiOnfuLAAQYmNjc1Q/q/Mqq5+rm5ubYGdnJ13ft2+f9HuSnXHjxgnGxsbfPB9PnTolABBOnTolF9Pbt29l6jZp0kRo0qSJdN3f318AICxdulSu3S/PjZx8LxX5Xih6rjZs2PCbfZAp89zMasnsHwCChoaGcOfOHbn9lf3+Zv4MKlWqJCQnJ0vrLV++XAAg3Lp1S9pvlpaWQrVq1WTqrVu3TgAg87Pp2LGj4OTk9N3PTFTQ8NI2yejRowcSExNx6NAhfPjwAYcOHfrmX9P6+vrSf8fGxuL9+/do1KiRzKXQnBgxYoRC9RMSEtC5c2eYmZlh+/bt0NTUzLbuP//8AwAYO3asTPnXoxOCIGDPnj1wd3eHIAiIjo6WLm5ubnj//v03P1d8fDwAwMjI6Lvxp6enIzg4GJ06dYKdnZ20vHjx4ujTpw/OnTsnbS/TsGHDZC71N2rUCOnp6Xj27Nl3j5dTpqamuHTpEl69epVtHQMDA+m/ExISEB0djfr160MQBPz3338AgMjISNy4cQMDBgxA0aJFpfWdnZ3RqlUr6c9EFRTp9+x8eR6/f/8e0dHRaNKkCR4/foz3798D+N/9i4cOHUJqamqW7ZiamiIhIUHm9hBV2rNnDywsLDBmzBi5bV+eGzn5Xub0e6HMuTp06NBvfie/NmzYMBw7dkxmqVq1qnR7kyZN4Ojo+M02lPn+Dhw4UOY+1EaNGgEAHj9+DODzrQxv3rzBiBEjZOoNGDAAJiYmMm2ZmprixYsXuHLlSo4/N1FBwEvbJKNYsWJo2bIltm3bhk+fPiE9PR3dunXLtv6hQ4fw22+/4caNG0hOTpaWKzpPX9myZRWqP3ToUDx69AghISEwNzf/Zt1nz55BQ0ND7nK6vb29zPrbt28RFxeHdevWZTv9SuZDEVkxNjYG8Pk+w+95+/YtPn36JBcDAFSqVAkZGRl4/vw5nJycpOWlS5eWqWdmZgbgc6KgKgsXLoSHhwdsbGxQs2ZNtG3bFv3795dJICIiIjBr1iwcPHhQ7tiZSVdmcpvd5zt69Og3H8KIioqSWTcxMZFJjr70Zb9//bBKTp0/fx7e3t64cOECPn36JLPt/fv3MDExQZMmTdC1a1fMnj0bfn5+aNq0KTp16oQ+ffpIZzQYNWoUdu7ciTZt2qBkyZJwdXVFjx490Lp1a6Xi+tqjR49gb2//3YfQcvK9VOR7oei5quj3uUKFCnK3rXwpJ+0p8/393ncq8zyuUKGCTD1tbW2Z7wQATJ06FcePH0edOnVQvnx5uLq6ok+fPmjQoMF3YyfKz5hIkpw+ffpg6NChiIqKQps2bbL9j/O///6LDh06oHHjxli9ejWKFy8ObW1tBAQEKHyDeXZJQlaWL1+O7du3Y+vWrSqdcDsjIwMA0K9fP3h4eGRZ51tzJTo4OAAAbt26pZaJwLMb4RGyuac0U3ZJfXp6ulxZjx490KhRI+zbtw/BwcFYtGgRFixYgL1796JNmzZIT09Hq1atEBMTg6lTp8LBwQGGhoZ4+fIlBgwYIO3DH1W8eHGZ9YCAAOkDWl/7st8zR5QU8ejRI7Ro0QIODg5YunQpbGxsoKOjg3/++Qd+fn7SzySRSLB7925cvHgRf/31F44ePYpBgwZhyZIluHjxIooUKQJLS0vcuHEDR48exeHDh3H48GEEBASgf//+2LRpk8KxKUOV30tlKfJ9VlV7ynx/lf1OZaVSpUq4f/8+Dh06hCNHjmDPnj1YvXo1Zs2ahdmzZyvcHlF+wUSS5HTu3BnDhw/HxYsXpQ9yZGXPnj3Q09PD0aNHZeaYDAgIkKurqjeJ/Pvvv5g0aRLGjx+Pvn375mgfW1tbZGRkSEdzMt2/f1+mXuaTq+np6d8cHclOmzZtoKmpia1bt373wY9ixYrBwMBALgbg8+TUGhoaMjfy/4jMUZa4uDiZ8uwuiRcvXhyjRo3CqFGj8ObNG9SoUQNz585FmzZtcOvWLTx48ACbNm1C//79pft8fSk3c3qg7D6fhYXFN6eE+bq9L0e7vubu7g5fX19s3bpVqUTyr7/+QnJyMg4ePCgzQnXq1Kks69erVw/16tXD3LlzsW3bNvTt2xdBQUEYMmQIgM9T9ri7u8Pd3R0ZGRkYNWoU1q5di5kzZ8rMEamMcuXK4dKlS0hNTZU+iPK1nH4vFfle5Na5+iN+9PublczzODw8HM2bN5eWp6am4smTJzKX3wHA0NAQPXv2RM+ePZGSkoIuXbpg7ty58PLy4lRFVGDxHkmSU6RIEaxZswY+Pj5wd3fPtp6mpiYkEonMyNbTp0+zfIONoaGhXCKjqMjISPTo0QMNGzbEokWLcrxf5hPoXz91vmzZMpl1TU1NdO3aFXv27MHt27fl2vlyqp2s2NjYYOjQoQgODsbvv/8utz0jIwNLlizBixcvoKmpCVdXVxw4cABPnz6V1nn9+rV0UvjMS7Y/ytjYGBYWFjh79qxM+erVq2XW09PTpZemM1laWqJEiRLSy6OZIzhfjtgIgiAzvQ3wORmtVq0aNm3aJPNzv337NoKDg+Umn/5ay5YtZZavRyi/5OLigtatW2P9+vVZnnspKSmYNGlStvtn9Znev38vl3jFxsbKjVRljjxn9s+7d+9ktmtoaEhHwb68xKysrl27Ijo6GitXrpTblhlbTr+Xinwvcutc/RE/+v3NSq1atVCsWDH88ccfMhPab9y4Ue732dc/ex0dHTg6OkIQhGzvqSUqCDgiSVnK7tLQl9q1a4elS5eidevW6NOnD968eYNVq1ahfPnyCA0Nlalbs2ZNHD9+HEuXLkWJEiVQtmxZuSlDvmfs2LF4+/YtpkyZgqCgIJltzs7O2V52rlatGnr37o3Vq1fj/fv3qF+/Pk6cOJHlfHHz58/HqVOnULduXQwdOhSOjo6IiYnB9evXcfz4ccTExHwzxiVLluDRo0cYO3Ys9u7di/bt28PMzAwRERHYtWsX7t27h169egEAfvvtNxw7dgwNGzbEqFGjoKWlhbVr1yI5ORkLFy5UqG++Z8iQIZg/fz6GDBmCWrVq4ezZs3KvDfzw4QNKlSqFbt26oWrVqihSpAiOHz+OK1euYMmSJQA+X0YuV64cJk2ahJcvX8LY2Bh79uzJ8j7NRYsWoU2bNnBxccHgwYOl0/+YmJio/P3ImzdvhqurK7p06QJ3d3e0aNEChoaGCA8PR1BQECIjI7OdS9LV1VU6ijh8+HB8/PgRf/75JywtLREZGSmtt2nTJqxevRqdO3dGuXLl8OHDB/z5558wNjaWJsZDhgxBTEwMmjdvjlKlSuHZs2f4/fffUa1aNVSqVOmHP2f//v2xefNmTJw4EZcvX0ajRo2QkJCA48ePY9SoUejYsWOOv5eKfC9y81z9ET/6/f2atrY2fvvtNwwfPhzNmzdHz5498eTJEwQEBMjdI+nq6gpra2s0aNAAVlZWCAsLw8qVK9GuXbsfehCMKM8T5VlxylO+nP7nW7Ka/mfDhg1ChQoVBF1dXcHBwUEICAjIcnqVe/fuCY0bNxb09fUFANKpgLKb9uTLbZmaNGmS7VQhX04BkpXExERh7Nixgrm5uWBoaCi4u7sLz58/z3Lf169fC56enoKNjY2gra0tWFtbCy1atBDWrVv3zWNkSktLE9avXy80atRIMDExEbS1tQVbW1th4MCBclMDXb9+XXBzcxOKFCkiGBgYCM2aNRNCQkJk6mT388lqGpmspv8RhM/TwQwePFgwMTERjIyMhB49eghv3ryR+fzJycnC5MmThapVqwpGRkaCoaGhULVqVWH16tUybd29e1do2bKlUKRIEcHCwkIYOnSocPPmzSynGDp+/LjQoEEDQV9fXzA2Nhbc3d2Fu3fv5qgfFfXp0ydh8eLFQu3atYUiRYoIOjo6QoUKFYQxY8YIDx8+lNbL6vw8ePCg4OzsLOjp6QllypQRFixYIJ1q58mTJ4IgfP5Z9e7dWyhdurSgq6srWFpaCu3btxeuXr0qbWf37t2Cq6urYGlpKejo6AilS5cWhg8fLkRGRkrr/Mj0P5mfc/r06ULZsmWl52e3bt1kpubJ6fdSke/Fj5yr2cmc/mfRokXZ1gGQ7ZRUyn5/M38Gu3btyjKer8/j1atXC2XLlhV0dXWFWrVqCWfPnpX72axdu1Zo3LixYG5uLujq6grlypUTJk+eLLx//z5HfUGUX0kEQYm7iomIiIio0OM9kkRERESkFCaSRERERKQUJpJEREREpBQmkkRERESkFCaSRERERKQUJpJEREREpBQmkkRERESklAL5ZhvLwTvFDqHAiFjbQ+wQiIiokNATMSvRrz5abW0n/if/WtOCgiOSRERERKSUAjkiSURERKQQCcfWlMFEkoiIiEgiETuCfInpNxEREREphSOSRERERLy0rRT2GhEREREphSOSRERERLxHUikckSQiIiIipXBEkoiIiIj3SCqFvUZERERESuGIJBERERHvkVQKE0kiIiIiXtpWCnuNiIiIiJQiaiLZtm1bvH//Xro+f/58xMXFSdffvXsHR0dHESIjIiKiQkUiUd9SgImaSB49ehTJycnS9Xnz5iEmJka6npaWhvv374sRGhERERF9h6iJpCAI31wnIiIiyhUSDfUtCjp79izc3d1RokQJSCQS7N+/XzZUiSTLZdGiRdI6ZcqUkds+f/58mXZCQ0PRqFEj6OnpwcbGBgsXLlQ4Vt4jSURERJSHJCQkoGrVqli1alWW2yMjI2UWf39/SCQSdO3aVabenDlzZOqNGTNGui0+Ph6urq6wtbXFtWvXsGjRIvj4+GDdunUKxSrqU9uZGfLXZURERES5Kg/lH23atEGbNm2y3W5tbS2zfuDAATRr1gx2dnYy5UZGRnJ1MwUGBiIlJQX+/v7Q0dGBk5MTbty4gaVLl2LYsGE5jlXURFIQBAwYMAC6uroAgKSkJIwYMQKGhoYAIHP/JBEREVF+lJycLJfT6OrqSvOfH/H69Wv8/fff2LRpk9y2+fPn49dff0Xp0qXRp08fTJgwAVpan1O/CxcuoHHjxtDR0ZHWd3Nzw4IFCxAbGwszM7McHV/URNLDw0NmvV+/fnJ1+vfvn1vhEBERUWGlxnkkfX19MXv2bJkyb29v+Pj4/HDbmzZtgpGREbp06SJTPnbsWNSoUQNFixZFSEgIvLy8EBkZiaVLlwIAoqKiULZsWZl9rKyspNvyRSIZEBAg5uGJiIiIPlPjpW0vLy9MnDhRpkwVo5EA4O/vj759+0JPT0+m/MvjOTs7Q0dHB8OHD4evr6/Kjg3wzTZEREREaqWqy9hf+/fff3H//n3s2LHju3Xr1q2LtLQ0PH36FPb29rC2tsbr169l6mSuZ3dfZVZEf2r71KlTWLJkCc6fPw8AWLt2LUqXLo1ixYph6NChSExMFDlCIiIiKvDy0PQ/ObVhwwbUrFkTVatW/W7dGzduQENDA5aWlgAAFxcXnD17FqmpqdI6x44dg729fY4vawMiJ5J//vknWrVqhT/++AMtWrSAr68vfv75Z7Rr1w49evTAzp075e4pICIiIirIPn78iBs3buDGjRsAgCdPnuDGjRuIiIiQ1omPj8euXbswZMgQuf0vXLiAZcuW4ebNm3j8+DECAwMxYcIE9OvXT5ok9unTBzo6Ohg8eDDu3LmDHTt2YPny5XKX4L9H1Evby5cvh5+fH8aMGYMjR47A3d0d69evlz6E07RpU3h5eclNoElERESkUmocOVTU1atX0axZM+l6ZnLn4eGBjRs3AgCCgoIgCAJ69+4tt7+uri6CgoLg4+OD5ORklC1bFhMmTJBJEk1MTBAcHAxPT0/UrFkTFhYWmDVrlkJT/wCARBDxdTIGBgYICwuDra0tAEBHRwc3b95EpUqVAAARERGoUKGCwtMAWQ7eqfJYC6uItT3EDoGIiAoJPRGHt/SbzFFb24lnZqmtbbGJOiKZlJQEfX196frXN6Pq6uoiLS1NjNCIiIioMNHIOxOS5yeiv9nmw4cP0NPTgyAIkEgk+PjxI+Lj4wFA+v9ERERElPeI/mabihUryqxXr15dZp2vTCQiIiK1y0P3SOYnoiaSp06dEvPwRERERJ9x4EopoiaSTZo0EfPwRERERPQDRB3H3blzJ1JSUqTrL168QEZGhnT906dPWLhwoRihERERUWGSDyckzwtE/XS9e/dGXFycdN3R0RFPnz6Vrn/48AFeXl65H1gO1atogS1jGiJ0iTvebOiBNtVLZFt30U818WZDDwxrWUFaVt++GN5s6JHlUq3M/2aVb+ZkhX+mtcDjVZ1xd1kH+I+qDxtzA7V+tvwiaFsg2rRqjtrVq6Bvr+64FRoqdkj5EvtRddiXqsO+VA32I6mTqInk11NYijilpVIMdLRw50Ucftl6/Zv12lYviZp2RREZ+0mm/MrDd6g84aDMsuXsYzx7+xE3nsYCAEpbGGLTmIY4d+8NmvsEo+fSsyhaRAcBng3U9rnyiyOH/8Hihb4YPsoTQbv2wd7eASOHD8a7d+/EDi1fYT+qDvtSddiXqsF+VIBEor6lACvY461qdvJ2FObvu41//nuZbR1rU33M61MdI/+8hNR02UQ5NT0Db+KTpEtMQjJaVyuB7eeeSus425pBUyKB775bePo2Abci4rD66H1UtjGFlmbBPjm/Z8umAHTp1gOdOndFufLlMcN7NvT09LB/7x6xQ8tX2I+qw75UHfalarAfSd2YSKqRRAKsGlIHq47ex/1X358Ts3W1EihaRAfbzz+RloU+i0WGIKB3g7LQkEhgpK+N7i5lcDbsNdLS89cIriqlpqQg7O4d1HOpLy3T0NBAvXr1EXrzPxEjy1/Yj6rDvlQd9qVqsB8VxHsklSLqU9sAcPToUZiYmAAAMjIycOLECdy+fRsAZO6fzE5ycrLcKxSF9FRINLVVHquixrRxQHqGgD+Ph+eofp+Gdjh1+zUiYxOlZRHRCeix9CzWj3DB4v41oaWpgSsPo9F72b/qCjtfiI2LRXp6OszNzWXKzc3N8eTJY5Giyn/Yj6rDvlQd9qVqsB8pN4ieSHp4eMisDx8+XGb9exOS+/r6Yvbs2TJlBtW6wbBGd9UEqCRnWzMMa1kBLeYcy1H94mb6aFbZCkP/uCBTbmmsh6UetbAj5Cn2Xo5AET0tTO1YGf6j6qPbkjPqCJ2IiKjwKeD3MqqLqInkl1P9KMvLywsTJ06UKSs39q8fbvdH1atgAQsjPfy3sL20TEtTA7N7VsWwVhVRa+rfMvV7NyiLmI8pOHLjlUz5wOblEZ+Yijm7//eU3aj1l3BzsTtq2hXFtccx6v0geZSZqRk0NTXlbhh/9+4dLCwsRIoq/2E/qg77UnXYl6rBflRQAb8ErS75vtd0dXVhbGwss+SFy9q7LjxDU5+jaD47WLpExn7CqiP30XPpWbn6vRuWwa4Lz+TuezTQ0UTGV0+zp2d8XtcoxH89aevooJKjEy5d/N8IbkZGBi5dugDnqtW/sSd9if2oOuxL1WFfqgb7kXKD6Je2AWDXrl3Yvn07Hjx4AACoWLEi+vTpg27duokc2bcZ6mqhrGUR6XppiyKobGOK2IQUvIz5hNiEFJn6qekC3rxPwqPXH2TKG1WyhG2xIth6Vv6elWOhkRjeqiJ+dnfE3kufL21P71IFEdGfn+AuzH7yGIiZ06bCyakyKldxxtYtm5CYmIhOnbuIHVq+wn5UHfal6rAvVYP9qIBCPDjzI0S/tN27d2/s2rULFStWhIODAwDgzp076NmzJ7p3747t27d/9z5JsVQtY4b9U5pJ13/tVQ0AEHT+Ccb6X8lxO30alsXl8Gg8jPogt+3cvTcY8edFjG7tgNGt7fEpJR1XH71DL7+zSEpN/+HPkJ+1btMWsTExWL1yBaKj38LeoRJWr10Pc16yUQj7UXXYl6rDvlQN9iOpm0QQcRZwPz8//Pbbb9i0aRPat28vs+3gwYMYOHAgZs6cifHjxyvUruXgnSqMsnCLWNtD7BCIiKiQ0BNxeEu/7XK1tZ34zzi1tS02Ue+RDAgIwKJFi+SSSADo0KEDFi5cCH9/fxEiIyIiIqLvETWRDA8PR8uWLbPd3rJlS4SH52wORiIiIiKl8RWJShE1kdTX1//mpOPx8fHQ09PLvYCIiIiIKMdETSRdXFywZs2abLevWrUKLi4uuRgRERERFUp8RaJSRH1qe/r06WjatCnevXuHSZMmwcHBAYIgICwsDEuWLMGBAwdw6tQpMUMkIiKiwqCAJ3zqImoiWb9+fezYsQPDhg3Dnj17ZLaZmZlh+/btaNCggUjREREREdG3iD4heefOneHm5oajR49KH6ypWLEiXF1dYWBgIHJ0REREVCgU8Idi1EX0RBIADAwM0LlzZ7HDICIiIiIFiJpIrlixIkf1xo4dq+ZIiIiIqFDjPZJKETWR9PPzk1l//vw5ihcvDi2t/4UlkUiYSBIRERHlQaImkk+ePJFZNzIywpkzZ2BnZydSRERERFQo8R5JpXAcl4iIiIiUkicetiEiIiISFe+RVAoTSSIiIiJe2laKqIlkfHy8zLpEIsHHjx/lyo2NjXMzLCIiIiLKAVETSVNTU0i++AtAEARUr15dZl0ikSA9PV2M8IiIiKiQkHBEUimiJpJ8jzYRERFR/iVqItmoUSMsWrQIBw8eREpKClq0aAFvb2/o6+uLGRYREREVMhyRVI6ojyjNnTsX06ZNQ5EiRVCyZEksX74cnp6eYoZERERERDkkaiK5efNmrF69GkePHsX+/fvx119/ITAwEBkZGWKGRURERIWNRI1LASZqIhkREYG2bdtK11u2bAmJRIJXr16JGBURERER5YSo90impaVBT09PpkxbWxupqakiRURERESFEe+RVI6oiaQgCBgwYAB0dXWlZUlJSRgxYgQMDQ2lZXv37hUjPCIiIiokmEgqR9RE0sPDQ66sX79+IkRCRERERIoSNZEMCAgQ8/BEREREADgiqSy+oZyIiIiIlCLqiCQRERFRXsARSeVwRJKIiIiIlMIRSSIiIiIOSCqFI5JEREREpBSOSBIREVGhx3sklcMRSSIiIiJSCkckiYiIqNDjiKRyCmQiGbG2h9ghFBhm7RaLHUKBEfv3JLFDICKibDCRVA4vbRMRERGRUvJ0Inn16lWxQyAiIqJCQCKRqG1R1NmzZ+Hu7o4SJUpAIpFg//79MtsHDBggd4zWrVvL1ImJiUHfvn1hbGwMU1NTDB48GB8/fpSpExoaikaNGkFPTw82NjZYuHChwrGKnkh+/PgRiYmJMmU3btyAu7s76tatK1JUREREROJISEhA1apVsWrVqmzrtG7dGpGRkdJl+/btMtv79u2LO3fu4NixYzh06BDOnj2LYcOGSbfHx8fD1dUVtra2uHbtGhYtWgQfHx+sW7dOoVhFSySfP38OFxcXmJiYwMTEBBMnTsSnT5/Qv39/1K1bF4aGhggJCRErPCIiIipMJGpcFNSmTRv89ttv6Ny5c7Z1dHV1YW1tLV3MzMyk28LCwnDkyBGsX78edevWRcOGDfH7778jKCgIr169AgAEBgYiJSUF/v7+cHJyQq9evTB27FgsXbpUoVhFSyQnT56MpKQkLF++HA0bNsTy5cvRpEkTGBsb49GjRwgKCuKIJBEREeV7ycnJiI+Pl1mSk5N/qM3Tp0/D0tIS9vb2GDlyJN69eyfdduHCBZiamqJWrVrSspYtW0JDQwOXLl2S1mncuDF0dHSkddzc3HD//n3ExsbmOA7REsmzZ89izZo1GD16NIKCgiAIAvr27YuVK1eiVKlSYoVFREREhZA675H09fWVXoHNXHx9fZWOtXXr1ti8eTNOnDiBBQsW4MyZM2jTpg3S09MBAFFRUbC0tJTZR0tLC0WLFkVUVJS0jpWVlUydzPXMOjkh2vQ/r1+/RtmyZQEAlpaWMDAwQJs2bcQKh4iIiEgtvLy8MHHiRJkyXV1dpdvr1auX9N9VqlSBs7MzypUrh9OnT6NFixZKt6sMUeeR1NDQkPn3l8OrRERERLlFnfNI6urq/lDi+D12dnawsLDAw4cP0aJFC1hbW+PNmzcyddLS0hATEwNra2sAgLW1NV6/fi1TJ3M9s05OiHZpWxAEVKxYEUWLFkXRokXx8eNHVK9eXbqeuRARERGpW16a/kdRL168wLt371C8eHEAgIuLC+Li4nDt2jVpnZMnTyIjI0P6/ImLiwvOnj2L1NRUaZ1jx47B3t5e5sGd7xFtRDIgIECsQxMRERHlWR8/fsTDhw+l60+ePMGNGzekg2yzZ89G165dYW1tjUePHmHKlCkoX7483NzcAACVKlVC69atMXToUPzxxx9ITU3F6NGj0atXL5QoUQIA0KdPH8yePRuDBw/G1KlTcfv2bSxfvhx+fn4KxSpaIunh4SHWoYmIiIhk5aE3JF69ehXNmjWTrmfeX+nh4YE1a9YgNDQUmzZtQlxcHEqUKAFXV1f8+uuvMpfPAwMDMXr0aLRo0QIaGhro2rUrVqxYId1uYmKC4OBgeHp6ombNmrCwsMCsWbNk5prMCYkgCMIPfl6lXL58GTVr1oSmpmaW25OTk3HgwAH06KH4e7OT0n40OsrEd22rDt+1TUT0bXoiPrlhOXin2tp+s0HxXCa/EO0eSRcXF5k5j4yNjfH48WPpelxcHHr37i1GaERERFTI5Od7JMUk6sM231rProyIiIiI8gZRp//5noKexRMREVHewJxDOaKNSBIRERFR/ibqiOTdu3elr+ERBAH37t3Dx48fAQDR0dFihkZERESFCEcklSNqItmiRQuZ+yDbt28P4PMPUxAE/lCJiIgoVzDnUI5oieSTJ0/EOjQRERERqYBoiaStre03t8fFxeGff/75bj0iIiKiH8YBSaXk2Ydtnj17hp9++knsMIiIiIgoG3l6+h8iIiKi3MB7JJWTZ0ckiYiIiChv44gkERERFXockVSOaInkihUrvrn95cuXuRQJERERESlDtETSz8/vu3VKly6dC5EQERFRYccRSeVwHkkiIiIi5pFK4cM2RERERKQUUR+2ycjIwMaNG7F37148ffoUEokEZcuWRbdu3fDTTz9xmJmIiIhyBXMO5Yg2IikIAjp06IAhQ4bg5cuXqFKlCpycnPDs2TMMGDAAnTt3Fis0IiIiIsoB0UYkN27ciLNnz+LEiRNo1qyZzLaTJ0+iU6dO2Lx5M/r37y9ShERERFRYcERSOaKNSG7fvh3Tpk2TSyIBoHnz5vjll18QGBgoQmRERERElBOiJZKhoaFo3bp1ttvbtGmDmzdv5mJEuSdoWyDatGqO2tWroG+v7rgVGip2SKJqULkUds/ujMfbRiDx6CS4u5SXq2NvUxS7fDohau8YRB8Yh3Mr+sGmmBEAoLSVMRKPTspy6dKookw7/Vo54fIaD8T+NR7PdoyCn2eLXPmMeR3PSdVhX6oO+1I12I85I5FI1LYUZKIlkjExMbCyssp2u5WVFWJjY3Mxotxx5PA/WLzQF8NHeSJo1z7Y2ztg5PDBePfundihicZQTxu3Hr/B+JXHs9xetrgJTiztjQfPY+A2eQdqj9gI320XkJSSDgB48fYDyvRaLbPM2XweHz6l4OiV/00zNbZLTcwe0BBLdl5CjWEBaPfLThy/9jQ3PmKexnNSddiXqsO+VA32I6mbaIlkeno6tLSyv0VTU1MTaWlpuRhR7tiyKQBduvVAp85dUa58eczwng09PT3s37tH7NBEE3z1CWZvOo+DIQ+z3D57QCMcvfwY0zecxc1Hb/Ak8j3+vvgIb99/AgBkZAh4HftJZulQvzz2nL2PhKRUAIBpEV14ezTE4EWHsePUPTyJfI/bT6Lx98VHufY58yqek6rDvlQd9qVqsB9zjiOSyhHtYRtBEDBgwADo6upmuT05OTmXI1K/1JQUhN29g8FDh0vLNDQ0UK9efYTe/E/EyPIuiQRoXccOS3ddxsG5XVG1vBWeRb3HoqBL+OtC1oln9fJWqFbeChNWnZCWtahRBhoaEpSwKIL//hwII30dXAx7hV/WncaLtx9y6+PkOTwnVYd9qTrsS9VgPyqoYOd7aiPaiKSHhwcsLS1hYmKS5WJpaZmjJ7aTk5MRHx8vs+TVJDQ2Lhbp6ekwNzeXKTc3N0d0dLRIUeVtlqYGMDLQwaSedXHs6lO4e+3CwfPhCJrVEQ2rlMpyH4/WVRD27B0u3n0lLStrbQINiQRTetXF5D9Ooc9vB2FmpIdDvt2grVV45+XnOak67EvVYV+qBvuRcoNoI5IBAQEqacfX1xezZ8+WKZs+0xszZvmopH0Sl8b/XxI4dOEhft93DQAQ+vgt6jqWwNB2VXHu1guZ+no6WujZzAHzt12UKZdoSKCjrYmfV5/EievPAAAevofwdPtINKlamvdKEhEVcgX9ErS6iPpmG1Xw8vLCxIkTZcoEzawvl4vNzNQMmpqacjc5v3v3DhYWFiJFlbdFxyciNS0dYc9k++z+8xjUdyopV79zo4ow0NVG4PE7MuVRMQkAgHsR/2sn+n0iouMTYWNppIbI8week6rDvlQd9qVqsB8pN4iWSA4aNOi7dSQSCTZs2PDNOrq6unL3WSbl0Wd0tHV0UMnRCZcuXkDzFi0BfH5N5KVLF9Crdz+Ro8ubUtMycO1BFCqWMpMpr1DSDBFv4uXqD3Crgr8vPkL0+0SZ8gt3Xn7er1RRvIz+CAAwM9KDhbE+Il7Lt1NY8JxUHfal6rAvVYP9qBiOSCpHtETyW1P7pKen4/jx40hOTv5uIpnf/OQxEDOnTYWTU2VUruKMrVs2ITExEZ06dxE7NNEY6mmjXAlT6XoZaxM42xVD7IckPH/7AX67rmDLNHecu/0CZ24+h2utsmhbrxzcJu+QaceuhCkaVimFTjPln0Z8+DIWf4WEY/HI5hi9PBjxCSmYM6gR7r+IwZmbz9X9EfM0npOqw75UHfalarAfSd1ESyT37duXZfmBAwcwbdo06OrqYtasWbkclfq1btMWsTExWL1yBaKj38LeoRJWr10P80J8maFGRWsEL+opXV844vPbjrYE38awJUdwMOQhxqw4hsm96mLJyOZ48CIWvX89gJD/H2XM5OFWGS+jP2R7v+PgRYexcHgz7J3TBRmCgHOhz9Fx+h6kpWeo7bPlBzwnVYd9qTrsS9VgP+YcBySVIxEEQRA7CAA4f/48fvnlF1y/fh2jR4/GL7/8AjMzs+/vmIW8emk7PzJrt1jsEAqM2L8niR0CEVGepifikxvlJx1WW9sPF7dRW9tiE33ek7t378Ld3R1NmzZFxYoVcf/+fSxYsEDpJJKIiIhIUZyQXDmiJZLPnz/HwIEDUbVqVWhpaSE0NBQbNmxAqVJZzw1IREREpC4SifqWgky0QWR7e3tIJBJMnDgRDRo0QHh4OMLDw+XqdejQQYToiIiIiOh7REskk5KSAACLFi3CokWLsqwjkUiQnp6em2ERERFRIVTQL0Gri2iJZEZG4X5SloiIiCi/E/1hm+xkZGTg0KFDYodBREREhQDvkVROnntF4sOHD+Hv74+NGzfi7du3SE1NFTskIiIiIspCnhiRTExMxObNm9G4cWPY29sjJCQEs2bNwosXL8QOjYiIiAoBDQ2J2paCTNQRyStXrmD9+vUICgpCuXLl0LdvX4SEhGD16tVwdHQUMzQiIiIi+g7REklnZ2fEx8ejT58+CAkJgZOTEwDgl19+ESskIiIiKqQK+r2M6iLape379++jcePGaNasGUcfiYiISFR8s41yREskHz9+DHt7e4wcORKlSpXCpEmT8N9//xX4DiciIiIqKERLJEuWLInp06fj4cOH2LJlC6KiotCgQQOkpaVh48aNePDggVihERERUSHD6X+Ukyee2m7evDm2bt2KyMhIrFy5EidPnoSDgwOcnZ3FDo2IiIiIspEnEslMJiYmGDVqFK5evYrr16+jadOmYodEREREhQDvkVROnkokv1StWjWsWLFC7DCIiIiIKBuiTf9TvXr172bpEokE165dy6WIiIiIqLAq6COH6iJaItmpUyfpvwVBgK+vL0aMGIGiRYuKFRIRERERKUC0RNLb21tmfcmSJRg3bhzs7OxEioiIiIgKKw5IKkfUVyQSERER5QW8tK2cPPuwDRERERHlbUwkiYiIqNDLSxOSnz17Fu7u7ihRogQkEgn2798v3ZaamoqpU6eiSpUqMDQ0RIkSJdC/f3+8evVKpo0yZcrITUM0f/58mTqhoaFo1KgR9PT0YGNjg4ULFyocq2iXtr+e2ifzjTYWFhYy5WPHjs3NsIiIiIhElZCQgKpVq2LQoEHo0qWLzLZPnz7h+vXrmDlzJqpWrYrY2FiMGzcOHTp0wNWrV2XqzpkzB0OHDpWuGxkZSf8dHx8PV1dXtGzZEn/88Qdu3bqFQYMGwdTUFMOGDctxrKIlkn5+fjLr1tbW2LJli0yZRCJhIklERERql5fukWzTpg3atGmT5TYTExMcO3ZMpmzlypWoU6cOIiIiULp0aWm5kZERrK2ts2wnMDAQKSkp8Pf3h46ODpycnHDjxg0sXbo0fySST548EevQRERERLkmOTkZycnJMmW6urrQ1dVVSfvv37+HRCKBqampTPn8+fPx66+/onTp0ujTpw8mTJgALa3Pqd+FCxfQuHFj6OjoSOu7ublhwYIFiI2NhZmZWY6OLdo9kidPnoSjoyPi4+Pltr1//x5OTk74999/RYiMiIiICht13iPp6+sLExMTmcXX11clcSclJWHq1Kno3bs3jI2NpeVjx45FUFAQTp06heHDh2PevHmYMmWKdHtUVBSsrKxk2spcj4qKyvHxRRuRXLZsGYYOHSrzoTOZmJhg+PDhWLp0KRo1aiRCdERERESq4eXlhYkTJ8qUqWI0MjU1FT169IAgCFizZo3Mti+P5+zsDB0dHQwfPhy+vr4qGwkFRByRvHnzJlq3bp3tdldXV74ekYiIiHLF1084q3LR1dWFsbGxzPKjyVxmEvns2TMcO3Ysy4G5L9WtWxdpaWl4+vQpgM/Pprx+/VqmTuZ6dvdVZkW0RPL169fQ1tbOdruWlhbevn2bixERERER5X2ZSWR4eDiOHz8Oc3Pz7+5z48YNaGhowNLSEgDg4uKCs2fPIjU1VVrn2LFjsLe3z/H9kYCIiWTJkiVx+/btbLeHhoaiePHiuRgRERERFVZ5aR7Jjx8/4saNG7hx4waAzw8o37hxAxEREUhNTUW3bt1w9epVBAYGIj09HVFRUYiKikJKSgqAzw/SLFu2DDdv3sTjx48RGBiICRMmoF+/ftIksU+fPtDR0cHgwYNx584d7NixA8uXL5e7BP89ot0j2bZtW8ycOROtW7eGnp6ezLbExER4e3ujffv2IkVHREREhUlemv7n6tWraNasmXQ9M7nz8PCAj48PDh48CACoVq2azH6nTp1C06ZNoauri6CgIPj4+CA5ORlly5bFhAkTZJJEExMTBAcHw9PTEzVr1oSFhQVmzZql0NQ/ACARBEFQ8nP+kNevX6NGjRrQ1NTE6NGjYW9vDwC4d+8eVq1ahfT0dFy/fl3uiaKcSEpTdbSFl1m7xWKHUGDE/j1J7BCIiPI0PdGGt4C6vmfU1vYlryZqa1tsov3IrKysEBISgpEjR8LLywuZ+axEIoGbmxtWrVqlVBJJREREpKg8NCCZr4g2Ivml2NhYPHz4EIIgoEKFCgrd5JkVjkhSXmRWe7TYIRQIsVdWih0CEamJmCOS9earb0Ty4i8ckVQrMzMz1K5dW+wwiIiIqJDKS/dI5ieiPbVNRERERPlbnhiRJCIiIhITBySVwxFJIiIiIlIKRySJiIio0OM9ksphIklERESFHvNI5fDSNhEREREphSOSREREVOjx0rZyOCJJRERERErhiCQREREVehyRVA5HJImIiIhIKRyRJCIiokKPA5LK4YgkERERESklTyeS9+7dQ8WKFcUOg4iIiAo4iUSitqUgy9OXtpOTk/Ho0SOxwyAiIqICroDne2qTp0ckiYiIiCjvytMjkkRERES5oaBfglYXjkgSERERkVJEHZE0MzP75l8AaWlpuRgNERERFVYckFSOqImkn58fh5KJiIiI8ilRE8kBAwaIeXgiIiIiAIAGB7aUIuo9kpcvX0Z6enq225OTk7Fz585cjIiIiIiIckrURNLFxQXv3r2TrhsbG+Px48fS9bi4OPTu3VuM0IiIiKgQkUjUtxRkol7aFgThm+vZlRERERGpEp/ZUE6en/6HP1giIiKivIkTkhMREVGhp8FxK6WInkjevXsXUVFRAD5fxr537x4+fvwIAIiOjhYzNCIiIiL6BtETyRYtWsjcB9m+fXsAny9pC4LAS9tERESkdsw3lCNqIvnkyRMxD09EREREP0DURNLW1lbMwxMREREBKPjT9KiLqIlkaGhojuo5OzurORIiIiIiUpSoiWS1atWk90IC/7s/4ct7JiUSyTfffkNERET0oyTgkKQyRJ1H8smTJ3j8+LH0//X19XHq1Ck8efJEunz5ppuCImhbINq0ao7a1augb6/uuJXDkVmSx76U1aBGOexeNhyPg+ci8b+VcG8qO5pvqK8Dv6nd8fDIr4i5sBTX90zHkG4NpdvNjA2wdGp33Nw3EzEXluLBP3OwZEo3GBfRk2mnaZ2KOLVxIt6cW4wnx+bht7EdoamZ56elzRU8J1WHfaka7Mec0ZCobynIRP3Nb2trK13KlCkDiUSCUqVKyZQXtPsojxz+B4sX+mL4KE8E7doHe3sHjBw+WOZVkZQz7Et5hvq6uPXgJcb77shy+4Kfu6JVfUcMnL4Z1br8hpWBp+E3tTvaNakCAChezATFi5nAy28fanafh6HeW9GqviP+8O4rbaNKxZLY//tIBIfcRb3e8/HTL/5o16QKfhvbMVc+Y17Gc1J12JeqwX4kdeMQQi7bsikAXbr1QKfOXVGufHnM8J4NPT097N+7R+zQ8h32pbzg83cxe/UhHDyV9YhDvaplsfXQJfx7LRwRkTHw33seoQ9eopbT5z/Y7j6KRO9J6/HP2dt48iIaZ648gM/Kv9C2cWXpiGM31xq4Hf4KvuuO4PHzaJy79hDTl+/H8B6NUMRAN9c+a17Ec1J12JeqwX7MOYlEoralIGMimYtSU1IQdvcO6rnUl5ZpaGigXr36CL35n4iR5T/sS+VcvPkE7ZtUQYliJgCAxrUqoIKtJY5fDMt2H2MjPcQnJCE9PQMAoKujhaTkVJk6icmp0NfTQfVKpdUXfB7Hc1J12JeqwX6k3JDnEklFM/fk5GTEx8fLLMnJyWqK7sfExsUiPT0d5ubmMuXm5uZ8i4+C2JfKmbhgF8IeR+FR8FzEX16Og6tGYfz8nTh//VGW9c1NDeE1tA3894RIy46FhKFeVTv0aF0TGhoSlChmgmnD2gAAihczzpXPkRfxnFQd9qVqsB8VI5GobynIRH1qu3r16jKJY2JiItzd3aGjoyNT7/r169m24evri9mzZ8uUTZ/pjRmzfFQaK1FBMKpXE9SpUgZdx/2BiMgYNKxRHst+6YHIt+9x6tJ9mbpGhnrYt2Ikwh5H4re1f0vLT1y8h2nL9mPFtF7Y8Gt/JKemYf6fR9CwRnlkZAhfH5KIiAowURPJTp06yax37Kj4zfpeXl6YOHGiTJmgmTfv0zIzNYOmpqbcTc7v3r2DhYWFSFHlT+xLxenpamP2GHf0nPgnjpy7AwC4Hf4KzvalMP6nFjKJZBEDXRxcNQofPiWh58Q/kZaWIdPWiq0nsWLrSRQvZoLY+E+wLVEUv47tiCcvCu8oB89J1WFfqgb7UTEaBX3oUE1ETSS9vb1/uA1dXV3o6somjklpP9ysWmjr6KCSoxMuXbyA5i1aAgAyMjJw6dIF9OrdT+To8hf2peK0tTSho62FDEF21DA9PQMaX8xPYWSoh79WeyI5JQ3dxq9Fckr2X6jIt+8BAD1a18LzyBj8d++5eoLPB3hOqg77UjXYj5QbRE0kk5KSEBwcjGbNmsHIyEhmW3x8PE6fPg03Nze5RDE/+8ljIGZOmwonp8qoXMUZW7dsQmJiIjp17iJ2aPkO+1Keob4OytkUk66XKWkO54olERv/Cc+jYnH2ajjmje+ExKRURETGoFHN8ujbvg6mLt0L4HMSeWi1J/T1dDBw+iYYG+rB2PDzHJJvYz9KL11P6N8CwSFhyMjIQMcW1TBpYCv0m+Jf6C9t85xUHfalarAfc44DkspROpF8+/Yt7t//fCnM3t4exYoV+84e8tauXYuDBw+iQ4cOctuMjY2xYsUKREREYPTo0cqGmee0btMWsTExWL1yBaKj38LeoRJWr10Pc15mUBj7Ul4NR1sErx8nXV84qSsAYMvBixjmvRX9f/HHnDEdsXGeB8yMDRARGQOfVYfw565zAIBqDjao41wWAHD3Lx+Ztu3bzkJEZAwAwLWBI6YMcYOuthZuPXiJ7hPWIfj83Vz4hHkbz0nVYV+qBvsx5wr6ND3qIhEEQaEhhISEBIwZMwZbtmyRvrpQU1MT/fv3x++//w4DA4Mct1WnTh3MnDkT7u7uWW4/dOgQ5syZg8uXLysSYp69tE2Fm1ntgvMHkZhir6wUOwQiUhM9Ea+TdgvI/sHeH7V7YA21tS02haf/mThxIs6cOYODBw8iLi4OcXFxOHDgAM6cOYOff/5ZobbCw8NRtWrVbLc7OzsjPDxc0RCJiIiIFMLpf5SjcO6/Z88e7N69G02bNpWWtW3bFvr6+ujRowfWrFmT47bS0tLw9u1blC6d9STGb9++RVoahxeJiIiI8iKFRyQ/ffoEKysruXJLS0t8+vRJobacnJxw/PjxbLcHBwfDyclJ0RCJiIiIFKIhkahtKcgUTiRdXFzg7e2NpKQkaVliYiJmz54NFxcXhdoaNGgQfv31Vxw6dEhu219//YW5c+di0KBBioZIRERERLlA4Uvby5YtQ+vWrVGqVCnp/Y03b96Enp4ejh49qlBbw4YNw9mzZ9GhQwc4ODjA3t4eAHDv3j08ePAAPXr0wLBhwxQNkYiIiEghBXvcUH0UTiSrVKmC8PBwBAYG4t69ewCA3r17o2/fvtDX11c4gK1bt6JDhw7Ytm0bHjx4AEEQYG9vj9mzZ6NHjx4Kt0dEREREuUOhRDI1NRUODg44dOgQhg4dqrIgevTokWXSmJGRgX/++Qft27dX2bGIiIiIvsZ5JJWj0D2S2traMvdGqsvDhw8xbdo0lCpVCp07d1b78YiIiKhw05Cob1HU2bNn4e7ujhIlSkAikWD//v0y2wVBwKxZs1C8eHHo6+ujZcuWctMlxsTEoG/fvjA2NoapqSkGDx6Mjx8/ytQJDQ1Fo0aNoKenBxsbGyxcuFDhWBV+2MbT0xMLFixQ+bQ8iYmJ2Lx5Mxo3bgx7e3uEhIRg1qxZePHihUqPQ0RERJSXJSQkoGrVqli1alWW2xcuXIgVK1bgjz/+wKVLl2BoaAg3NzeZwb6+ffvizp07OHbsGA4dOoSzZ8/KPHcSHx8PV1dX2Nra4tq1a1i0aBF8fHywbt06hWJV+M02nTt3xokTJ1CkSBFUqVIFhoaGMtv37t2rUABXrlzB+vXrERQUhHLlyqFv376YOnUqQkND4ejoqFBbmfhmG8qL+GYb1eCbbYgKLjHfbNNv6021tb21X/YvX/keiUSCffv2oVOnTgA+j0aWKFECP//8MyZNmgQAeP/+PaysrLBx40b06tULYWFhcHR0xJUrV1CrVi0AwJEjR9C2bVu8ePECJUqUwJo1azB9+nRERUVBR0cHAPDLL79g//790mdgckLhEUlTU1N07doVbm5uKFGiBExMTGQWRTg7O6N79+4wNzdHSEgIrl+/jp9//pn3KRAREVGBkZycjPj4eJklOTlZqbaePHmCqKgotGzZUlpmYmKCunXr4sKFCwCACxcuwNTUVJpEAkDLli2hoaGBS5cuSes0btxYmkQCgJubG+7fv4/Y2Ngcx6Nw7h8QEKDoLtm6f/8+evbsiWbNmik9+khERET0o9Q5huXr64vZs2fLlHl7e8PHx0fhtqKiogBA7uUwVlZW0m1RUVGwtLSU2a6lpYWiRYvK1ClbtqxcG5nbzMzMchSPiIPIwOPHj7Fx40aMHDkSiYmJ0mmEOCJJREREBYWXlxcmTpwoU6arqytSNKqVo0SyRo0aOHHiBMzMzFC9evVvJnrXr1/P8cFLliyJ6dOnY/r06Th58iT8/f3RoEEDpKWlYePGjRgyZAgqVqyY4/aIiIiIlKHOQSxdXV2VJY7W1tYAgNevX6N48eLS8tevX6NatWrSOm/evJHZLy0tDTExMdL9ra2t8fr1a5k6meuZdXIiR4lkx44dpR2QebOnqjVv3hzNmzfH+/fvERgYCH9/fyxevBh2dnZ4+PChWo5JRERElJ+ULVsW1tbWOHHihDRxjI+Px6VLlzBy5EgAn19nHRcXh2vXrqFmzZoAgJMnTyIjIwN169aV1pk+fTpSU1Ohra0NADh27Bjs7e1zfFkbUOKp7dySlJSEVatWYdq0aQrfkMqntikv4lPbqsGntokKLjGf2h6wPVRtbW/s7axQ/Y8fP0oH0apXr46lS5eiWbNmKFq0KEqXLo0FCxZg/vz52LRpE8qWLYuZM2ciNDQUd+/ehZ6eHgCgTZs2eP36Nf744w+kpqZi4MCBqFWrFrZt2wbg85Pe9vb2cHV1xdSpU3H79m0MGjQIfn5+Cr2eWqkfWVxcHHbv3o1Hjx5h8uTJKFq0KK5fvw4rKyuULFkyx+0kJyfDx8cHx44dg46ODqZMmYJOnTohICAAM2bMgKamJubMmaNMiEREREQ5lpeez7h69SqaNWsmXc+8v9LDwwMbN27ElClTkJCQgGHDhiEuLg4NGzbEkSNHpEkkAAQGBmL06NFo0aIFNDQ00LVrV6xYsUK63cTEBMHBwfD09ETNmjVhYWGBWbNmKZREAkqMSIaGhqJly5YwMTHB06dPcf/+fdjZ2WHGjBmIiIjA5s2bc9zW1KlTsXbtWrRs2RIhISF4+/YtBg4ciIsXL2LatGno3r07NDU1FfpAAEckKW/iiKRqcESSqOASc0RyYNAttbUd0KuK2toWm8LzSE6cOBEDBgxAeHi4TObbtm1bnD17VqG2du3ahc2bN2P37t0IDg5Geno60tLScPPmTfTq1UupJJKIiIhIURI1LgWZwonklStXMHz4cLnykiVLSucmyqkXL15IbwKtXLkydHV1MWHChDw1vExEREREWVN4EFlXVxfx8fFy5Q8ePECxYsUUais9PV1mRnUtLS0UKVJE0ZCIiIiIfogGB7GUonAi2aFDB8yZMwc7d+4E8Pnm1IiICEydOhVdu3ZVqC1BEDBgwADp1EJJSUkYMWLED7+/m4iIiIjUT+FEcsmSJejWrRssLS2RmJiIJk2aICoqCi4uLpg7d65CbXl4eMis9+vXT9FwiIiIiH4YBySVo3AiaWJigmPHjuHcuXMIDQ3Fx48fUaNGDZmXh+eUKt/bTURERES5S+kH7Rs2bIiGDRuqMhYiIiIiUfBBX+XkKJH8cgLL7xk7dqzSwRARERFR/pGjRNLPz09m/e3bt/j06RNMTU0BfH7TjYGBASwtLZlIEhERUb7DAUnl5GgeySdPnkiXuXPnolq1aggLC0NMTAxiYmIQFhaGGjVq4Ndff1V3vEREREQqpyGRqG0pyBSekHzmzJn4/fffYW9vLy2zt7eHn58fZsyYodLgiIiIiCjvUvhhm8jISKSlyb/MOj09Ha9fv1ZJUERERES5qYAPHKqNwiOSLVq0wPDhw3H9+nVp2bVr1zBy5EilpgAiIiIiovxJ4UTS398f1tbWqFWrFnR1daGrq4s6derAysoK69evV0eMRERERGolkUjUthRkCl/aLlasGP755x88ePAA9+7dAwA4ODigYsWKKg+OiIiIiPIupSckr1ixIpNHIgXEXlkpdggFgpm73/crUY7E/jVB7BCI8gyFL9ESACUTyRcvXuDgwYOIiIhASkqKzLalS5eqJDAiIiIiytsUTiRPnDiBDh06wM7ODvfu3UPlypXx9OlTCIKAGjVqqCNGIiIiIrUq6PcyqovCI7leXl6YNGkSbt26BT09PezZswfPnz9HkyZN0L17d3XESERERKRWGhL1LQWZwolkWFgY+vfvDwDQ0tJCYmIiihQpgjlz5mDBggUqD5CIiIiI8iaFE0lDQ0PpfZHFixfHo0ePpNuio6NVFxkRERFRLuGIpHIUvkeyXr16OHfuHCpVqoS2bdvi559/xq1bt7B3717Uq1dPHTESERERUR6kcCK5dOlSfPz4EQAwe/ZsfPz4ETt27ECFChX4xDYRERHlS3zYRjkKJ5J2dnbSfxsaGuKPP/5QaUBERERElD8oPSE5ERERUUFR0O9lVJccJZJmZmY5HvKNiYn5oYCIiIiIKH/IUSK5bNky6b/fvXuH3377DW5ubnBxcQEAXLhwAUePHsXMmTPVEiQRERGROvEWSeXkKJH08PCQ/rtr166YM2cORo8eLS0bO3YsVq5ciePHj2PCBL67lYiIiPIXDWaSSlF4HsmjR4+idevWcuWtW7fG8ePHVRLUl27fvq3yNomIiIjoxymcSJqbm+PAgQNy5QcOHIC5ublKgvrw4QPWrVuHOnXqoGrVqippk4iIiCg7GmpcCjKFn9qePXs2hgwZgtOnT6Nu3boAgEuXLuHIkSP4888/fyiYs2fPYsOGDdizZw9KlCiBLl26YNWqVT/UJhERERGph8KJ5IABA1CpUiWsWLECe/fuBQBUqlQJ586dkyaWioiKisLGjRuxYcMGxMfHo0ePHkhOTsb+/fvh6OiocHtEREREiuItkspRKJFMTU3F8OHDMXPmTAQGBv7wwd3d3XH27Fm0a9cOy5YtQ+vWraGpqclJzomIiIjyAYUu3Wtra2PPnj0qO/jhw4cxePBgzJ49G+3atYOmpqbK2iYiIiLKKQ2JRG1LQabwPaCdOnXC/v37VXLwc+fO4cOHD6hZsybq1q2LlStXIjo6WiVtExEREZF6KXyPZIUKFTBnzhycP38eNWvWhKGhocz2sWPH5ritevXqoV69eli2bBl27NgBf39/TJw4ERkZGTh27BhsbGxgZGSkaIhERERECingA4dqIxEEQVBkh7Jly2bfmESCx48f/1BA9+/fx4YNG7BlyxbExcWhVatWOHjwoEJtJKX9UAhElIeZufuJHUKBEfsXXyBBeYuewsNbquMTHK6+tl0rqK1tsSn8I3vy5Ik64pCyt7fHwoUL4evri7/++gv+/v5qPR4RERERKUfpeTJTUlJw//59pKUpP/yXnp6O0NBQJCYmZtm+nZ0d9u3bp3T7RERERDnBh22Uo3Ai+enTJwwePBgGBgZwcnJCREQEAGDMmDGYP3++Qm1t2bIFgwYNgo6Ojtw2bW1tDBo0CNu3b1c0RCIiIiLKBQonkl5eXrh58yZOnz4NPT09aXnLli2xY8cOhdrasGEDJk2alOW0P1paWpgyZQrWrVunaIhERERECpFI1LcUZArfI7l//37s2LED9erVg+SL3nFycsKjR48Uauv+/fuoV69etttr166NsLAwRUMkIiIiolygcCL59u1bWFpaypUnJCTIJJY5kZCQgPj4+Gy3f/jwAZ8+fVI0RCIiIiKFaBTwkUN1UfjSdq1atfD3339L1zOTx/Xr18PFxUWhtipUqICQkJBst587dw4VKhTcR+aJiIiI8rMcj0jevn0blStXhq+vL1q3bo27d+8iNTUVy5cvx927dxESEoIzZ84odPA+ffpgxowZqF+/PpydnWW23bx5E7NmzcKUKVMUapOIiIhIURJwSFIZOU4knZ2dUbt2bQwZMgTnz5/H77//DmdnZwQHB6NGjRq4cOECqlSpotDBJ0yYgMOHD6NmzZpo2bIlHBwcAAD37t3D8ePH0aBBA0yYwAlziYiISL14aVs5OU4kz5w5g4CAAPz888/IyMhA165dsXjxYjRu3Fjpg2trayM4OBh+fn7Ytm0bzp49C0EQULFiRcydOxfjx4+Htra20u0TERERkfoo/IrEhIQE7Ny5Exs3bsS///6L8uXLY/DgwfDw8IC1tbW64lQIX5FIVHDxFYmqw1ckUl4j5isSF55SbOYZRUxpVk5tbYtN4YdtDA0NMXDgQJw5cwYPHjxA9+7dsWrVKpQuXRodOnRQR4wFTtC2QLRp1Ry1q1dB317dcSs0VOyQ8i32pWqwH2U1qFwSu3064vHWoUg8PAHuLvL/EbC3KYpd3h0QtXsUoveNxrnlvWFTzEimTl2H4jjs2xXR+0bj9Z5ROLawO/R0Ps+bW9rSGGvGt0JYwCDE7B+DO/4DMaOfC7S1lH7hWIHD81I12I+kTj/0G6t8+fKYNm0aZsyYASMjI5mnuXPCzMwMRYsW/e5SkBw5/A8WL/TF8FGeCNq1D/b2Dhg5fDDevXsndmj5DvtSNdiP8gz1tHHr8VuMX30yy+1li5vgxOIeePA8Fm5Td6H2qC3w3XYJSSn/uxxS16E4DvzWGSeuR6DRuO1oOHY7/vjrJjL+/xqQvY0ZNCQSjP79OGqM2Iwpa89gSNsqmDOgQW58xDyP56VqsB9zTiKRqG0pyBS+tJ3p7Nmz8Pf3x549e6ChoYEePXpg8ODB35xg/GubNm3KUT0PDw+FYsvLl7b79uoOp8pVMG3GLABARkYGXFs0Qe8+P2Hw0GEiR5e/sC9VI7/1Y25f2k48PAE95hzEXxf+d9lr8y9tkZqWgcGLj2S73xm/Xjhx/RnmbLmQ42NN6FoTQ9tVheMg/x+KOafy8qXt/HZe5lX5rR/FvLS96PRjtbU9uamd2toWm0I/slevXmHjxo3YuHEjHj58iPr162PFihXo0aMHDA0NFT64oglifpeakoKwu3cweOhwaZmGhgbq1auP0Jv/iRhZ/sO+VA32o+IkEqB17bJYuvsqDv7WGVXLWeJZ1Hss2nlFmmwWM9FHHYfiCDp1D6eW9ETZ4iZ48CIWPpvOI+TOq2zbNjbURcyHpNz6KHkWz0vVYD8qhk9tKyfHl7bbtGkDW1tb/P777+jcuTPCwsJw7tw5DBw4UKkkUlWSk5MRHx8vsyQnJ4sWz7fExsUiPT0d5ubmMuXm5uaIjo4WKar8iX2pGuxHxVmaGsDIQAeTetTGsatP4T59Lw6GPELQDHc0rFISwOdL3wAwvW89+B+5hY4z9+HGwzf4x7crypUwzbJdu+ImGNmhGjYc5v1rPC9Vg/2YP5UpUybLy+Oenp4AgKZNm8ptGzFihEwbERERaNeuHQwMDGBpaYnJkycjLU09l2tzPCKpra2N3bt3o3379tDU1FTJwcuWLfvdewckEsk33+Ht6+uL2bNny5RNn+mNGbN8VBEiEZEMjf//nXXowiP8vv/zqE7o47eo61gcQ9s649ytl9I6G/65hS3H7gIAbj46g6bVbODh6oRZG8/LtFnC3BAHf+uCvf8+QMCR27n4aYgoU165lfHKlStIT0+Xrt++fRutWrVC9+7dpWVDhw7FnDlzpOsGBgbSf6enp6Ndu3awtrZGSEgIIiMj0b9/f2hra2PevHkqjzfHieTBgwdVfvDx48dnu+3p06dYu3btd0cXvby8MHHiRJkyQVNXFeGpnJmpGTQ1NeVucn737h0sLCxEiip/Yl+qBvtRcdHxiUhNS0dYhGyf3X8eg/qOn0ckI2MSAEC+TkQMbCxln+wuXtQQR+Z3x8W7r+C54rgaI88/eF6qBvtRMRp5JJMsVqyYzPr8+fNRrlw5NGnSRFpmYGCQ7ZSLwcHBuHv3Lo4fPw4rKytUq1YNv/76K6ZOnQofHx/o6OioNF5R55kYN26c3PLTTz/h6dOnWLNmDWrXro3z589/sw1dXV0YGxvLLLq6eTOR1NbRQSVHJ1y6+L+b7zMyMnDp0gU4V60uYmT5D/tSNdiPiktNy8C1B69RsZTsjBIVSpoh4k08AODZ63i8iv6IiqXMZOqUL2WGiNcfpOslzA1xdEF3/PfwNYb5BUO5Rx8LHp6XqsF+zDuUvQ0vJSUFW7duxaBBg2Su4AYGBsLCwgKVK1eGl5cXPn36JN2W+aZBKysraZmbmxvi4+Nx584d1X4wKPiwjTolJiZi6dKlWLx4MWxtbbF37160bdtW7LBU7iePgZg5bSqcnCqjchVnbN2yCYmJiejUuYvYoeU77EvVYD/KM9TTlrmXsYyVMZztiiH2QxKev/0Avz1XseWXdjh3+wXO3HwO11pl0LauHdym7pLu47fnKmb0c8GtJ9G4+egN+rV0hH2pougz9xCA/yWREW8+wGv9WRQz0Zfu+zr2f/9RKKx4XqoG+zHn1PmwTVa34Xl7e8PHx+eb++3fvx9xcXEYMGCAtKxPnz6wtbVFiRIlEBoaiqlTp+L+/fvYu3cvACAqKkomiQQgXY+KivrxD/MV0RPJ9PR0/Pnnn5g9ezb09PSwYsUK9OvXr8DOu9S6TVvExsRg9coViI5+C3uHSli9dj3MeZlBYexL1WA/yqtRwQrBC/93P9LC4U0BAFuO3cGwpcE4GPIIY1aewOQetbFkRDM8eBGD3r/9JfNE9sr9/0FPWwsLhzWBmZEebj1+i/bT9+BJ5HsAQPPqtihf0gzlS5rh0VbZaVj02/DtPTwvVYP9mDdkdRteTq6ebtiwAW3atEGJEiWkZcOG/e/3RZUqVVC8eHG0aNECjx49Qrlyuf8GHaXnkVSFnTt3YsaMGYiLi8P06dMxcuRIlVy7z8vzSBLRj+ErElUnL88jSYWTmPNI/n7+idraHtOgrML7PHv2DHZ2dti7dy86duyYbb2EhAQUKVIER44cgZubG2bNmoWDBw/ixo0b0jpPnjyBnZ0drl+/jurVVXtbg6gjkr169YK+vj569+6NZ8+e4Zdffsmy3tKlS3M5MiIiIiLxBAQEwNLSEu3atftmvcyEsXjx4gAAFxcXzJ07F2/evIGlpSUA4NixYzA2Noajo6PK4xQ1kWzcuPF3p/cpqJe4iYiIKO/QQN7JNzIyMhAQEAAPDw9oaf0vVXv06BG2bduGtm3bwtzcHKGhoZgwYQIaN24MZ2dnAICrqyscHR3x008/YeHChYiKisKMGTPg6emploeRRU0kT58+LebhiYiIiPKc48ePIyIiAoMGDZIp19HRwfHjx7Fs2TIkJCTAxsYGXbt2xYwZM6R1NDU1cejQIYwcORIuLi4wNDSEh4eHzLyTqiT6wzZfypxpn/NbERERUW7KSxdAXV1dkdUjLDY2Njhz5sx397e1tcU///yjjtDkiDqPJADExcXB09MTFhYWsLKygpWVFSwsLDB69GjExcWJHR4REREVAhoS9S0FmagjkjExMXBxccHLly/Rt29fVKpUCQBw9+5dbNy4ESdOnEBISAjMzMy+0xIRERER5TZRE8k5c+ZAR0cHjx49kps8c86cOXB1dcWcOXPg58fpPoiIiEh98sorEvMbUS9t79+/H4sXL5ZLIgHA2toaCxcuxL59+0SIjIiIiIi+R9QRycjISDg5OWW7vXLlymp5nQ8RERHRlzggqRxRRyQtLCzw9OnTbLc/efIERYsWzb2AiIiIiCjHRE0k3dzcMH36dKSkpMhtS05OxsyZM9G6dWsRIiMiIqLCREMiUdtSkIn+sE2tWrVQoUIFeHp6wsHBAYIgICwsDKtXr0ZycjK2bNkiZohERERElA1RE8lSpUohJCQEnp6e8PLykk6+KZFI0KpVK6xcuRI2NjZihkhERESFQAEfOFQb0d9sY2dnh8OHDyM2Nhbh4eEAgPLly/PeSCIiIso1or+hJZ8SNZH8+h2S2fH391dzJERERESkKFETyY0bN8LW1hbVq1fP8p2SRERERLlBwmvbShE1kRw5ciS2b9+OJ0+eYODAgejXrx8vaRMRERHlE6LeErBq1SpERkZiypQp+Ouvv2BjY4MePXrg6NGjHKEkIiKiXCNR41KQiX5vqa6uLnr37o1jx47h7t27cHJywqhRo1CmTBl8/PhR7PCIiIiIKBuiP7X9JQ0NDUgkEgiCgPT0dLHDISIiokKioE8cri6ij0gmJydj+/btaNWqFSpWrIhbt25h5cqViIiIQJEiRcQOj4iIiIiyIeqI5KhRoxAUFAQbGxsMGjQI27dvh4WFhZghERERUSHE8UjliJpI/vHHHyhdujTs7Oxw5swZnDlzJst6e/fuzeXIiIiIqDDhlW3liJpI9u/fn/M2EREREeVTok9ITkRERCQ2DmwpR/SHbYiIiIgof8pT0/8QERERiYEja8phvxERERGRUjgiSURERIUe75FUDkckiYiIiEgpHJEkIiKiQo/jkcrhiCQRERERKYUjkkRERFTo8R5J5TCRJKJ8JfavCWKHUGCY1RkrdggFRuzlFWKHQD+Il2iVw34jIiIiIqVwRJKIiIgKPV7aVg5HJImIiIhIKRyRJCIiokKP45HK4YgkERERESmFI5JERERU6PEWSeVwRJKIiIiIlMIRSSIiIir0NHiXpFKYSBIREVGhx0vbyuGlbSIiIiJSCkckiYiIqNCT8NK2UjgiSURERERK4YgkERERFXq8R1I5HJEkIiIiIqVwRJKIiIgKPU7/oxyOSBIRERGRUjgiSURERIUe75FUDhNJIiIiKvSYSCqHl7aJiIiISCkckSQiIqJCjxOSK4cjkkRERESkFI5IEhERUaGnwQFJpeTJEclnz57h7t27yMjIEDsUIiIiIsqGqImkv78/li5dKlM2bNgw2NnZoUqVKqhcuTKeP38uUnRERERUWEjU+D9F+Pj4QCKRyCwODg7S7UlJSfD09IS5uTmKFCmCrl274vXr1zJtREREoF27djAwMIClpSUmT56MtLQ0lfTT10RNJNetWwczMzPp+pEjRxAQEIDNmzfjypUrMDU1xezZs0WMkIiIiCh3OTk5ITIyUrqcO3dOum3ChAn466+/sGvXLpw5cwavXr1Cly5dpNvT09PRrl07pKSkICQkBJs2bcLGjRsxa9YstcQq6j2S4eHhqFWrlnT9wIED6NixI/r27QsAmDdvHgYOHChWeERERFRIqHMeyeTkZCQnJ8uU6erqQldXN8v6WlpasLa2lit///49NmzYgG3btqF58+YAgICAAFSqVAkXL15EvXr1EBwcjLt37+L48eOwsrJCtWrV8Ouvv2Lq1Knw8fGBjo6OSj+bqCOSiYmJMDY2lq6HhISgcePG0nU7OztERUWJERoREREVIuq8tO3r6wsTExOZxdfXN9tYwsPDUaJECdjZ2aFv376IiIgAAFy7dg2pqalo2bKltK6DgwNKly6NCxcuAAAuXLiAKlWqwMrKSlrHzc0N8fHxuHPnjsr7TdQRSVtbW1y7dg22traIjo7GnTt30KBBA+n2qKgomJiYiBghERER0Y/x8vLCxIkTZcqyG42sW7cuNm7cCHt7e0RGRmL27Nlo1KgRbt++jaioKOjo6MDU1FRmHysrK+nAW1RUlEwSmbk9c5uqiZpIenh4wNPTE3fu3MHJkyfh4OCAmjVrSreHhISgcuXKIkZIREREhYE6p//51mXsr7Vp00b6b2dnZ9StWxe2trbYuXMn9PX11RWi0kS9tD1lyhQMHToUe/fuhZ6eHnbt2iWz/fz58+jdu7dI0RERERGJy9TUFBUrVsTDhw9hbW2NlJQUxMXFydR5/fq19J5Ka2truae4M9ezuu/yR4maSGpoaGDOnDn477//cPjwYVSqVElm+65duzB48GCRoiMiIqLCIq9M//O1jx8/4tGjRyhevDhq1qwJbW1tnDhxQrr9/v37iIiIgIuLCwDAxcUFt27dwps3b6R1jh07BmNjYzg6Ov5QLFnJc2+2SUpKwo4dO5CQkABXV1eUL19e7JCIiIiIcsWkSZPg7u4OW1tbvHr1Ct7e3tDU1ETv3r1hYmKCwYMHY+LEiShatCiMjY0xZswYuLi4oF69egAAV1dXODo64qeffsLChQsRFRWFGTNmwNPTM8eX1xUh6ojkxIkTMWbMGOl6SkoKXFxcMHToUEybNg3VqlWTPoVUkARtC0SbVs1Ru3oV9O3VHbdCQ8UOKd9iX6oG+1F12JeyGtQoh93LhuHx0V+ReH0F3JtWkdluqK8Dv6nd8PDwHMSELMb13dMwpOv/Hro0MzbA0ildcXPvdMSELMaDv32wZHJXGBfRk2nHxtoMe5cPx7vzi/Hs+FzMG98Rmpp58uVtuY7nZM5IJOpbFPHixQv07t0b9vb26NGjB8zNzXHx4kUUK1YMAODn54f27duja9euaNy4MaytrbF3717p/pqamjh06BA0NTXh4uKCfv36oX///pgzZ44qu0tK1G9ZcHAwWrVqJV0PDAzEs2fPEB4ejtjYWHTv3h2//fabiBGq3pHD/2DxQl8MH+WJoF37YG/vgJHDB+Pdu3dih5bvsC9Vg/2oOuxLeYZ6Orj14CXGz9+V5fYFP3dGq/qVMHDGZlTrOg8rt52G39RuaNf484OWxYuZoHgxE3gtO4CaPeZjqE8gWtWvhD9m9ZG2oaEhwd7lw6GjrYlmA/0wdNZW9HOvi1kj2+bKZ8zLeE7mP0FBQXj16hWSk5Px4sULBAUFoVy5ctLtenp6WLVqFWJiYpCQkIC9e/fK3ftoa2uLf/75B58+fcLbt2+xePFiaGmp5yK0qIlkRESEzPX64OBgdOvWDba2tpBIJBg3bhz+++8/ESNUvS2bAtClWw906twV5cqXxwzv2dDT08P+vXvEDi3fYV+qBvtRddiX8oJDwjB79d84eCrrUbB6zmWx9a/L+PfaQ0RExsB/bwhCw1+hVmVbAMDdR5HoPdkf/5y9jScvonHmSjh8Vh1C28aVpSOOLes5oJKdNQbN2ILQBy8RHBKGOav/xvDujaCtpZlrnzUv4jmZcxI1LgWZ6A/bCIIgXc+clT2TqakpYmNjxQhNLVJTUhB29w7qudSXlmloaKBevfoIvVmwEmZ1Y1+qBvtRddiXyrkY+gTtm1RGiWKf5wxuXKsCKpQuhuMX72W7j3ERfcQnJCE9PQMAUNe5LG4/fIU3MR+kdY5dCIOJkT4cyxVX7wfIw3hOKkZDIlHbUpCJmkhWqlQJf/31FwDgzp07iIiIQLNmzaTbnz17Jjep5teSk5MRHx8vs3z9GqK8IjYuFunp6TA3N5cpNzc3R3R0tEhR5U/sS9VgP6oO+1I5ExfsQdjjKDw6+iviL/nh4MqRGD9/F85ff5RlfXNTQ3gNdYP/3vPSMisLI5kkEoB03crcSH3B53E8Jyk3iD6PpJeXF1q0aIEWLVqgbdu2KFu2rHT7P//8gzp16nyzjaxeO7RoQfavHSIiorxjVK/GqFOlDLqOX4f6/RbhF799WPZLdzSrU1GurpGhHvYtH46wx1H4be1hEaKlgoyXtpUj6vQ/nTt3xj///INDhw7B1dVV5gluADAwMMCoUaO+2UZWrx0SNFX/eLsqmJmaQVNTU+4m53fv3sHCwkKkqPIn9qVqsB9Vh32pOD1dbcwe3R49f16PI+fuAgBuh7+Cc8VSGN+/BU5dfiCtW8RAFwdXjsSHT8no+fN6pKVlSLe9jv6AWk62Mm1bFv08Evn6nexIZWHCc5Jyg+hzI7Ro0QJ+fn6YOnUqDAwMZLZ5e3ujadOm39xfV1cXxsbGMos65klSBW0dHVRydMKli/+b0igjIwOXLl2Ac9XqIkaW/7AvVYP9qDrsS8Vpa2lCR1sLGRmCTHl6RobMfWVGhno4tHoUUlLT0G3COiSnpMnUvxT6BJXLl0AxsyLSshb1HPD+QyLCHqv+3cL5Bc9JBXFIUil5YkLyK1euYPv27Xjw4PNfnxUrVkSfPn1Qq1YtkSNTvZ88BmLmtKlwcqqMylWcsXXLJiQmJqJT5y5ih5bvsC9Vg/2oOuxLeYb6OihnU0y6XqakOZwrlkRs/Cc8j4rF2avhmDe+IxKTUxERGYNGNcujb7vamLp0P4D/JZH6etoYOGMLjA31YGz4eQ7Jt7EfkZEh4PjFewh7HIUNv/2E6csOwMrCGN6j2mHtrn+RkpqWVViFBs9JUjeJ8OVj0yKYMmUKFi9ejCJFisDOzg4A8OjRI3z69AmTJk3CggULFG4zKY//3tgeuBWbAjYgOvot7B0qYeq0GXB2rip2WPkS+1I12I+qk5/60qzOWLUfo1HN8gj+U/44Ww5ewjCfQFiZG2HOGHe0rOcAM2MDRETGwn9vCFYEnvrm/gBg384HEZExAIDSxc2w3KsHGtesgISkFAT+dQkzfv9L+mS3usVeXpErx1FGfjon9UQc3rr06L3a2q5bzkRtbYtN1ERy06ZNGDFiBBYtWoThw4dDW1sbAJCamoo1a9Zg6tSpWLt2Lfr3769Qu3k9kSQiygtyI5EsLPJyIpmfMJHMf0S9tL1q1SrMmzcPo0ePlinX1tbG2LFjkZaWhpUrVyqcSBIREREpooBP96g2oj5sc+fOHXTs2DHb7Z06dcKdO3dyMSIiIiIqjPisjXJETSQ1NTWRkpKS7fbU1FRoahbu11sRERER5VWiJpI1atRAYGBgttu3bNmCGjVq5GJEREREVChxSFIpot4jOWnSJHTq1AnJycn4+eefpa9DjIqKwpIlS7Bs2TLs27dPzBCJiIiIKBuiJpLt27eHn58fJk2ahCVLlsDE5PNTTe/fv4eWlhYWL16M9u3bixkiERERFQKSgj50qCaiT0g+ZswYdOrUCbt370Z4eDiAzxOSd+3aFTY2NkhMTIS+vr7IURIRERHR10RPJAHAxsYGEyZMkClLTk7G0qVLsXDhQkRFFd5XXBEREZH6cfof5Yj6sE1ycjK8vLxQq1Yt1K9fH/v37wcABAQEoGzZsvDz85NLMImIiIgobxB1RHLWrFlYu3YtWrZsiZCQEHTv3h0DBw7ExYsXsXTpUnTv3p3T/xAREZHacUBSOaImkrt27cLmzZvRoUMH3L59G87OzkhLS8PNmzch4RgzERER5RamHUoR9dL2ixcvULNmTQBA5cqVoauriwkTJjCJJCIiIsoHRB2RTE9Ph46OjnRdS0sLRYoUETEiIiIiKow4/Y9yRE0kBUHAgAEDoKurCwBISkrCiBEjYGhoKFNv7969YoRHRERERN8gaiLp4eEhs96vXz+RIiEiIqLCjHfVKUfURDIgIEDMwxMRERHRD8gTE5ITERERiYkDksoR9altIiIiIsq/OCJJRERExCFJpTCRJCIiokKP0/8oh5e2iYiIiEgpHJEkIiKiQo/T/yiHI5JEREREpBSOSBIREVGhxwFJ5XBEkoiIiIiUwhFJIiIiIg5JKoUjkkRERESkFI5IEhERUaHHeSSVwxFJIiIiIlIKRySJiIio0OM8ksphIklERESFHvNI5fDSNhEREREphSOSRERERBySVIpEEARB7CBULSlN7AiIiKgwMeu0UuwQCoTEQ6NFO3ZYZILa2q5U3FBtbYuNI5JERERU6HH6H+XwHkkiIiIiUgpHJImIiKjQ4/Q/yuGIJBEREREphSOSREREVOhxQFI5TCSJiIiImEkqhZe2iYiIiEgpHJEkIiKiQo/T/yiHI5JEREREpBQmkkRERFToSSTqWxTh6+uL2rVrw8jICJaWlujUqRPu378vU6dp06aQSCQyy4gRI2TqREREoF27djAwMIClpSUmT56MtDTVv/qPl7aJiIiI8ogzZ87A09MTtWvXRlpaGqZNmwZXV1fcvXsXhob/e9Xi0KFDMWfOHOm6gYGB9N/p6elo164drK2tERISgsjISPTv3x/a2tqYN2+eSuNlIklERESFXl65Q/LIkSMy6xs3boSlpSWuXbuGxo0bS8sNDAxgbW2dZRvBwcG4e/cujh8/DisrK1SrVg2//vorpk6dCh8fH+jo6KgsXl7aJiIiIlKj5ORkxMfHyyzJyck52vf9+/cAgKJFi8qUBwYGwsLCApUrV4aXlxc+ffok3XbhwgVUqVIFVlZW0jI3NzfEx8fjzp07KvhE/8NEkoiIiEiivsXX1xcmJiYyi6+v73dDysjIwPjx49GgQQNUrlxZWt6nTx9s3boVp06dgpeXF7Zs2YJ+/fpJt0dFRckkkQCk61FRUQp3zbfw0jYREREVeuqc/sfLywsTJ06UKdPV1f3ufp6enrh9+zbOnTsnUz5s2DDpv6tUqYLixYujRYsWePToEcqVK6eaoHOII5JEREREaqSrqwtjY2OZ5XuJ5OjRo3Ho0CGcOnUKpUqV+mbdunXrAgAePnwIALC2tsbr169l6mSuZ3dfpbKYSBIREVGhl1em/xEEAaNHj8a+fftw8uRJlC1b9rv73LhxAwBQvHhxAICLiwtu3bqFN2/eSOscO3YMxsbGcHR0VCyg7+ClbSIiIqI8wtPTE9u2bcOBAwdgZGQkvafRxMQE+vr6ePToEbZt24a2bdvC3NwcoaGhmDBhAho3bgxnZ2cAgKurKxwdHfHTTz9h4cKFiIqKwowZM+Dp6ZmjS+qKkAiCIKi0xTwgSfXzbRIREWXLrNNKsUMoEBIPjRbt2E+jk9TWdhkLvRzXlWQzhBkQEIABAwbg+fPn6NevH27fvo2EhATY2Nigc+fOmDFjBoyNjaX1nz17hpEjR+L06dMwNDSEh4cH5s+fDy0t1Y4hMpEkIiL6QUwkVYOJZP7DS9tEREREeWVG8nyGD9sQERERkVI4IklERESFnjrnkSzIRBmR7NGjB2JjY8U4NBEREZGcvDL9T34jSiL54sULODk54e+//xbj8ERERESkAqIkkufPn8eECRPQvXt3DBkyBB8/fhQjDCIiIiIAan3VdoEm6vQ/9+7dw8CBAxEVFYUxY8bIzW00duxYpdrl9D9ERJSbOP2Paog5/c/zmGS1tW1TVLWTgOclos8juX79eowYMQLFixeXSSQlEgkeP36sVJtMJImIKDcxkVQNMRPJF7HqSyRLmRXcRFK0p7Zfv36NIUOG4Ny5c9iwYQM8PDzECoWIiIiIlCDKPZJBQUFwcnJCYmIibt68ySSSiIiIRMa7JJUhSiI5ePBgeHt74/jx4yhdurQYIRARERHRDxLl0vaNGzdQoUIFMQ5NREREJKegz/eoLqKMSPr5+clM+bN9+3YkJCRI1+Pi4tC2bVsxQssVQdsC0aZVc9SuXgV9e3XHrdBQsUPKt9iXqsF+VB32peqwL2U1cCqB3bPa4fGmgUg8NBru9crK1bEvZYZdM9shasdQRO8ejnNLu8OmWJEs29vv4y7XTpWy5tg02RXhAR6I2TMC/63pA88Ozmr7THkJL2wrR5REcu3atfj06ZN0ffjw4Xj9+rV0PTk5GUePHhUjNLU7cvgfLF7oi+GjPBG0ax/s7R0wcvhgvHv3TuzQ8h32pWqwH1WHfak67Et5hnpauPU4GuP/OJPl9rLWxjixsCsevIiFm9c+1B69Hb5BV5CUki5Xd0zHqhAgP2lL9fKWePs+EQOXHEONUduwYMdVzOnvghHtq6j881DBIEoi+fWMQyLPQJSrtmwKQJduPdCpc1eUK18eM7xnQ09PD/v37hE7tHyHfaka7EfVYV+qDvtSXvC1CMzeegkHL2Q9Nd7s/vVw9OpTTA8Iwc3H0XgSFY+/Lz/F2/eJMvWcy1pgXOfqGLHspFwbm4+FYdK6f3Hu9is8fR2PoNMPsPl4GDq6lFPLZ8pL+IpE5YiSSBZWqSkpCLt7B/Vc6kvLNDQ0UK9efYTe/E/EyPIf9qVqsB9Vh32pOuxLxUkkQOtaZRD+Kg4H53TAs62DcHZJN7nL3/q6Wtg42RXj15zB67hP2bQmy8RQF7Efk9QRNhUA+T6RTE5ORnx8vMySnKy+SUV/RGxcLNLT02Fubi5Tbm5ujujoaJGiyp/Yl6rBflQd9qXqsC8VZ2liACMDHUzqVhPHrj2D+8yDOHjhMYKmtUXDyiWk9RYOaYiLYZE4dOlJjtqt52CNbo3KY8ORO+oKPc+QqPF/BZloE5LPmjULBgYGAICUlBTMnTsXJiYmACBz/+T3+Pr6Yvbs2TJl02d6Y8YsH5XFSkRElJdpaHxOVg5dfILfD9wEAIQ+iUbdSsUxtE1lnLv9Cu3qlEHTqqVQb+yOHLXpaFsUO2e2w9ztV3Div+dqi53yN1ESycaNG+P+/fvS9fr168u9DrFx48Y5asvLywsTJ06UKRM08+ariMxMzaCpqSl3s/i7d+9gYWEhUlT5E/tSNdiPqsO+VB32peKi4xORmpaOsOcxMuX3n8egvuPnEcmmVUvBztoEUTuGytTZ7tUG5+9Gws1rn7TMwcYM//zWCf5H7mDBjqvq/wB5QcEeOFQbURLJ06dPq6wtXV1d6OrKJo559V3b2jo6qOTohEsXL6B5i5YAgIyMDFy6dAG9evcTObr8hX2pGuxH1WFfqg77UnGpaRm4Fv4GFUuaypRXKGmKiDcfAACLd11HQPBdme3XVvXBlPXn8Pfl/13qrlS6KA7P7YTAk/fgs+Wi2mOn/E20S9tfyrznpTD8pfmTx0DMnDYVTk6VUbmKM7Zu2YTExER06txF7NDyHfalarAfVYd9qTrsS3mGetooV9xEul7GyhjOZS0Q+zEJz99+hN/e/7BlihvO3XmFM6Ev4VqzNNrWKSsdaXwd9ynLB2yev/2AZ68/J5uOtp+TyOPXI7Bi3w1YmX6+BS09IwPR8QX7gRsOSCpHtEQyLi4O06dPx44dOxAbGwsAMDMzQ69evfDbb7/B1NRUrNDUqnWbtoiNicHqlSsQHf0W9g6VsHrtepgXgiRa1diXqsF+VB32peqwL+XVqGCJYN/O0vWFQxsBALYcD8OwZSdw8MJjjFl9GpO718SSYY3x4GUses87jJC7kTk+RucG5WFpaoA+zR3Qp7mDtPzZ63g4DN6sug+TBxX0aXrURSKIMIljTEwMXFxc8PLlS/Tt2xeVKlUCANy9exfbtm2DjY0NQkJCYGZmplT7efXSNhERFUxmnVaKHUKBkHhotGjHfvMhVW1tWxppq61tsYkyIjlnzhzo6Ojg0aNHsLKyktvm6uqKOXPmwM/PT4zwiIiIqJAp6NP0qIso80ju378fixcvlksiAcDa2hoLFy7Evn37stiTiIiIiPIKUUYkIyMj4eTklO32ypUrIyoqKhcjIiIiokKNA5JKEWVE0sLCAk+fPs12+5MnT1C0aNHcC4iIiIiIFCZKIunm5obp06cjJSVFbltycjJmzpyJ1q1bixAZERERFUYSNS4FmWgP29SqVQsVKlSAp6cnHBwcIAgCwsLCsHr1aiQnJ2PLli1ihEZEREREOSRKIlmqVCmEhITA09MTXl5eyJyBSCKRoFWrVli5ciVsbGzECI2IiIgKIc4jqRzRJiS3s7PD4cOHERsbi/DwcABA+fLleW8kERER5TpO/6McURLJLl2+/4orLS0tWFtbo1WrVnB3d8+FqIiIiIhIEaIkkiYmJt+tk5GRgfDwcKxfvx6TJk3CnDlzciEyIiIiKox4aVs5orwiURGHDh3CqFGjEBERkeN9+IpEIiLKTXxFomqI+YrE2E/pamvbzEBTbW2LTZTpfxTRsGFD1KpVS+wwiIiIiOgreT6RNDU1xd69e8UOg4iIiIi+ItpT20RERER5Be+RVE6eH5EkIiIioryJI5JERERU6HEeSeUwkSQiIqJCj5e2lcNL20RERESkFI5IEhERUaHHAUnlcESSiIiIiJTCEUkiIiIiDkkqhSOSRERERKQUjkgSERFRocfpf5TDEUkiIiIiUgpHJImIiKjQ4zySyuGIJBEREREphSOSREREVOhxQFI5TCSJiIiImEkqhZe2iYiIiEgpTCSJiIio0JOo8X/KWLVqFcqUKQM9PT3UrVsXly9fVvEnVg0mkkRERER5yI4dOzBx4kR4e3vj+vXrqFq1Ktzc3PDmzRuxQ5PDRJKIiIgKPYlEfYuili5diqFDh2LgwIFwdHTEH3/8AQMDA/j7+6v+g/8gJpJEREREapScnIz4+HiZJTk5Ocu6KSkpuHbtGlq2bCkt09DQQMuWLXHhwoXcCjnnBBJFUlKS4O3tLSQlJYkdSr7GflQd9qXqsC9Vg/2oOuxLcXl7ewsAZBZvb+8s6758+VIAIISEhMiUT548WahTp04uRKsYiSAIgqiZbCEVHx8PExMTvH//HsbGxmKHk2+xH1WHfak67EvVYD+qDvtSXMnJyXIjkLq6utDV1ZWr++rVK5QsWRIhISFwcXGRlk+ZMgVnzpzBpUuX1B6vIjiPJBEREZEaZZc0ZsXCwgKampp4/fq1TPnr169hbW2tjvB+CO+RJCIiIsojdHR0ULNmTZw4cUJalpGRgRMnTsiMUOYVHJEkIiIiykMmTpwIDw8P1KpVC3Xq1MGyZcuQkJCAgQMHih2aHCaSItHV1YW3t3eOh7opa+xH1WFfqg77UjXYj6rDvsxfevbsibdv32LWrFmIiopCtWrVcOTIEVhZWYkdmhw+bENERERESuE9kkRERESkFCaSRERERKQUJpJEREREpBQmkkRERESkFCaSXxkwYAAkEgkkEgl0dHRQvnx5zJkzB2lpaTh9+jQkEgni4uLk9itTpgyWLVsmUxYSEoK2bdvCzMwMenp6qFKlCpYuXYr09HSZepnH+3oJCgoCAOlxMxd9fX04OTlh3bp12cb+5dK6dWuV9hEAREVFYcyYMbCzs4Ouri5sbGzg7u4unfcqq/4AAB8fH1SrVk2u/MWLF9DR0UHlypWzPJ5EIoGenh6ePXsmU96pUycMGDBAuv5lH2hra8PKygqtWrWCv78/MjIyZPbNLkYAePr0abY/l4sXLwIANm7cKC3T0NBA8eLF0bNnT0RERGTTa8r7+nOVLVsWU6ZMQVJSkky97/WjIAhYt24d6tatiyJFisDU1BS1atXCsmXL8OnTJwDZ/4wy++TGjRsy69/rI1NTU5X1w4/K7McRI0bIbfP09IREIpE5n54/f45BgwahRIkS0NHRga2tLcaNG4d3797J7Nu0aVOZ72ymZcuWoUyZMtL1rPojJSUFCxcuRNWqVWFgYAALCws0aNAAAQEBSE1Nlal74cIFaGpqol27dsp1QC7L6Xl76NAhNGnSBEZGRjAwMEDt2rWxceNGufb27duHevXqwcTEBEZGRnBycsL48eOl29PT0zF//nw4ODhAX18fRYsWRd26dbF+/Xo1f9LcM2DAAHTq1Em6rug5+vUyYsQIPHjwAAYGBti2bZvMPhkZGahfvz66deuWGx+N8ikmkllo3bo1IiMjER4ejp9//hk+Pj5YtGiRQm3s27cPTZo0QalSpXDq1Cncu3cP48aNw2+//YZevXrh64flAwICEBkZKbN8+csCAO7fv4/IyEjcvXsXw4cPx8iRI2UmLP0y9i+X7du3K9UP2Xn69Clq1qyJkydPYtGiRbh16xaOHDmCZs2awdPTU6k2N27ciB49eiA+Pj7b1z9JJBLMmjXru21l9sHTp09x+PBhNGvWDOPGjUP79u2RlpamUFzHjx+X68+aNWtKtxsbGyMyMhIvX77Enj17cP/+fXTv3l2hY+RU5ud6/Pgx/Pz8sHbtWnh7e8vU+V4//vTTTxg/fjw6duyIU6dO4caNG5g5cyYOHDiA4OBgpeL6Xh/lNTY2NggKCkJiYqK0LCkpCdu2bUPp0qWlZY8fP0atWrUQHh6O7du34+HDh/jjjz+kkwLHxMTItKunp4cZM2bIJX/fkpKSAjc3N8yfPx/Dhg1DSEgILl++DE9PT/z++++4c+eOTP0NGzZgzJgxOHv2LF69eqVkD+Su7523v//+Ozp27IgGDRrg0qVLCA0NRa9evTBixAhMmjRJWu/EiRPo2bMnunbtisuXL+PatWuYO3euTH/Pnj0bfn5++PXXX3H37l2cOnUKw4YNy/KP/4JA0XN06NChct/VhQsXomLFipg/fz7GjBmDyMhIaf0lS5bg8ePH+OOPP3L7o1F+IuaLvvMiDw8PoWPHjjJlrVq1EurVqyecOnVKACDExsbK7Wdrayv4+fkJgiAIHz9+FMzNzYUuXbrI1Tt48KAAQAgKCpKWARD27duXbUzZHbdcuXLCwoULvxm7OrRp00YoWbKk8PHjR7ltmTF+2R9f8vb2FqpWrSpTlpGRIdjZ2QlHjhwRpk6dKgwdOlRuPwDCpEmTBA0NDeHWrVvS8o4dOwoeHh7S9ez64MSJEwIA4c8//5SWZRejIAjCkydPBADCf//9l+V2QRCEgIAAwcTERKZsxYoVAgDh/fv32e6njKw+V5cuXYTq1atL17/Xjzt27BAACPv375drPyMjQ4iLixMEIeufkSDI94myfSSmzH6sXLmysHXrVml5YGCg4OzsLHM+tW7dWihVqpTw6dMnmTYiIyMFAwMDYcSIEdKyJk2aCAMHDhTMzc2FVatWScv9/PwEW1tb6frX/bFgwQJBQ0NDuH79ulysKSkpMt+xDx8+CEWKFBHu3bsn9OzZU5g7d66y3ZBrvnfeRkRECNra2sLEiRPl9s38Ll28eFEQBEEYN26c0LRp028er2rVqoKPj49qgs+jvuxTRc/RcePGZdtuRkaG0KxZM6Fdu3aCIAhCWFiYoKenJxw4cEDln4EKFo5I5oC+vj5SUlJyXD84OBjv3r2T+Ws6k7u7OypWrPhDo4SCIODIkSOIiIhA3bp1lW5HGTExMThy5Ag8PT1haGgot12Zy5inTp3Cp0+f0LJlS/Tr1w9BQUFISEiQq9egQQO0b98ev/zyi8LHaN68OapWrYq9e/cqvG9OvXnzBvv27YOmpiY0NTXVdhwAuH37NkJCQqCjoyMt+14/BgYGwt7eHh07dpRrTyKRwMTERK0x5yWDBg1CQECAdN3f31/mjRExMTE4evQoRo0aBX19fZl9ra2t0bdvX+zYsUPmyoKxsTGmT5+OOXPmZHn+ZiUwMBAtW7ZE9erV5bZpa2vLfMd27twJBwcH2Nvbo1+/fvD395e7spHXfX3e7t69G6mpqVn+rhw+fDiKFCki/V1pbW2NO3fu4Pbt29m2b21tjZMnT+Lt27fq+QB5iDLn6LdIJBIEBATg33//xZ9//okBAwagV69e6NChgzrCpwKEieQ3CIKA48eP4+jRo2jevLm0vFSpUihSpIjM8uV9cQ8ePAAAVKpUKct2HRwcpHUy9e7d+5ttfnlcHR0dtGvXDt7e3mjcuLFMnUOHDsm1M2/evB/qhy89fPgQgiDAwcHhu3WnTp2ao1g2bNiAXr16QVNTE5UrV4adnR127dqVZZu+vr44cuQI/v33X4Vjd3BwwNOnTxXap379+nKf4Uvv379HkSJFYGhoCCsrK5w6dSrbJPtHZf5sM++3ffPmDSZPnizd/r1+DA8Ph729fY6OdevWLbnP7eTklGXd7/VRXtSvXz+cO3cOz549w7Nnz3D+/Hn069dPuj08PByCIGT7Ha5UqRJiY2PlEpZRo0ZBT08PS5cuzVEc4eHhOfouAZ9/vpkxtm7dGu/fv8eZM2dytK+YvnXePnjwACYmJihevLjcfjo6OrCzs5P+rhwzZgxq166NKlWqoEyZMujVqxf8/f2RnJws3Wfp0qV4+/YtrK2t4ezsjBEjRuDw4cO580FzmTLn6OrVq+W+q4GBgdLttra2WLZsGUaMGIHIyEgsX75c7Z+D8j++IjELmb/4UlNTkZGRgT59+sDHxwdXrlwBAPz7778wMjKS2adp06Zy7SgyWuDn54eWLVvKlJUoUUJmPfO4ycnJuHz5MkaPHo2iRYti5MiR0jrNmjXDmjVrZPYrWrRojuP4HkU+0+TJk2UeXACAFStW4OzZs9L1uLg47N27F+fOnZOW9evXDxs2bJDbFwAcHR3Rv39//PLLLzh//rzCsUskEoX22bFjR7a/qAHAyMgI169fR2pqKg4fPozAwEDMnTtXoWPkVObPNiEhAX5+ftDS0kLXrl0B5KwfFfnZ2dvb4+DBgzJlL1++zPI8/14f5UXFihVDu3btsHHjRgiCgHbt2sHCwkKunqIjfrq6upgzZw7GjBkj873MTk7bv3//Pi5fvox9+/YBALS0tNCzZ09s2LAhy59JXvKt81YRhoaG+Pvvv/Ho0SOcOnUKFy9exM8//4zly5fjwoULMDAwgKOjI27fvo1r167h/PnzOHv2LNzd3TFgwIAC9cDNlxQ5R/v27Yvp06fLlH39yr2BAwdi5syZGDNmDIyNjVUSIxVsTCSzkPmLT0dHByVKlICWlmw3lS1bVu4S7pd1KlasCAAICwtD/fr15doPCwuDo6OjTJm1tTXKly//zbi+PK6TkxMuXbqEuXPnyvwHy9DQ8Lvt/IgKFSpAIpHg3r17361rYWEhF8vXSe22bduQlJQkc4leEARkZGTgwYMH0r780uzZs1GxYkXs379fodjDwsJQtmxZhfaxsbH5Zn9qaGhIt1eqVAmPHj3CyJEjsWXLFoWOkxNf/mz9/f1RtWpVbNiwAYMHD85RP1asWDFHPzcA0hkLvvT19yDT9/oorxo0aBBGjx4NAFi1apXMtvLly0MikSAsLAydO3eW2zcsLAxmZmYoVqyY3LZ+/fph8eLF+O2332Se2M5KTn8mGzZsQFpamswfl4IgQFdXFytXrszTtyV867ytWLEi3r9/j1evXsn94ZySkoJHjx6hWbNmMuXlypVDuXLlMGTIEEyfPh0VK1bEjh07pLcmaGhooHbt2qhduzbGjx+PrVu34qeffsL06dMV/v7nZcqcoyYmJjn6rmppaWX7fSf6Gi9tZyHzF1/p0qWV+jK5urqiaNGiWLJkidy2gwcPIjw8HL179/7hODU1NWWePM0NRYsWhZubG1atWpXlfWCKPh25YcMG/Pzzz7hx44Z0uXnzJho1agR/f/8s97GxscHo0aMxbdo0uamUsnPy5EncunVLqZEQRfzyyy/YsWMHrl+/rtbjaGhoYNq0aZgxYwYSExNz1I99+vTBgwcPcODAAbn2BEHA+/fv1RpzXtO6dWukpKQgNTUVbm5uMtvMzc3RqlUrrF69Wu47FhUVhcDAQPTs2TPLEW4NDQ34+vpizZo1372Vok+fPjh+/Dj+++8/uW2pqalISEhAWloaNm/ejCVLlsj9fEuUKKHyWRnU6evztmvXrtDW1s7yd+Uff/yBhISEb/6uLFOmDAwMDL55T2rmH+05vW81v/iRc5RIlZhIqoGhoSHWrl2LAwcOYNiwYQgNDcXTp0+llxm7deuGHj16yOwTFxeHqKgomeXrX3xv3rxBVFQUnj17hl27dmHLli1yD04kJyfLtRMdHa3Sz7dq1Sqkp6ejTp062LNnD8LDwxEWFoYVK1bAxcUlx+3cuHED169fx5AhQ1C5cmWZpXfv3ti0aVO20/V4eXnh1atXOH78uNy2zD54+fIlrl+/jnnz5qFjx45o3749+vfvL1P35cuXMv9xvnHjBmJjY6Xb3717J9efX8+B9yUbGxt07tw5R9MU/aju3btDU1MTq1atylE/9ujRAz179kTv3r0xb948XL16Fc+ePcOhQ4fQsmVLnDp1Sqk4vtdH6enpcn0cFhamqm5QmqamJsLCwnD37t0sH45auXIlkpOT4ebmhrNnz+L58+c4cuQIWrVqhZIlS37zFoZ27dqhbt26WLt27TdjGD9+PP6vvfsNaer74wD+NufV3CayWpqlLhTFzCdaVIxC0XJFZGlYEOLQR2X2byJIGDIpo9IMDCNMjYpKyP4wAglraBYjJCQoy8xJf/YgyYIIU9f5PvjRfk2n2a1lf94vuA92Pfecc493lw/n7H6uXq9HamoqTpw4ga6uLjx//hxNTU1YtmwZenp6YLFYMDg4iPz8/HH/36ysLJw+ffqHx+JX+vq6jYiIwOHDh1FdXY19+/ahu7sbvb29qKqqQnFxMUwmk2uWvaysDMXFxbBarejr68ODBw+Ql5eHkZERrFq1CgCwadMmHDt2DDabDf39/bBarSgoKEBMTMyUf4v6J/nea/Tjx4/jvqtf3++IZPm1D4n//iZLoTPV9D9ftLW1ifT0dBEUFCQkSRLx8fHi6NGjYnR01K0cAI9bRUWFW7tfNoVCIRYsWCCKiorc0oPk5uZ6rCc2NvaHxsST169fi4KCAhEZGSkkSRLz5s0T69evF7dv355wPIRwTy2zY8cOsXDhQo/1OxwOMWPGDFfqCXhIkXTw4EEBYFz6n6/HSavVirS0NFFfXy+cTqfb8ZGRkR7H6+zZs67UNp62CxcuCCEmTm1z7949AUDYbLZvD+QUTXRdVlRUCIVCIXQ6ncfjxo6j0+kUtbW1YsmSJSIwMFAEBQWJpKQkcfz4cVcKke9N//OtMfL096ioqB8fFBm+lSJrbDopu90ucnNzRUhIiPDz8xPh4eGisLBQDAwMuB3nKbXK3bt3BYBJ0/8IIcTQ0JCoqKgQCQkJIiAgQGg0GqHX60VjY6MYGRkR69atE2vXrvXYX5vNJgCIrq6uqZz+LzfZdavVal33r2vXrokVK1YIpVIpAgICRFJSkqivr3c75tatWyIrK0uEh4cLSZJESEiIMBgMor293VXm1KlTIiUlRWi1WiFJkoiIiBBGo1HY7XavnuevlJOTI7Kyslyfv+ca9fRdTE9PH9fGZKnRiMbyEeIPyx9BRET0jzIYDIiOjkZNTc10d4UIAJe2iYiIfnuDg4OwWCywWq3jMnwQTSc+lkVERPSby8vLw/3792EymTy+VIBounBpm4iIiIhk4dI2EREREcnCQJKIiIiIZGEgSURERESyMJAkIiIiIlkYSBIRERGRLAwkieiPZTQasWHDBtfn5ORk7N69e9r6Q0T0r2EgSUQ/ndFohI+PD3x8fCBJEqKjo2E2myd8d/rP0tzcjPLyctdnnU6H6upqr7ZJRPQvY0JyIvIKg8GAhoYGfPr0CTdu3EBBQQH8/PxQUlLiVm54eBiSJP2UNjUazU+ph4iIpoYzkkTkFf7+/ggNDUVkZCS2bduGtLQ0XL9+3bUcfeDAAYSFhSE2NhYA8OLFC2RnZyM4OBgajQYZGRmw2+2u+pxOJ/bu3Yvg4GDMmjULxcXFGPs+ha+XtpOTk9Hf3489e/a4Zke/uHz5MuLj4+Hv7w+dTofKykqvjwcR0d+IgSQR/RIzZ87E8PAwAKC1tRVPnjzBzZs3YbFYMDIygvT0dKjVarS3t6OjowMqlQoGg8F1TGVlJRobG1FfX487d+7g7du3uHLlyoTtNTc3Y/78+TCbzXA4HHA4HACAzs5OZGdnY8uWLXj48CHKyspQWlqKxsZGr48BEdHfhkvbRORVQgi0traipaUFhYWFePPmDZRKJerq6lxL2ufOncPnz59RV1fnmjlsaGhAcHAwrFYrVq9ejerqapSUlCAzMxMAcPLkSbS0tEzYrkajga+vL9RqNUJDQ137q6qqkJqaitLSUgBATEwMHj16hCNHjsBoNHppFIiI/k6ckSQir7BYLFCpVAgICMCaNWuwefNmlJWVAQASEhLcfhfZ1dWFZ8+eQa1WQ6VSQaVSQaPRYGhoCL29vXj//j0cDgeWLl3qOkahUGDx4sXf3a/Hjx9Dr9e77dPr9ejp6YHT6ZR3skRE/yjOSBKRV6SkpKC2thaSJCEsLAwKxf9vN0ql0q3shw8fkJSUhPPnz4+rR6vVer2vREQkDwNJIvIKpVKJ6OjoKZVNTEzEpUuXMGfOHAQFBXksM3fuXNhsNqxcuRIAMDo6is7OTiQmJk5YryRJ42YZ4+Li0NHR4bavo6MDMTEx8PX1nVJ/iYjof7i0TUTTbuvWrZg9ezYyMjLQ3t6Ovr4+WK1W7Ny5Ey9fvgQA7Nq1C4cOHcLVq1fR3d2N7du34927d5PWq9Pp0NbWhlevXmFgYAAAYDKZ0NraivLycjx9+hRnzpxBTU0NioqKvH2aRER/HQaSRDTtAgMD0dbWhoiICGRmZiIuLg75+fkYGhpyzVCaTCbk5OQgNzcXy5cvh1qtxsaNGyet12w2w263IyoqyrVEnpiYiKamJly8eBGLFi3C/v37YTab+aANEZEMPmJsIjYiIiIioingjCQRERERycJAkoiIiIhkYSBJRERERLIwkCQiIiIiWRhIEhEREZEsDCSJiIiISBYGkkREREQkCwNJIiIiIpKFgSQRERERycJAkoiIiIhkYSBJRERERLL8B9dfSp23/2tQAAAAAElFTkSuQmCC",
            "text/plain": [
              "<Figure size 800x600 with 2 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Relatório de Classificação por personagem:\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "      PHOEBE       1.00      1.00      1.00      1478\n",
            "    CHANDLER       1.00      1.00      1.00      1676\n",
            "      RACHEL       1.00      1.00      1.00      1829\n",
            "      MONICA       1.00      1.00      1.00      1662\n",
            "        ROSS       1.00      1.00      1.00      1820\n",
            "        JOEY       1.00      1.00      1.00      1642\n",
            "\n",
            "    accuracy                           1.00     10107\n",
            "   macro avg       1.00      1.00      1.00     10107\n",
            "weighted avg       1.00      1.00      1.00     10107\n",
            "\n"
          ]
        }
      ],
      "source": [
        "#Matriz de confusão\n",
        "\n",
        "best_model = keras.models.load_model(\"checkpoints/friends_finetuned_epoch_01_valacc_1.00.keras\")\n",
        "\n",
        "y_pred = best_model.predict(x_test_vect, verbose=0)\n",
        "y_pred_classes = np.argmax(y_pred, axis=1)\n",
        "\n",
        "\n",
        "labels = [\"PHOEBE\", \"CHANDLER\", \"RACHEL\", \"MONICA\", \"ROSS\", \"JOEY\"]\n",
        "\n",
        "# Matriz de confusão\n",
        "cm = confusion_matrix(y_test, y_pred_classes)\n",
        "\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.heatmap(cm, annot=True, fmt='d', cmap=\"Blues\", xticklabels=labels, yticklabels=labels)\n",
        "plt.xlabel(\"Predito\")\n",
        "plt.ylabel(\"Verdadeiro\")\n",
        "plt.title(\"Matriz de Confusão - Classificador Friends\")\n",
        "plt.show()\n",
        "\n",
        "# Relatório de classificação\n",
        "report = classification_report(y_test, y_pred_classes, target_names=labels)\n",
        "print(\"Relatório de Classificação por personagem:\\n\")\n",
        "print(report)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T68PvrzzEvhb"
      },
      "source": [
        "### **Refazer o pipeline com oversampling**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 109
        },
        "id": "Mh6GFLuS_PSh",
        "outputId": "7ec3fd61-f8e7-42c3-c905-39200c26a782"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-acf30cde-512f-4cdb-a8ff-d32e1f1acc81\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-acf30cde-512f-4cdb-a8ff-d32e1f1acc81\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saving falas_tagged.txt to falas_tagged.txt\n",
            "Total de falas: 50531\n",
            "Exemplo de fala: [PHOEBE] wait, does he eat chalk?\n"
          ]
        }
      ],
      "source": [
        "#Recarregar a base de dados falas_tagged\n",
        "\n",
        "uploaded = files.upload()\n",
        "\n",
        "with open(\"falas_tagged.txt\", \"r\", encoding=\"utf-8\") as f:\n",
        "    falas_tagged = f.read().splitlines()\n",
        "\n",
        "# Verifica algumas amostras\n",
        "print(f\"Total de falas: {len(falas_tagged)}\")\n",
        "print(\"Exemplo de fala:\", falas_tagged[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hcwwpparE5P_",
        "outputId": "c99578da-7f2e-45ef-c333-84690d894947"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[PHOEBE]: 7389 falas\n",
            "[CHANDLER]: 8381 falas\n",
            "[RACHEL]: 9142 falas\n",
            "[MONICA]: 8310 falas\n",
            "[ROSS]: 9099 falas\n",
            "[JOEY]: 8210 falas\n"
          ]
        }
      ],
      "source": [
        "#Prepara para aplicar o Oversampling\n",
        "\n",
        "from collections import defaultdict\n",
        "\n",
        "#Contar falas por personagem\n",
        "falas_por_personagem = defaultdict(list)\n",
        "\n",
        "for fala in falas_tagged:\n",
        "    if fala.startswith(\"[\") and \"]\" in fala:\n",
        "        personagem = fala.split(\"]\")[0] + \"]\"\n",
        "        falas_por_personagem[personagem].append(fala)\n",
        "\n",
        "#Exibe contagem atual por personagem\n",
        "for personagem, falas in falas_por_personagem.items():\n",
        "    print(f\"{personagem}: {len(falas)} falas\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8-mT8OLpGfsS",
        "outputId": "dc656858-2cf6-4ccb-ce09-5c46d7e6414f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Total de falas balanceadas: 54852\n"
          ]
        }
      ],
      "source": [
        "#aplicar o Oversampling\n",
        "import random\n",
        "\n",
        "# Encontra o personagem com mais falas\n",
        "max_falas = max(len(falas) for falas in falas_por_personagem.values())\n",
        "\n",
        "# Aplica o oversampling\n",
        "falas_balanceadas = []\n",
        "\n",
        "for personagem, falas in falas_por_personagem.items():\n",
        "    if len(falas) < max_falas:\n",
        "        multiplicado = falas * (max_falas // len(falas))\n",
        "        resto = random.choices(falas, k=max_falas - len(multiplicado))\n",
        "        falas_balanceadas.extend(multiplicado + resto)\n",
        "    else:\n",
        "        falas_balanceadas.extend(falas)\n",
        "\n",
        "# Embaralha as falas para evitar agrupamento por personagem\n",
        "random.shuffle(falas_balanceadas)\n",
        "\n",
        "print(f\"\\nTotal de falas balanceadas: {len(falas_balanceadas)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "88rKgfaRGu5y",
        "outputId": "b246ec55-031b-4c24-fde2-b0f74a5f116f"
      },
      "outputs": [
        {
          "data": {
            "application/javascript": "\n    async function download(id, filename, size) {\n      if (!google.colab.kernel.accessAllowed) {\n        return;\n      }\n      const div = document.createElement('div');\n      const label = document.createElement('label');\n      label.textContent = `Downloading \"${filename}\": `;\n      div.appendChild(label);\n      const progress = document.createElement('progress');\n      progress.max = size;\n      div.appendChild(progress);\n      document.body.appendChild(div);\n\n      const buffers = [];\n      let downloaded = 0;\n\n      const channel = await google.colab.kernel.comms.open(id);\n      // Send a message to notify the kernel that we're ready.\n      channel.send({})\n\n      for await (const message of channel.messages) {\n        // Send a message to notify the kernel that we're ready.\n        channel.send({})\n        if (message.buffers) {\n          for (const buffer of message.buffers) {\n            buffers.push(buffer);\n            downloaded += buffer.byteLength;\n            progress.value = downloaded;\n          }\n        }\n      }\n      const blob = new Blob(buffers, {type: 'application/binary'});\n      const a = document.createElement('a');\n      a.href = window.URL.createObjectURL(blob);\n      a.download = filename;\n      div.appendChild(a);\n      a.click();\n      div.remove();\n    }\n  ",
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/javascript": "download(\"download_ac42f5ca-2f3d-4e0a-b8e4-96db35e6f8cd\", \"falas_balanceadas.txt\", 3514281)",
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "#salva novo ds balanceado\n",
        "with open(\"falas_balanceadas.txt\", \"w\", encoding=\"utf-8\") as f:\n",
        "    f.write(\"\\n\".join(falas_balanceadas))\n",
        "\n",
        "# Download no Colab\n",
        "from google.colab import files\n",
        "files.download(\"falas_balanceadas.txt\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "BvvLdUMYE7cI",
        "outputId": "7491e13c-ffc6-487b-ef39-079c4928f6d6"
      },
      "outputs": [
        {
          "data": {
            "application/javascript": "\n    async function download(id, filename, size) {\n      if (!google.colab.kernel.accessAllowed) {\n        return;\n      }\n      const div = document.createElement('div');\n      const label = document.createElement('label');\n      label.textContent = `Downloading \"${filename}\": `;\n      div.appendChild(label);\n      const progress = document.createElement('progress');\n      progress.max = size;\n      div.appendChild(progress);\n      document.body.appendChild(div);\n\n      const buffers = [];\n      let downloaded = 0;\n\n      const channel = await google.colab.kernel.comms.open(id);\n      // Send a message to notify the kernel that we're ready.\n      channel.send({})\n\n      for await (const message of channel.messages) {\n        // Send a message to notify the kernel that we're ready.\n        channel.send({})\n        if (message.buffers) {\n          for (const buffer of message.buffers) {\n            buffers.push(buffer);\n            downloaded += buffer.byteLength;\n            progress.value = downloaded;\n          }\n        }\n      }\n      const blob = new Blob(buffers, {type: 'application/binary'});\n      const a = document.createElement('a');\n      a.href = window.URL.createObjectURL(blob);\n      a.download = filename;\n      div.appendChild(a);\n      a.click();\n      div.remove();\n    }\n  ",
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/javascript": "download(\"download_0f3d8996-740e-4e16-b916-4aeff471e238\", \"vectorize_layer_friends_balanced.keras\", 276665)",
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "#Atualizar a vectorize_layer para a nova bd balanceada\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import TextVectorization\n",
        "from tensorflow import keras\n",
        "\n",
        "#Custom standardization\n",
        "def custom_standardization(input_string):\n",
        "    lowercase = tf.strings.lower(input_string)\n",
        "    return tf.strings.regex_replace(lowercase, r\"[^\\w\\s\\[\\]]\", \"\")\n",
        "\n",
        "#Cria a camada de vetorização com [MASK]\n",
        "def get_vectorize_layer(texts, vocab_size=30000, max_seq_length=128, special_tokens=[\"[MASK]\"]):\n",
        "    vectorize_layer = TextVectorization(\n",
        "        max_tokens=vocab_size,\n",
        "        output_mode=\"int\",\n",
        "        standardize=custom_standardization,\n",
        "        output_sequence_length=max_seq_length,\n",
        "    )\n",
        "\n",
        "    # Adapta com os textos\n",
        "    vectorize_layer.adapt(texts)\n",
        "\n",
        "    # Constrói vocabulário com tokens especiais no início\n",
        "    vocab = vectorize_layer.get_vocabulary()\n",
        "    vocab = [tok for tok in vocab if tok not in [\"\", \"[UNK]\"] + special_tokens]\n",
        "    vocab = vocab[:vocab_size - len(special_tokens) - 2]\n",
        "    vocab_final = [\"\", \"[UNK]\"] + special_tokens + vocab\n",
        "\n",
        "    vectorize_layer.set_vocabulary(vocab_final)\n",
        "    return vectorize_layer\n",
        "\n",
        "#Junta as falas balanceadas\n",
        "falas_balanceadas = [fala for falas in falas_por_personagem.values() for fala in falas]\n",
        "vectorize_layer = get_vectorize_layer(falas_balanceadas)\n",
        "\n",
        "# Salva a camada como modelo\n",
        "vectorize_model = keras.Sequential([vectorize_layer])\n",
        "vectorize_model(tf.constant([\"exemplo de texto\"]))\n",
        "vectorize_model.save(\"vectorize_layer_friends_balanced.keras\")\n",
        "\n",
        "# Faz download\n",
        "from google.colab import files\n",
        "files.download(\"vectorize_layer_friends_balanced.keras\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Dv36hximE9ia"
      },
      "outputs": [],
      "source": [
        "#Codificar os textos e aplicar o masking para MLM\n",
        "\n",
        "def encode(texts, vectorize_layer):\n",
        "    return vectorize_layer(texts).numpy()\n",
        "\n",
        "\n",
        "def get_masked_input_and_labels(encoded_texts, mask_token_id):\n",
        "    #Aplica máscara em 15% dos tokens\n",
        "    inp_mask = np.random.rand(*encoded_texts.shape) < 0.15\n",
        "    inp_mask[encoded_texts <= 2] = False  # Não aplica em padding, OOV ou [MASK]\n",
        "\n",
        "    #Cria rótulos com -1 nos tokens que não queremos prever\n",
        "    y_labels = np.full_like(encoded_texts, fill_value=-1)\n",
        "    y_labels[inp_mask] = encoded_texts[inp_mask]\n",
        "\n",
        "    #Copia os tokens para aplicar a máscara\n",
        "    encoded_texts_masked = np.copy(encoded_texts)\n",
        "\n",
        "    #90% dos tokens mascarados viram [MASK]\n",
        "    inp_mask_2mask = inp_mask & (np.random.rand(*encoded_texts.shape) < 0.90)\n",
        "    encoded_texts_masked[inp_mask_2mask] = mask_token_id\n",
        "\n",
        "    #10% viram tokens aleatórios válidos\n",
        "    vocab_size = len(vectorize_layer.get_vocabulary())\n",
        "    inp_mask_2random = inp_mask & (np.random.rand(*encoded_texts.shape) < 0.10)\n",
        "    encoded_texts_masked[inp_mask_2random] = np.random.randint(3, vocab_size, inp_mask_2random.sum())\n",
        "\n",
        "    #Define os pesos (só computa o loss onde há token verdadeiro)\n",
        "    sample_weights = np.where(y_labels != -1, 1.0, 0.0).astype(np.float32)\n",
        "\n",
        "    return encoded_texts_masked.astype(np.int32), y_labels.astype(np.int32), sample_weights\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9PUR7hprITPG"
      },
      "outputs": [],
      "source": [
        "#Codifica os textos\n",
        "x_encoded = encode(falas_balanceadas, vectorize_layer)\n",
        "\n",
        "\n",
        "vocab = vectorize_layer.get_vocabulary()\n",
        "id2token = dict(enumerate(vocab))\n",
        "token2id = {token: idx for idx, token in enumerate(vocab)}\n",
        "mask_token_id = token2id[\"[MASK]\"]\n",
        "\n",
        "#masking\n",
        "x_masked, y_labels, sample_weights = get_masked_input_and_labels(x_encoded, mask_token_id)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o-sHjc5rIrLc"
      },
      "outputs": [],
      "source": [
        "#dataset de treinamento para MLM\n",
        "\n",
        "BATCH_SIZE = 32\n",
        "\n",
        "mlm_ds = tf.data.Dataset.from_tensor_slices((x_masked, y_labels, sample_weights))\n",
        "\n",
        "mlm_ds = mlm_ds.shuffle(buffer_size=1000).batch(BATCH_SIZE)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "mgJvbm9rJBHk",
        "outputId": "04d1e356-ff03-4f7e-df9e-d6f3909c25ab"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"bert_mlm_friends\"</span>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1mModel: \"bert_mlm_friends\"\u001b[0m\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)        </span>┃<span style=\"font-weight: bold\"> Output Shape      </span>┃<span style=\"font-weight: bold\">    Param # </span>┃<span style=\"font-weight: bold\"> Connected to      </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
              "│ input_ids           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ word_embedding      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)  │  <span style=\"color: #00af00; text-decoration-color: #00af00\">3,840,000</span> │ input_ids[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ position_embedding  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)  │     <span style=\"color: #00af00; text-decoration-color: #00af00\">16,384</span> │ word_embedding[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">PositionEmbedding</span>) │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ add_27 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)  │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ word_embedding[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
              "│                     │                   │            │ position_embeddi… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ encoder_0_multihea… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)  │     <span style=\"color: #00af00; text-decoration-color: #00af00\">66,048</span> │ add_27[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],     │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MultiHeadAttentio…</span> │                   │            │ add_27[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],     │\n",
              "│                     │                   │            │ add_27[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ encoder_0_att_drop… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)  │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ encoder_0_multih… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)           │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ add_28 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)  │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ add_27[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],     │\n",
              "│                     │                   │            │ encoder_0_att_dr… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ encoder_0_att_laye… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)  │        <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │ add_28[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LayerNormalizatio…</span> │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ encoder_0_ffn       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)  │     <span style=\"color: #00af00; text-decoration-color: #00af00\">65,920</span> │ encoder_0_att_la… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Sequential</span>)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ encoder_0_ffn_drop… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)  │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ encoder_0_ffn[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)           │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ add_29 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)  │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ encoder_0_att_la… │\n",
              "│                     │                   │            │ encoder_0_ffn_dr… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ encoder_0_ffn_laye… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)  │        <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │ add_29[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LayerNormalizatio…</span> │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ encoder_1_multihea… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)  │     <span style=\"color: #00af00; text-decoration-color: #00af00\">66,048</span> │ encoder_0_ffn_la… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MultiHeadAttentio…</span> │                   │            │ encoder_0_ffn_la… │\n",
              "│                     │                   │            │ encoder_0_ffn_la… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ encoder_1_att_drop… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)  │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ encoder_1_multih… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)           │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ add_30 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)  │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ encoder_0_ffn_la… │\n",
              "│                     │                   │            │ encoder_1_att_dr… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ encoder_1_att_laye… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)  │        <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │ add_30[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LayerNormalizatio…</span> │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ encoder_1_ffn       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)  │     <span style=\"color: #00af00; text-decoration-color: #00af00\">65,920</span> │ encoder_1_att_la… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Sequential</span>)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ encoder_1_ffn_drop… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)  │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ encoder_1_ffn[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)           │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ add_31 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)  │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ encoder_1_att_la… │\n",
              "│                     │                   │            │ encoder_1_ffn_dr… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ encoder_1_ffn_laye… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)  │        <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │ add_31[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LayerNormalizatio…</span> │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ encoder_2_multihea… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)  │     <span style=\"color: #00af00; text-decoration-color: #00af00\">66,048</span> │ encoder_1_ffn_la… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MultiHeadAttentio…</span> │                   │            │ encoder_1_ffn_la… │\n",
              "│                     │                   │            │ encoder_1_ffn_la… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ encoder_2_att_drop… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)  │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ encoder_2_multih… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)           │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ add_32 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)  │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ encoder_1_ffn_la… │\n",
              "│                     │                   │            │ encoder_2_att_dr… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ encoder_2_att_laye… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)  │        <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │ add_32[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LayerNormalizatio…</span> │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ encoder_2_ffn       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)  │     <span style=\"color: #00af00; text-decoration-color: #00af00\">65,920</span> │ encoder_2_att_la… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Sequential</span>)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ encoder_2_ffn_drop… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)  │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ encoder_2_ffn[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)           │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ add_33 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)  │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ encoder_2_att_la… │\n",
              "│                     │                   │            │ encoder_2_ffn_dr… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ encoder_2_ffn_laye… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)  │        <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │ add_33[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LayerNormalizatio…</span> │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ encoder_3_multihea… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)  │     <span style=\"color: #00af00; text-decoration-color: #00af00\">66,048</span> │ encoder_2_ffn_la… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MultiHeadAttentio…</span> │                   │            │ encoder_2_ffn_la… │\n",
              "│                     │                   │            │ encoder_2_ffn_la… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ encoder_3_att_drop… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)  │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ encoder_3_multih… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)           │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ add_34 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)  │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ encoder_2_ffn_la… │\n",
              "│                     │                   │            │ encoder_3_att_dr… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ encoder_3_att_laye… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)  │        <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │ add_34[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LayerNormalizatio…</span> │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ encoder_3_ffn       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)  │     <span style=\"color: #00af00; text-decoration-color: #00af00\">65,920</span> │ encoder_3_att_la… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Sequential</span>)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ encoder_3_ffn_drop… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)  │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ encoder_3_ffn[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)           │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ add_35 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)  │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ encoder_3_att_la… │\n",
              "│                     │                   │            │ encoder_3_ffn_dr… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ encoder_3_ffn_laye… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)  │        <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │ add_35[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LayerNormalizatio…</span> │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ mlm_cls (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>,       │  <span style=\"color: #00af00; text-decoration-color: #00af00\">3,870,000</span> │ encoder_3_ffn_la… │\n",
              "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">30000</span>)            │            │                   │\n",
              "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n",
              "</pre>\n"
            ],
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
              "│ input_ids           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
              "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ word_embedding      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m)  │  \u001b[38;5;34m3,840,000\u001b[0m │ input_ids[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
              "│ (\u001b[38;5;33mEmbedding\u001b[0m)         │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ position_embedding  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m)  │     \u001b[38;5;34m16,384\u001b[0m │ word_embedding[\u001b[38;5;34m0\u001b[0m… │\n",
              "│ (\u001b[38;5;33mPositionEmbedding\u001b[0m) │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ add_27 (\u001b[38;5;33mAdd\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m)  │          \u001b[38;5;34m0\u001b[0m │ word_embedding[\u001b[38;5;34m0\u001b[0m… │\n",
              "│                     │                   │            │ position_embeddi… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ encoder_0_multihea… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m)  │     \u001b[38;5;34m66,048\u001b[0m │ add_27[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],     │\n",
              "│ (\u001b[38;5;33mMultiHeadAttentio…\u001b[0m │                   │            │ add_27[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],     │\n",
              "│                     │                   │            │ add_27[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ encoder_0_att_drop… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m)  │          \u001b[38;5;34m0\u001b[0m │ encoder_0_multih… │\n",
              "│ (\u001b[38;5;33mDropout\u001b[0m)           │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ add_28 (\u001b[38;5;33mAdd\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m)  │          \u001b[38;5;34m0\u001b[0m │ add_27[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],     │\n",
              "│                     │                   │            │ encoder_0_att_dr… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ encoder_0_att_laye… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m)  │        \u001b[38;5;34m256\u001b[0m │ add_28[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      │\n",
              "│ (\u001b[38;5;33mLayerNormalizatio…\u001b[0m │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ encoder_0_ffn       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m)  │     \u001b[38;5;34m65,920\u001b[0m │ encoder_0_att_la… │\n",
              "│ (\u001b[38;5;33mSequential\u001b[0m)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ encoder_0_ffn_drop… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m)  │          \u001b[38;5;34m0\u001b[0m │ encoder_0_ffn[\u001b[38;5;34m0\u001b[0m]… │\n",
              "│ (\u001b[38;5;33mDropout\u001b[0m)           │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ add_29 (\u001b[38;5;33mAdd\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m)  │          \u001b[38;5;34m0\u001b[0m │ encoder_0_att_la… │\n",
              "│                     │                   │            │ encoder_0_ffn_dr… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ encoder_0_ffn_laye… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m)  │        \u001b[38;5;34m256\u001b[0m │ add_29[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      │\n",
              "│ (\u001b[38;5;33mLayerNormalizatio…\u001b[0m │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ encoder_1_multihea… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m)  │     \u001b[38;5;34m66,048\u001b[0m │ encoder_0_ffn_la… │\n",
              "│ (\u001b[38;5;33mMultiHeadAttentio…\u001b[0m │                   │            │ encoder_0_ffn_la… │\n",
              "│                     │                   │            │ encoder_0_ffn_la… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ encoder_1_att_drop… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m)  │          \u001b[38;5;34m0\u001b[0m │ encoder_1_multih… │\n",
              "│ (\u001b[38;5;33mDropout\u001b[0m)           │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ add_30 (\u001b[38;5;33mAdd\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m)  │          \u001b[38;5;34m0\u001b[0m │ encoder_0_ffn_la… │\n",
              "│                     │                   │            │ encoder_1_att_dr… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ encoder_1_att_laye… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m)  │        \u001b[38;5;34m256\u001b[0m │ add_30[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      │\n",
              "│ (\u001b[38;5;33mLayerNormalizatio…\u001b[0m │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ encoder_1_ffn       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m)  │     \u001b[38;5;34m65,920\u001b[0m │ encoder_1_att_la… │\n",
              "│ (\u001b[38;5;33mSequential\u001b[0m)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ encoder_1_ffn_drop… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m)  │          \u001b[38;5;34m0\u001b[0m │ encoder_1_ffn[\u001b[38;5;34m0\u001b[0m]… │\n",
              "│ (\u001b[38;5;33mDropout\u001b[0m)           │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ add_31 (\u001b[38;5;33mAdd\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m)  │          \u001b[38;5;34m0\u001b[0m │ encoder_1_att_la… │\n",
              "│                     │                   │            │ encoder_1_ffn_dr… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ encoder_1_ffn_laye… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m)  │        \u001b[38;5;34m256\u001b[0m │ add_31[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      │\n",
              "│ (\u001b[38;5;33mLayerNormalizatio…\u001b[0m │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ encoder_2_multihea… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m)  │     \u001b[38;5;34m66,048\u001b[0m │ encoder_1_ffn_la… │\n",
              "│ (\u001b[38;5;33mMultiHeadAttentio…\u001b[0m │                   │            │ encoder_1_ffn_la… │\n",
              "│                     │                   │            │ encoder_1_ffn_la… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ encoder_2_att_drop… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m)  │          \u001b[38;5;34m0\u001b[0m │ encoder_2_multih… │\n",
              "│ (\u001b[38;5;33mDropout\u001b[0m)           │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ add_32 (\u001b[38;5;33mAdd\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m)  │          \u001b[38;5;34m0\u001b[0m │ encoder_1_ffn_la… │\n",
              "│                     │                   │            │ encoder_2_att_dr… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ encoder_2_att_laye… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m)  │        \u001b[38;5;34m256\u001b[0m │ add_32[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      │\n",
              "│ (\u001b[38;5;33mLayerNormalizatio…\u001b[0m │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ encoder_2_ffn       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m)  │     \u001b[38;5;34m65,920\u001b[0m │ encoder_2_att_la… │\n",
              "│ (\u001b[38;5;33mSequential\u001b[0m)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ encoder_2_ffn_drop… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m)  │          \u001b[38;5;34m0\u001b[0m │ encoder_2_ffn[\u001b[38;5;34m0\u001b[0m]… │\n",
              "│ (\u001b[38;5;33mDropout\u001b[0m)           │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ add_33 (\u001b[38;5;33mAdd\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m)  │          \u001b[38;5;34m0\u001b[0m │ encoder_2_att_la… │\n",
              "│                     │                   │            │ encoder_2_ffn_dr… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ encoder_2_ffn_laye… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m)  │        \u001b[38;5;34m256\u001b[0m │ add_33[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      │\n",
              "│ (\u001b[38;5;33mLayerNormalizatio…\u001b[0m │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ encoder_3_multihea… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m)  │     \u001b[38;5;34m66,048\u001b[0m │ encoder_2_ffn_la… │\n",
              "│ (\u001b[38;5;33mMultiHeadAttentio…\u001b[0m │                   │            │ encoder_2_ffn_la… │\n",
              "│                     │                   │            │ encoder_2_ffn_la… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ encoder_3_att_drop… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m)  │          \u001b[38;5;34m0\u001b[0m │ encoder_3_multih… │\n",
              "│ (\u001b[38;5;33mDropout\u001b[0m)           │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ add_34 (\u001b[38;5;33mAdd\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m)  │          \u001b[38;5;34m0\u001b[0m │ encoder_2_ffn_la… │\n",
              "│                     │                   │            │ encoder_3_att_dr… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ encoder_3_att_laye… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m)  │        \u001b[38;5;34m256\u001b[0m │ add_34[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      │\n",
              "│ (\u001b[38;5;33mLayerNormalizatio…\u001b[0m │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ encoder_3_ffn       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m)  │     \u001b[38;5;34m65,920\u001b[0m │ encoder_3_att_la… │\n",
              "│ (\u001b[38;5;33mSequential\u001b[0m)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ encoder_3_ffn_drop… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m)  │          \u001b[38;5;34m0\u001b[0m │ encoder_3_ffn[\u001b[38;5;34m0\u001b[0m]… │\n",
              "│ (\u001b[38;5;33mDropout\u001b[0m)           │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ add_35 (\u001b[38;5;33mAdd\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m)  │          \u001b[38;5;34m0\u001b[0m │ encoder_3_att_la… │\n",
              "│                     │                   │            │ encoder_3_ffn_dr… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ encoder_3_ffn_laye… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m)  │        \u001b[38;5;34m256\u001b[0m │ add_35[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      │\n",
              "│ (\u001b[38;5;33mLayerNormalizatio…\u001b[0m │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ mlm_cls (\u001b[38;5;33mDense\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m,       │  \u001b[38;5;34m3,870,000\u001b[0m │ encoder_3_ffn_la… │\n",
              "│                     │ \u001b[38;5;34m30000\u001b[0m)            │            │                   │\n",
              "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">8,256,304</span> (31.50 MB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m8,256,304\u001b[0m (31.50 MB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">8,256,304</span> (31.50 MB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m8,256,304\u001b[0m (31.50 MB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "#BERT\n",
        "import keras_nlp\n",
        "from tensorflow import keras\n",
        "from keras import layers\n",
        "\n",
        "EMBED_DIM = 128\n",
        "NUM_HEAD = 4\n",
        "FF_DIM = 256\n",
        "NUM_LAYERS = 4\n",
        "VOCAB_SIZE = 30000\n",
        "MAX_LEN = 128\n",
        "LR = 1e-5\n",
        "\n",
        "#Função de perda e métrica\n",
        "loss_fn = keras.losses.SparseCategoricalCrossentropy(from_logits=True, reduction=\"none\")\n",
        "loss_tracker = keras.metrics.Mean(name=\"loss\")\n",
        "\n",
        "#encoder BERT block\n",
        "def bert_module(query, key, value, i):\n",
        "    attention_output = layers.MultiHeadAttention(\n",
        "        num_heads=NUM_HEAD,\n",
        "        key_dim=EMBED_DIM // NUM_HEAD,\n",
        "        name=f\"encoder_{i}_multiheadattention\"\n",
        "    )(query, key, value)\n",
        "\n",
        "    attention_output = layers.Dropout(0.1, name=f\"encoder_{i}_att_dropout\")(attention_output)\n",
        "    attention_output = layers.LayerNormalization(epsilon=1e-6, name=f\"encoder_{i}_att_layernorm\")(query + attention_output)\n",
        "\n",
        "    ffn = keras.Sequential([\n",
        "        layers.Dense(FF_DIM, activation=\"relu\"),\n",
        "        layers.Dense(EMBED_DIM)\n",
        "    ], name=f\"encoder_{i}_ffn\")\n",
        "\n",
        "    ffn_output = ffn(attention_output)\n",
        "    ffn_output = layers.Dropout(0.1, name=f\"encoder_{i}_ffn_dropout\")(ffn_output)\n",
        "    output = layers.LayerNormalization(epsilon=1e-6, name=f\"encoder_{i}_ffn_layernorm\")(attention_output + ffn_output)\n",
        "\n",
        "    return output\n",
        "\n",
        "\n",
        "class MaskedLanguageModel(keras.Model):\n",
        "    def compute_loss(self, x=None, y=None, y_pred=None, sample_weight=None):\n",
        "        #valid_indices = tf.where(y != -1)\n",
        "\n",
        "        #y_pred = tf.gather_nd(y_pred, valid_indices)\n",
        "        #y = tf.gather_nd(y, valid_indices)\n",
        "        #sample_weight = tf.gather_nd(sample_weight, valid_indices)\n",
        "\n",
        "        loss = loss_fn(y, y_pred)\n",
        "\n",
        "        if sample_weight is not None:\n",
        "            loss = loss * sample_weight\n",
        "\n",
        "        loss_tracker.update_state(loss)\n",
        "        return tf.reduce_mean(loss)\n",
        "\n",
        "    def compute_metrics(self, x, y, y_pred, sample_weight):\n",
        "        return {\"loss\": loss_tracker.result()}\n",
        "\n",
        "    @property\n",
        "    def metrics(self):\n",
        "        return [loss_tracker]\n",
        "\n",
        "\n",
        "def create_masked_language_bert_model():\n",
        "    inputs = layers.Input(shape=(MAX_LEN,), dtype=\"int64\", name=\"input_ids\")\n",
        "\n",
        "    word_embeddings = layers.Embedding(\n",
        "        input_dim=VOCAB_SIZE,\n",
        "        output_dim=EMBED_DIM,\n",
        "        name=\"word_embedding\"\n",
        "    )(inputs)\n",
        "\n",
        "    position_embeddings = keras_nlp.layers.PositionEmbedding(\n",
        "        sequence_length=MAX_LEN,\n",
        "        name=\"position_embedding\"\n",
        "    )(word_embeddings)\n",
        "\n",
        "    x = word_embeddings + position_embeddings\n",
        "\n",
        "    for i in range(NUM_LAYERS):\n",
        "        x = bert_module(x, x, x, i)\n",
        "\n",
        "    outputs = layers.Dense(VOCAB_SIZE, activation=\"softmax\", name=\"mlm_cls\")(x)\n",
        "\n",
        "    model = MaskedLanguageModel(inputs, outputs, name=\"bert_mlm_friends\")\n",
        "    model.compile(optimizer=keras.optimizers.Adam(learning_rate=LR))\n",
        "\n",
        "    return model\n",
        "\n",
        "# Criar o modelo\n",
        "mlm_model = create_masked_language_bert_model()\n",
        "mlm_model.summary()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "HmyRDpNLJ1uR",
        "outputId": "031cb0e7-45af-4092-9e7c-b2d7fb5522e4"
      },
      "outputs": [
        {
          "data": {
            "application/javascript": "\n    async function download(id, filename, size) {\n      if (!google.colab.kernel.accessAllowed) {\n        return;\n      }\n      const div = document.createElement('div');\n      const label = document.createElement('label');\n      label.textContent = `Downloading \"${filename}\": `;\n      div.appendChild(label);\n      const progress = document.createElement('progress');\n      progress.max = size;\n      div.appendChild(progress);\n      document.body.appendChild(div);\n\n      const buffers = [];\n      let downloaded = 0;\n\n      const channel = await google.colab.kernel.comms.open(id);\n      // Send a message to notify the kernel that we're ready.\n      channel.send({})\n\n      for await (const message of channel.messages) {\n        // Send a message to notify the kernel that we're ready.\n        channel.send({})\n        if (message.buffers) {\n          for (const buffer of message.buffers) {\n            buffers.push(buffer);\n            downloaded += buffer.byteLength;\n            progress.value = downloaded;\n          }\n        }\n      }\n      const blob = new Blob(buffers, {type: 'application/binary'});\n      const a = document.createElement('a');\n      a.href = window.URL.createObjectURL(blob);\n      a.download = filename;\n      div.appendChild(a);\n      a.click();\n      div.remove();\n    }\n  ",
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/javascript": "download(\"download_e21ad9bc-e27f-4f91-9f40-53f8c69f4905\", \"bert_mlm_friends_untrained.keras\", 33217520)",
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "#Salva o modelo ainda não treinado\n",
        "from google.colab import files\n",
        "\n",
        "\n",
        "mlm_model.save(\"bert_mlm_friends_untrained.keras\")\n",
        "files.download(\"bert_mlm_friends_untrained.keras\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 386
        },
        "id": "9D-Nl7m0E_0i",
        "outputId": "57214756-8fb1-467c-bb5c-a7f3ef47757f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "\u001b[1m1580/1580\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 10.3089\n",
            "Epoch 1: loss improved from inf to 10.30890, saving model to checkpoints/bert_mlm_best.keras\n",
            "\u001b[1m1580/1580\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 23ms/step - loss: 10.3089\n",
            "Epoch 2/5\n",
            "\u001b[1m1577/1580\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 10.3053\n",
            "Epoch 2: loss improved from 10.30890 to 10.29825, saving model to checkpoints/bert_mlm_best.keras\n",
            "\u001b[1m1580/1580\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 15ms/step - loss: 10.3052\n",
            "Epoch 3/5\n",
            "\u001b[1m1577/1580\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 10.2790\n",
            "Epoch 3: loss improved from 10.29825 to 10.27760, saving model to checkpoints/bert_mlm_best.keras\n",
            "\u001b[1m1580/1580\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 15ms/step - loss: 10.2790\n",
            "Epoch 4/5\n",
            "\u001b[1m1577/1580\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 10.2744\n",
            "Epoch 4: loss improved from 10.27760 to 10.27423, saving model to checkpoints/bert_mlm_best.keras\n",
            "\u001b[1m1580/1580\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 15ms/step - loss: 10.2744\n",
            "Epoch 5/5\n",
            "\u001b[1m1577/1580\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 10.2711\n",
            "Epoch 5: loss improved from 10.27423 to 10.27047, saving model to checkpoints/bert_mlm_best.keras\n",
            "\u001b[1m1580/1580\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 15ms/step - loss: 10.2711\n"
          ]
        },
        {
          "data": {
            "application/javascript": "\n    async function download(id, filename, size) {\n      if (!google.colab.kernel.accessAllowed) {\n        return;\n      }\n      const div = document.createElement('div');\n      const label = document.createElement('label');\n      label.textContent = `Downloading \"${filename}\": `;\n      div.appendChild(label);\n      const progress = document.createElement('progress');\n      progress.max = size;\n      div.appendChild(progress);\n      document.body.appendChild(div);\n\n      const buffers = [];\n      let downloaded = 0;\n\n      const channel = await google.colab.kernel.comms.open(id);\n      // Send a message to notify the kernel that we're ready.\n      channel.send({})\n\n      for await (const message of channel.messages) {\n        // Send a message to notify the kernel that we're ready.\n        channel.send({})\n        if (message.buffers) {\n          for (const buffer of message.buffers) {\n            buffers.push(buffer);\n            downloaded += buffer.byteLength;\n            progress.value = downloaded;\n          }\n        }\n      }\n      const blob = new Blob(buffers, {type: 'application/binary'});\n      const a = document.createElement('a');\n      a.href = window.URL.createObjectURL(blob);\n      a.download = filename;\n      div.appendChild(a);\n      a.click();\n      div.remove();\n    }\n  ",
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/javascript": "download(\"download_3c6d9d6c-7da5-4986-b98a-029b59607662\", \"bert_mlm_friends_trained.keras\", 99316280)",
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/javascript": "\n    async function download(id, filename, size) {\n      if (!google.colab.kernel.accessAllowed) {\n        return;\n      }\n      const div = document.createElement('div');\n      const label = document.createElement('label');\n      label.textContent = `Downloading \"${filename}\": `;\n      div.appendChild(label);\n      const progress = document.createElement('progress');\n      progress.max = size;\n      div.appendChild(progress);\n      document.body.appendChild(div);\n\n      const buffers = [];\n      let downloaded = 0;\n\n      const channel = await google.colab.kernel.comms.open(id);\n      // Send a message to notify the kernel that we're ready.\n      channel.send({})\n\n      for await (const message of channel.messages) {\n        // Send a message to notify the kernel that we're ready.\n        channel.send({})\n        if (message.buffers) {\n          for (const buffer of message.buffers) {\n            buffers.push(buffer);\n            downloaded += buffer.byteLength;\n            progress.value = downloaded;\n          }\n        }\n      }\n      const blob = new Blob(buffers, {type: 'application/binary'});\n      const a = document.createElement('a');\n      a.href = window.URL.createObjectURL(blob);\n      a.download = filename;\n      div.appendChild(a);\n      a.click();\n      div.remove();\n    }\n  ",
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/javascript": "download(\"download_76e3b6e4-b9ed-425e-bfd0-38cf0349b22b\", \"bert_mlm_best.keras\", 99316280)",
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "#Treinar o modelo BERT-MLM\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint\n",
        "\n",
        "checkpoint_cb = ModelCheckpoint(\n",
        "    filepath=\"checkpoints/bert_mlm_best.keras\",\n",
        "    monitor=\"loss\",\n",
        "    save_best_only=True,\n",
        "    save_weights_only=False,\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "history = mlm_model.fit(\n",
        "    mlm_ds,\n",
        "    epochs=5,\n",
        "    callbacks=[checkpoint_cb]\n",
        ")\n",
        "\n",
        "mlm_model.save(\"bert_mlm_friends_trained.keras\")\n",
        "files.download(\"bert_mlm_friends_trained.keras\")\n",
        "files.download(\"checkpoints/bert_mlm_best.keras\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CcpKAK5Z2bd1",
        "outputId": "fe7822c3-2dd6-423c-eaa1-fc6826c6830e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "\u001b[1m1580/1580\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 10.2631\n",
            "Epoch 1: loss improved from 10.27047 to 10.26240, saving model to checkpoints/bert_mlm_best.keras\n",
            "\u001b[1m1580/1580\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 15ms/step - loss: 10.2631\n",
            "Epoch 2/10\n",
            "\u001b[1m1577/1580\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 10.2541\n",
            "Epoch 2: loss improved from 10.26240 to 10.25407, saving model to checkpoints/bert_mlm_best.keras\n",
            "\u001b[1m1580/1580\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 15ms/step - loss: 10.2541\n",
            "Epoch 3/10\n",
            "\u001b[1m1577/1580\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 10.2471\n",
            "Epoch 3: loss improved from 10.25407 to 10.24644, saving model to checkpoints/bert_mlm_best.keras\n",
            "\u001b[1m1580/1580\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 15ms/step - loss: 10.2471\n",
            "Epoch 4/10\n",
            "\u001b[1m1577/1580\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 10.2413\n",
            "Epoch 4: loss improved from 10.24644 to 10.23969, saving model to checkpoints/bert_mlm_best.keras\n",
            "\u001b[1m1580/1580\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 15ms/step - loss: 10.2413\n",
            "Epoch 5/10\n",
            "\u001b[1m1577/1580\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 10.2364\n",
            "Epoch 5: loss improved from 10.23969 to 10.23414, saving model to checkpoints/bert_mlm_best.keras\n",
            "\u001b[1m1580/1580\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 15ms/step - loss: 10.2364\n",
            "Epoch 6/10\n",
            "\u001b[1m1577/1580\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 10.2332\n",
            "Epoch 6: loss improved from 10.23414 to 10.23034, saving model to checkpoints/bert_mlm_best.keras\n",
            "\u001b[1m1580/1580\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 15ms/step - loss: 10.2332\n",
            "Epoch 7/10\n",
            "\u001b[1m1577/1580\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 10.2275\n",
            "Epoch 7: loss improved from 10.23034 to 10.22465, saving model to checkpoints/bert_mlm_best.keras\n",
            "\u001b[1m1580/1580\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 15ms/step - loss: 10.2275\n",
            "Epoch 8/10\n",
            "\u001b[1m1578/1580\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 10.2219\n",
            "Epoch 8: loss improved from 10.22465 to 10.21981, saving model to checkpoints/bert_mlm_best.keras\n",
            "\u001b[1m1580/1580\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 15ms/step - loss: 10.2219\n",
            "Epoch 9/10\n",
            "\u001b[1m1579/1580\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 10.2181\n",
            "Epoch 9: loss improved from 10.21981 to 10.21758, saving model to checkpoints/bert_mlm_best.keras\n",
            "\u001b[1m1580/1580\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 16ms/step - loss: 10.2181\n",
            "Epoch 10/10\n",
            "\u001b[1m1577/1580\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 10.2162\n",
            "Epoch 10: loss improved from 10.21758 to 10.21599, saving model to checkpoints/bert_mlm_best.keras\n",
            "\u001b[1m1580/1580\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 15ms/step - loss: 10.2162\n"
          ]
        }
      ],
      "source": [
        "#Rodar 10 épocas\n",
        "history = mlm_model.fit(\n",
        "    mlm_ds,\n",
        "    epochs=10,\n",
        "    callbacks=[checkpoint_cb]\n",
        ")\n",
        "\n",
        "mlm_model.save(\"bert_mlm_friends_trained.keras\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 578
        },
        "id": "eD8iKPVaAcQa",
        "outputId": "d4e6637d-f6b1-4dec-d63b-c94550c2219c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "\u001b[1m1577/1580\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 10.2234\n",
            "Epoch 1: loss did not improve from 10.22130\n",
            "\u001b[1m1580/1580\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 17ms/step - loss: 10.2235\n",
            "Epoch 2/5\n",
            "\u001b[1m1577/1580\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 10.2259\n",
            "Epoch 2: loss did not improve from 10.22130\n",
            "\u001b[1m1580/1580\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 16ms/step - loss: 10.2260\n",
            "Epoch 3/5\n",
            "\u001b[1m  81/1580\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m23s\u001b[0m 15ms/step - loss: 10.2631"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-32-9c17539e95e0>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#Rodar 5 épocas\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m history = mlm_model.fit(\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0mmlm_ds\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcheckpoint_cb\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    115\u001b[0m         \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 117\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    118\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m             \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras/src/backend/tensorflow/trainer.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq)\u001b[0m\n\u001b[1;32m    369\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miterator\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mepoch_iterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    370\u001b[0m                     \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 371\u001b[0;31m                     \u001b[0mlogs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    372\u001b[0m                     \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    373\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop_training\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras/src/backend/tensorflow/trainer.py\u001b[0m in \u001b[0;36mfunction\u001b[0;34m(iterator)\u001b[0m\n\u001b[1;32m    218\u001b[0m             ):\n\u001b[1;32m    219\u001b[0m                 \u001b[0mopt_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmulti_step_on_iterator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 220\u001b[0;31m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mopt_outputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhas_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    221\u001b[0m                     \u001b[0;32mraise\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    222\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mopt_outputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/data/ops/optional_ops.py\u001b[0m in \u001b[0;36mhas_value\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m    174\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mhas_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    175\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolocate_with\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_variant_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 176\u001b[0;31m       return gen_optional_ops.optional_has_value(\n\u001b[0m\u001b[1;32m    177\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_variant_tensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    178\u001b[0m       )\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/ops/gen_optional_ops.py\u001b[0m in \u001b[0;36moptional_has_value\u001b[0;34m(optional, name)\u001b[0m\n\u001b[1;32m    170\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mtld\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_eager\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    171\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 172\u001b[0;31m       _result = pywrap_tfe.TFE_Py_FastPathExecute(\n\u001b[0m\u001b[1;32m    173\u001b[0m         _ctx, \"OptionalHasValue\", name, optional)\n\u001b[1;32m    174\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0m_result\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "#Rodar 5 épocas\n",
        "history = mlm_model.fit(\n",
        "    mlm_ds,\n",
        "    epochs=5,\n",
        "    callbacks=[checkpoint_cb]\n",
        ")\n",
        "\n",
        "mlm_model.save(\"bert_mlm_friends_trained.keras\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0q5-vr3aBV5p",
        "outputId": "6789c10c-ebcf-4273-bf72-8cddeb74b7e4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "\u001b[1m1580/1580\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 10.2597\n",
            "Epoch 1: loss did not improve from 10.22130\n",
            "\u001b[1m1580/1580\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 24ms/step - loss: 10.2597\n",
            "Epoch 2/5\n",
            "\u001b[1m1578/1580\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 10.2593\n",
            "Epoch 2: loss did not improve from 10.22130\n",
            "\u001b[1m1580/1580\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 16ms/step - loss: 10.2593\n",
            "Epoch 3/5\n",
            "\u001b[1m1580/1580\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 10.2590\n",
            "Epoch 3: loss did not improve from 10.22130\n",
            "\u001b[1m1580/1580\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 16ms/step - loss: 10.2590\n",
            "Epoch 4/5\n",
            "\u001b[1m1580/1580\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 10.2594\n",
            "Epoch 4: loss did not improve from 10.22130\n",
            "\u001b[1m1580/1580\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 16ms/step - loss: 10.2594\n",
            "Epoch 5/5\n",
            "\u001b[1m1579/1580\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 10.2590\n",
            "Epoch 5: loss did not improve from 10.22130\n",
            "\u001b[1m1580/1580\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 16ms/step - loss: 10.2590\n"
          ]
        }
      ],
      "source": [
        "#treinar com LR = 1e-6 para tentar diminuir o loss\n",
        "mlm_model.compile(optimizer=keras.optimizers.Adam(learning_rate=1e-6))\n",
        "\n",
        "history = mlm_model.fit(\n",
        "    mlm_ds,\n",
        "    epochs=5,\n",
        "    callbacks=[checkpoint_cb]\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KeVAyRdEEAwY",
        "outputId": "ca68d790-5aa1-4b9d-df85-eecfe2307fdc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "\u001b[1m1580/1580\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 10.2591\n",
            "Epoch 1: loss did not improve from 10.22130\n",
            "\u001b[1m1580/1580\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m66s\u001b[0m 24ms/step - loss: 10.2591\n",
            "Epoch 2/5\n",
            "\u001b[1m1577/1580\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 10.2588\n",
            "Epoch 2: loss did not improve from 10.22130\n",
            "\u001b[1m1580/1580\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 17ms/step - loss: 10.2588\n",
            "Epoch 3/5\n",
            "\u001b[1m1577/1580\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 10.2589\n",
            "Epoch 3: loss did not improve from 10.22130\n",
            "\u001b[1m1580/1580\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 17ms/step - loss: 10.2589\n",
            "Epoch 4/5\n",
            "\u001b[1m1578/1580\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 10.2588\n",
            "Epoch 4: loss did not improve from 10.22130\n",
            "\u001b[1m1580/1580\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 17ms/step - loss: 10.2588\n",
            "Epoch 5/5\n",
            "\u001b[1m1577/1580\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 10.2588\n",
            "Epoch 5: loss did not improve from 10.22130\n",
            "\u001b[1m1580/1580\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 16ms/step - loss: 10.2587\n"
          ]
        }
      ],
      "source": [
        "#Recompilar o seu modelo para aplicar a nova função de perda corrigida\n",
        "mlm_model.compile(optimizer=keras.optimizers.Adam(learning_rate=1e-6))\n",
        "\n",
        "history = mlm_model.fit(\n",
        "    mlm_ds,\n",
        "    epochs=5,\n",
        "    callbacks=[checkpoint_cb]\n",
        ")\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mqhSU4cwGAKY"
      },
      "source": [
        "### Diagnóstico dos dados mascarados - inspecionar possíveis problemas nas entradas:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DxotaLekFyTk",
        "outputId": "de8bd607-e401-4825-8c0f-f15220abbf82"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Amostras com apenas zeros: 0\n",
            "Amostras com apenas [MASK] e padding: 105\n",
            "Amostras sem nenhum rótulo válido: 15485\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "\n",
        "# Verifica quantas amostras têm apenas padding ou valores irrelevantes\n",
        "apenas_zeros = np.all(x_masked == 0, axis=1)\n",
        "so_mask = np.all((x_masked == mask_token_id) | (x_masked == 0), axis=1)\n",
        "nenhuma_label = np.all(y_labels == -1, axis=1)\n",
        "\n",
        "print(\"Amostras com apenas zeros:\", apenas_zeros.sum())\n",
        "print(\"Amostras com apenas [MASK] e padding:\", so_mask.sum())\n",
        "print(\"Amostras sem nenhum rótulo válido:\", nenhuma_label.sum())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VDNprrxsGT9B",
        "outputId": "aaadc2fe-dcdd-4fff-fca6-f91948ee0c35"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Novo shape de x_masked: (35046, 128)\n"
          ]
        }
      ],
      "source": [
        "#Filtrar amostras inválidas\n",
        "\n",
        "# Máscara para filtrar amostras úteis (aquelas que têm ao menos um rótulo válido)\n",
        "validas = np.any(y_labels != -1, axis=1)\n",
        "\n",
        "# Aplica o filtro\n",
        "x_masked = x_masked[validas]\n",
        "y_labels = y_labels[validas]\n",
        "sample_weights = sample_weights[validas]\n",
        "\n",
        "# Mostra nova dimensão do dataset\n",
        "print(\"Novo shape de x_masked:\", x_masked.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SOkHBB8mC7De"
      },
      "outputs": [],
      "source": [
        "#Recriar o dataset mlm_ds\n",
        "BATCH_SIZE = 32\n",
        "mlm_ds = tf.data.Dataset.from_tensor_slices((x_masked, y_labels, sample_weights))\n",
        "mlm_ds = mlm_ds.shuffle(1000).batch(BATCH_SIZE)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "laABizHZCYcP",
        "outputId": "0375c028-e85d-4760-82b8-d486c6d03854"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "\u001b[1m1580/1580\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 10.2166\n",
            "Epoch 1: loss improved from inf to 10.22743, saving model to checkpoints/bert_mlm_filtered_best.keras\n",
            "\u001b[1m1580/1580\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m66s\u001b[0m 24ms/step - loss: 10.2166\n",
            "Epoch 2/5\n",
            "\u001b[1m1578/1580\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 10.2454\n",
            "Epoch 2: loss did not improve from 10.22743\n",
            "\u001b[1m1580/1580\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 16ms/step - loss: 10.2454\n",
            "Epoch 3/5\n",
            "\u001b[1m1578/1580\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 10.2235\n",
            "Epoch 3: loss did not improve from 10.22743\n",
            "\u001b[1m1580/1580\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 16ms/step - loss: 10.2235\n",
            "Epoch 4/5\n",
            "\u001b[1m1578/1580\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 10.2489\n",
            "Epoch 4: loss did not improve from 10.22743\n",
            "\u001b[1m1580/1580\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 16ms/step - loss: 10.2489\n",
            "Epoch 5/5\n",
            "\u001b[1m1579/1580\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 10.2367\n",
            "Epoch 5: loss did not improve from 10.22743\n",
            "\u001b[1m1580/1580\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 16ms/step - loss: 10.2367\n"
          ]
        }
      ],
      "source": [
        "#Novo treinamento\n",
        "mlm_model.compile(optimizer=keras.optimizers.Adam(learning_rate=1e-4))\n",
        "\n",
        "checkpoint_cb = ModelCheckpoint(\n",
        "    filepath=\"checkpoints/bert_mlm_filtered_best.keras\",\n",
        "    monitor=\"loss\",\n",
        "    save_best_only=True,\n",
        "    save_weights_only=False,\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "# Treinamento\n",
        "history = mlm_model.fit(\n",
        "    mlm_ds,\n",
        "    epochs=5,\n",
        "    callbacks=[checkpoint_cb]\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ocFzFeLI27gd"
      },
      "source": [
        "## 🍀 **BERT Model** (nova versão)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N6W8eKBDHwRB"
      },
      "source": [
        "Prof, desistimos. Vamos refazer o projeto do começo =("
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sLme1ViCJDd4"
      },
      "source": [
        "Novo projeto. Objetivo: Treinar um modelo BERT (do zero ou com fine-tuning) para completar frases dos personagens de Friends"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B3XijvZWKRoo"
      },
      "source": [
        "Etapas:\n",
        "1. Dataset | Organizar as falas dos personagens de Friends em formato linha por linha\n",
        "2. Pré-processamento | Limpeza básica\n",
        "3. Tokenização\n",
        "4. Dataset para treino | Criar Dataset com frases mascaradas ([MASK]) no estilo MLM.\n",
        "5. Modelo BERT\n",
        "6. Treinamento | Treinar com callbacks de checkpoint e salvar o modelo.\n",
        "7. Avaliação/Testes | Completar frases manualmente com o modelo e ver os resultados.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N86ClsFi27ge"
      },
      "source": [
        "### Dependências"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oYbta9BvH61T"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "os.environ[\"KERAS_BACKEND\"] = \"torch\"  # or jax, or tensorflow\n",
        "\n",
        "import keras_hub\n",
        "\n",
        "import keras\n",
        "from keras import layers\n",
        "from keras.layers import TextVectorization\n",
        "\n",
        "from dataclasses import dataclass\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import glob\n",
        "import re\n",
        "from pprint import pprint"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ji7oky5rAIZE"
      },
      "outputs": [],
      "source": [
        "@dataclass\n",
        "class Config:\n",
        "    MAX_LEN = 256\n",
        "    BATCH_SIZE = 32\n",
        "    LR = 0.001\n",
        "    VOCAB_SIZE = 30000\n",
        "    EMBED_DIM = 128\n",
        "    NUM_HEAD = 8  # used in bert model\n",
        "    FF_DIM = 128  # used in bert model\n",
        "    NUM_LAYERS = 1\n",
        "\n",
        "\n",
        "config = Config()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YsOQzYeMPXKI"
      },
      "source": [
        "### 1 Carregar Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 543
        },
        "id": "CIej_V8zMmy4",
        "outputId": "df350979-a311-4699-e3b3-e785a1a59541"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-82b94ea5-f103-4c23-863f-b830500a4c71\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-82b94ea5-f103-4c23-863f-b830500a4c71\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving falas_chandler.txt to falas_chandler (1).txt\n",
            "Saving falas_joey.txt to falas_joey (1).txt\n",
            "Saving falas_monica.txt to falas_monica (1).txt\n",
            "Saving falas_phoebe.txt to falas_phoebe (1).txt\n",
            "Saving falas_rachel.txt to falas_rachel (1).txt\n",
            "Saving falas_ross.txt to falas_ross (1).txt\n",
            "      character                                               line\n",
            "6125   Chandler  Well y'know a lot of those Muppets don't have ...\n",
            "51332    Rachel                                               Why?\n",
            "52679    Rachel                                            Pheebs?\n",
            "17203      Joey                      That guy’s still doing that?!\n",
            "65311      Ross                                               Ohh…\n",
            "\n",
            "Total de falas carregadas: 65621\n",
            "character\n",
            "Rachel      11899\n",
            "Ross        11842\n",
            "Monica      10937\n",
            "Chandler    10858\n",
            "Joey        10545\n",
            "Phoebe       9540\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ],
      "source": [
        "#Recarregar a base de dados com os .txt dos 6 personagens\n",
        "from google.colab import files\n",
        "from collections import defaultdict\n",
        "import pandas as pd\n",
        "\n",
        "\n",
        "uploaded = files.upload()\n",
        "\n",
        "# Dicionário arquivos - personagens\n",
        "files = {\n",
        "    \"Chandler\": \"falas_chandler.txt\",\n",
        "    \"Joey\": \"falas_joey.txt\",\n",
        "    \"Monica\": \"falas_monica.txt\",\n",
        "    \"Phoebe\": \"falas_phoebe.txt\",\n",
        "    \"Rachel\": \"falas_rachel.txt\",\n",
        "    \"Ross\": \"falas_ross.txt\",\n",
        "}\n",
        "\n",
        "#Lista para armazenar\n",
        "all_lines = []\n",
        "\n",
        "#Leitura dos arquivos\n",
        "for character, filename in files.items():\n",
        "    with open(filename, \"r\", encoding=\"utf-8\") as f:\n",
        "        lines = f.readlines()\n",
        "        lines = [line.strip() for line in lines if line.strip()]\n",
        "        all_lines.extend([(character, line) for line in lines])\n",
        "\n",
        "#DataFrame\n",
        "df_friends = pd.DataFrame(all_lines, columns=[\"character\", \"line\"])\n",
        "\n",
        "\n",
        "print(df_friends.sample(5))\n",
        "print(f\"\\nTotal de falas carregadas: {len(df_friends)}\")\n",
        "print(df_friends['character'].value_counts())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p-lR4DiOQVou"
      },
      "source": [
        "### 2 Pré-processamento e Limpeza dos Dados"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sWzfzaxvQZ_H",
        "outputId": "8191a0af-2766-4e62-f5bf-6f629eb906b6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      character                                               line  \\\n",
            "24369    Monica          Have I read it?  No, are you enjoying it?   \n",
            "53839      Ross  Well, we just wanted to say a quick hi, and th...   \n",
            "937    Chandler                           Uh Kathy, with K or a C?   \n",
            "51080    Rachel  You know what, I can't do this. I don't know w...   \n",
            "38972    Phoebe  No! But it's the nicest kitchen, the refrigera...   \n",
            "\n",
            "                                              clean_line  \n",
            "24369             Have I read it  No are you enjoying it  \n",
            "53839  Well we just wanted to say a quick hi and then...  \n",
            "937                               Uh Kathy with K or a C  \n",
            "51080  You know what I can't do this I don't know whi...  \n",
            "38972  No But it's the nicest kitchen the refrigerato...  \n",
            "\n",
            "Total de falas após limpeza: 47813\n"
          ]
        }
      ],
      "source": [
        "import re\n",
        "\n",
        "def limpar_fala(fala):\n",
        "    #Remover colchetes e parênteses\n",
        "    fala = re.sub(r'\\[.*?\\]', '', fala)\n",
        "    fala = re.sub(r'\\(.*?\\)', '', fala)\n",
        "\n",
        "    #Remover pontuação\n",
        "    fala = re.sub(r\"[^\\w\\s']\", '', fala)\n",
        "\n",
        "    #Remover espaços nas extremidades\n",
        "    fala = fala.strip()\n",
        "\n",
        "    return fala\n",
        "\n",
        "df_friends[\"clean_line\"] = df_friends[\"line\"].apply(limpar_fala)\n",
        "\n",
        "#Remover falas muito curtas\n",
        "df_friends = df_friends[df_friends[\"clean_line\"].str.split().str.len() >= 4]\n",
        "\n",
        "print(df_friends.sample(5))\n",
        "print(f\"\\nTotal de falas após limpeza: {len(df_friends)}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ILgm0g97QswE",
        "outputId": "642cb3d8-df12-4900-cca6-5ef2d3d121fb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total de falas limpas: 47813\n",
            "Treino: 43031 | Teste: 4782\n"
          ]
        }
      ],
      "source": [
        "#Separa treino e teste\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "train_lines, test_lines = train_test_split(\n",
        "    df_friends[\"clean_line\"], test_size=0.1, random_state=42\n",
        ")\n",
        "\n",
        "train_df = pd.DataFrame({\"line\": train_lines})\n",
        "test_df = pd.DataFrame({\"line\": test_lines})\n",
        "all_data = pd.concat([train_df, test_df], ignore_index=True)\n",
        "\n",
        "# Visualizar\n",
        "print(f\"Total de falas limpas: {len(all_data)}\")\n",
        "print(f\"Treino: {len(train_df)} | Teste: {len(test_df)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "saG1F3C627gg"
      },
      "source": [
        "### 3 Preparando dados para o Treinamento com MLM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SxEpPUXPTQtT"
      },
      "outputs": [],
      "source": [
        "#preparar os dados pro treinamento com Masked Language Modeling (MLM)\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import TextVectorization\n",
        "\n",
        "\n",
        "\n",
        "def custom_standardization(input_data):\n",
        "    lowercase = tf.strings.lower(input_data)\n",
        "    stripped_html = tf.strings.regex_replace(lowercase, \"<br />\", \" \")\n",
        "    return tf.strings.regex_replace(\n",
        "        stripped_html, \"[%s]\" % re.escape(\"!#$%&'()*+,-./:;<=>?@\\^_`{|}~\"), \"\"\n",
        "    )\n",
        "\n",
        "\n",
        "def get_vectorize_layer(texts, vocab_size, max_seq, special_tokens=[\"[MASK]\"]):\n",
        "    vectorize_layer = TextVectorization(\n",
        "        max_tokens=vocab_size,\n",
        "        output_mode=\"int\",\n",
        "        output_sequence_length=max_seq,\n",
        "        standardize=custom_standardization\n",
        "    )\n",
        "    vectorize_layer.adapt(texts)\n",
        "\n",
        "    # Adiciona token [MASK] vocabulário\n",
        "    vocab = vectorize_layer.get_vocabulary()\n",
        "    vocab = vocab[2 : vocab_size - len(special_tokens)] + [\"[mask]\"]\n",
        "    vectorize_layer.set_vocabulary(vocab)\n",
        "\n",
        "    return vectorize_layer\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NumHlp_cUdvb"
      },
      "outputs": [],
      "source": [
        "#instanciar vectorize_layer\n",
        "vectorize_layer = get_vectorize_layer(\n",
        "    all_data.line.values.tolist(),\n",
        "    config.VOCAB_SIZE,\n",
        "    config.MAX_LEN,\n",
        "    special_tokens=[\"[mask]\"]\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QzJhetjOT2Po"
      },
      "outputs": [],
      "source": [
        "# Pega o id do token [MASK]\n",
        "mask_token_id = vectorize_layer([\"[mask]\"]).numpy()[0][0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "99CQqwsxUCaF"
      },
      "outputs": [],
      "source": [
        "def encode(texts):\n",
        "    encoded_texts = vectorize_layer(texts)\n",
        "    return encoded_texts.numpy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KWtK-_WTVCnI"
      },
      "outputs": [],
      "source": [
        "def get_masked_input_and_labels(encoded_texts, mask_token_id):\n",
        "    # 15% das posições serão consideradas para masking\n",
        "    inp_mask = np.random.rand(*encoded_texts.shape) < 0.15\n",
        "\n",
        "    # Evita mascarar tokens especiais (0 = PAD, 1 = UNK, 2 = START)\n",
        "    inp_mask[encoded_texts <= 2] = False\n",
        "\n",
        "    # Labels: -1 onde não há máscara (ignorar na loss)\n",
        "    labels = -1 * np.ones(encoded_texts.shape, dtype=int)\n",
        "    labels[inp_mask] = encoded_texts[inp_mask]\n",
        "\n",
        "    # Cria cópia para modificar as entradas mascaradas\n",
        "    encoded_texts_masked = np.copy(encoded_texts)\n",
        "\n",
        "    # 90% dos tokens mascarados viram [MASK]\n",
        "    inp_mask_2mask = inp_mask & (np.random.rand(*encoded_texts.shape) < 0.9)\n",
        "    encoded_texts_masked[inp_mask_2mask] = mask_token_id\n",
        "\n",
        "    # 10% dos tokens mascarados viram tokens aleatórios\n",
        "    inp_mask_2random = inp_mask_2mask & (np.random.rand(*encoded_texts.shape) < 1 / 9)\n",
        "    encoded_texts_masked[inp_mask_2random] = np.random.randint(\n",
        "        3, mask_token_id, inp_mask_2random.sum()\n",
        "    )\n",
        "\n",
        "    # Sample weights: 1 onde há máscara, 0 onde não há\n",
        "    sample_weights = np.ones(labels.shape)\n",
        "    sample_weights[labels == -1] = 0\n",
        "\n",
        "    return encoded_texts_masked, encoded_texts, sample_weights"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tyAZjxCzVeLe"
      },
      "outputs": [],
      "source": [
        "#preparar os dados para Masked Language Modeling\n",
        "x_all = encode(all_data.line.values)\n",
        "\n",
        "x_masked, y_labels, sample_weights = get_masked_input_and_labels(x_all, mask_token_id)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZyZjF3DbWDZ_"
      },
      "outputs": [],
      "source": [
        "#preparar os dados para Masked Language Modeling\n",
        "mlm_ds = tf.data.Dataset.from_tensor_slices(\n",
        "    (x_masked, y_labels, sample_weights)\n",
        ")\n",
        "\n",
        "mlm_ds = mlm_ds.shuffle(1000).batch(config.BATCH_SIZE)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pd3UiBNRbeL5"
      },
      "source": [
        "### 5 Modelagem BERT\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gGYe6Y1eXcGT"
      },
      "outputs": [],
      "source": [
        "#Criando o BERT model\n",
        "import keras_nlp\n",
        "\n",
        "\n",
        "def bert_module(query, key, value, i):\n",
        "    # Multi-headed Self-Attention\n",
        "    attention_output = layers.MultiHeadAttention(\n",
        "        num_heads=config.NUM_HEAD,\n",
        "        key_dim=config.EMBED_DIM // config.NUM_HEAD,\n",
        "        name=f\"encoder_{i}_multiheadattention\"\n",
        "    )(query, key, value)\n",
        "\n",
        "    # Dropout + Residual Connection + Layer Norm\n",
        "    attention_output = layers.Dropout(0.1, name=f\"encoder_{i}_att_dropout\")(attention_output)\n",
        "    attention_output = layers.LayerNormalization(\n",
        "        epsilon=1e-6, name=f\"encoder_{i}_att_layernormalization\"\n",
        "    )(query + attention_output)\n",
        "\n",
        "    # Feed Forward Network (FFN)\n",
        "    ffn = keras.Sequential([\n",
        "        layers.Dense(config.FF_DIM, activation=\"relu\"),\n",
        "        layers.Dense(config.EMBED_DIM),\n",
        "    ], name=f\"encoder_{i}_ffn\")\n",
        "\n",
        "    ffn_output = ffn(attention_output)\n",
        "\n",
        "    # Dropout + Residual Connection + Layer Norm\n",
        "    ffn_output = layers.Dropout(0.1, name=f\"encoder_{i}_ffn_dropout\")(ffn_output)\n",
        "    sequence_output = layers.LayerNormalization(\n",
        "        epsilon=1e-6, name=f\"encoder_{i}_ffn_layernormalization\"\n",
        "    )(attention_output + ffn_output)\n",
        "\n",
        "    return sequence_output\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h9Y2qFoTW_Fe"
      },
      "outputs": [],
      "source": [
        "#definição da função de loss e o método de rastreamento\n",
        "loss_fn = keras.losses.SparseCategoricalCrossentropy(reduction=None)\n",
        "loss_tracker = keras.metrics.Mean(name=\"loss\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WAhEkaApYoGZ"
      },
      "outputs": [],
      "source": [
        "class MaskedLanguageModel(keras.Model):\n",
        "\n",
        "    def compute_loss(self, x=None, y=None, y_pred=None, sample_weight=None):\n",
        "        loss = loss_fn(y, y_pred, sample_weight)\n",
        "        loss_tracker.update_state(loss, sample_weight=sample_weight)\n",
        "        return keras.ops.sum(loss)\n",
        "\n",
        "    def compute_metrics(self, x, y, y_pred, sample_weight):\n",
        "        return {\"loss\": loss_tracker.result()}\n",
        "\n",
        "    @property\n",
        "    def metrics(self):\n",
        "        return [loss_tracker]\n",
        "\n",
        "\n",
        "def create_masked_language_bert_model():\n",
        "    inputs = layers.Input((config.MAX_LEN,), dtype=\"int64\")\n",
        "\n",
        "    word_embeddings = layers.Embedding(\n",
        "        config.VOCAB_SIZE,\n",
        "        config.EMBED_DIM,\n",
        "        name=\"word_embedding\"\n",
        "    )(inputs)\n",
        "\n",
        "\n",
        "    position_embeddings = keras_nlp.layers.PositionEmbedding(\n",
        "        sequence_length=config.MAX_LEN\n",
        "    )(word_embeddings)\n",
        "\n",
        "\n",
        "    embeddings = word_embeddings + position_embeddings\n",
        "\n",
        "\n",
        "    encoder_output = embeddings\n",
        "    for i in range(config.NUM_LAYERS):\n",
        "        encoder_output = bert_module(\n",
        "            encoder_output, encoder_output, encoder_output, i\n",
        "        )\n",
        "\n",
        "\n",
        "    mlm_output = layers.Dense(\n",
        "        config.VOCAB_SIZE, activation=\"softmax\", name=\"mlm_cls\"\n",
        "    )(encoder_output)\n",
        "\n",
        "    #Modelo final\n",
        "    mlm_model = MaskedLanguageModel(inputs, mlm_output, name=\"masked_bert_model\")\n",
        "\n",
        "    #Compila com otimizador Adam e learning rate da config\n",
        "    optimizer = keras.optimizers.Adam(learning_rate=config.LR)\n",
        "    mlm_model.compile(optimizer=optimizer)\n",
        "\n",
        "    return mlm_model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CPVaqf_kZlH0"
      },
      "outputs": [],
      "source": [
        "#classe MaskedTextGenerator pra ser usada como callback durante o treino\n",
        "\n",
        "import numpy as np\n",
        "from pprint import pprint\n",
        "from tensorflow import keras\n",
        "\n",
        "class MaskedTextGenerator(keras.callbacks.Callback):\n",
        "    def __init__(self, sample_tokens, top_k=5):\n",
        "        self.sample_tokens = sample_tokens\n",
        "        self.k = top_k\n",
        "\n",
        "    def decode(self, tokens):\n",
        "        return \" \".join([id2token[t] for t in tokens if t != 0])\n",
        "\n",
        "    def convert_ids_to_tokens(self, id):\n",
        "        return id2token[id]\n",
        "\n",
        "    def on_epoch_end(self, epoch, logs=None):\n",
        "        prediction = self.model.predict(self.sample_tokens)\n",
        "\n",
        "        masked_index = np.where(self.sample_tokens == mask_token_id)\n",
        "        masked_index = masked_index[1]  # ignorar batch dim\n",
        "        mask_prediction = prediction[0][masked_index]\n",
        "\n",
        "        top_indices = mask_prediction[0].argsort()[-self.k:][::-1]\n",
        "        values = mask_prediction[0][top_indices]\n",
        "\n",
        "        for i in range(len(top_indices)):\n",
        "            p = top_indices[i]\n",
        "            v = values[i]\n",
        "            tokens = np.copy(self.sample_tokens[0])\n",
        "            tokens[masked_index[0]] = p\n",
        "            result = {\n",
        "                \"input_text\": self.decode(sample_tokens[0].numpy()),\n",
        "                \"prediction\": self.decode(tokens),\n",
        "                \"probability\": v,\n",
        "                \"predicted mask token\": self.convert_ids_to_tokens(p),\n",
        "            }\n",
        "            pprint(result)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RF3qnDibaRGj"
      },
      "outputs": [],
      "source": [
        "sample_tokens = vectorize_layer([\"Joey doesn't share [mask]!\"])\n",
        "generator_callback = MaskedTextGenerator(sample_tokens.numpy())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 800
        },
        "id": "pVcgyqAMaZwl",
        "outputId": "e04abe45-7e71-41f4-edf8-860db9100cb3"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"masked_bert_model\"</span>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1mModel: \"masked_bert_model\"\u001b[0m\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)        </span>┃<span style=\"font-weight: bold\"> Output Shape      </span>┃<span style=\"font-weight: bold\">    Param # </span>┃<span style=\"font-weight: bold\"> Connected to      </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
              "│ input_layer_19      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ word_embedding      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)  │  <span style=\"color: #00af00; text-decoration-color: #00af00\">3,840,000</span> │ input_layer_19[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ position_embedding… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)  │     <span style=\"color: #00af00; text-decoration-color: #00af00\">32,768</span> │ word_embedding[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">PositionEmbedding</span>) │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ add_39 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)  │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ word_embedding[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
              "│                     │                   │            │ position_embeddi… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ encoder_0_multihea… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)  │     <span style=\"color: #00af00; text-decoration-color: #00af00\">66,048</span> │ add_39[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],     │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MultiHeadAttentio…</span> │                   │            │ add_39[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],     │\n",
              "│                     │                   │            │ add_39[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ encoder_0_att_drop… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)  │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ encoder_0_multih… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)           │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ add_40 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)  │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ add_39[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],     │\n",
              "│                     │                   │            │ encoder_0_att_dr… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ encoder_0_att_laye… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)  │        <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │ add_40[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LayerNormalizatio…</span> │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ encoder_0_ffn       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)  │     <span style=\"color: #00af00; text-decoration-color: #00af00\">33,024</span> │ encoder_0_att_la… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Sequential</span>)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ encoder_0_ffn_drop… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)  │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ encoder_0_ffn[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)           │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ add_41 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)  │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ encoder_0_att_la… │\n",
              "│                     │                   │            │ encoder_0_ffn_dr… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ encoder_0_ffn_laye… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)  │        <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │ add_41[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LayerNormalizatio…</span> │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ mlm_cls (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>,       │  <span style=\"color: #00af00; text-decoration-color: #00af00\">3,870,000</span> │ encoder_0_ffn_la… │\n",
              "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">30000</span>)            │            │                   │\n",
              "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n",
              "</pre>\n"
            ],
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
              "│ input_layer_19      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
              "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ word_embedding      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m128\u001b[0m)  │  \u001b[38;5;34m3,840,000\u001b[0m │ input_layer_19[\u001b[38;5;34m0\u001b[0m… │\n",
              "│ (\u001b[38;5;33mEmbedding\u001b[0m)         │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ position_embedding… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m128\u001b[0m)  │     \u001b[38;5;34m32,768\u001b[0m │ word_embedding[\u001b[38;5;34m0\u001b[0m… │\n",
              "│ (\u001b[38;5;33mPositionEmbedding\u001b[0m) │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ add_39 (\u001b[38;5;33mAdd\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m128\u001b[0m)  │          \u001b[38;5;34m0\u001b[0m │ word_embedding[\u001b[38;5;34m0\u001b[0m… │\n",
              "│                     │                   │            │ position_embeddi… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ encoder_0_multihea… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m128\u001b[0m)  │     \u001b[38;5;34m66,048\u001b[0m │ add_39[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],     │\n",
              "│ (\u001b[38;5;33mMultiHeadAttentio…\u001b[0m │                   │            │ add_39[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],     │\n",
              "│                     │                   │            │ add_39[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ encoder_0_att_drop… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m128\u001b[0m)  │          \u001b[38;5;34m0\u001b[0m │ encoder_0_multih… │\n",
              "│ (\u001b[38;5;33mDropout\u001b[0m)           │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ add_40 (\u001b[38;5;33mAdd\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m128\u001b[0m)  │          \u001b[38;5;34m0\u001b[0m │ add_39[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],     │\n",
              "│                     │                   │            │ encoder_0_att_dr… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ encoder_0_att_laye… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m128\u001b[0m)  │        \u001b[38;5;34m256\u001b[0m │ add_40[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      │\n",
              "│ (\u001b[38;5;33mLayerNormalizatio…\u001b[0m │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ encoder_0_ffn       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m128\u001b[0m)  │     \u001b[38;5;34m33,024\u001b[0m │ encoder_0_att_la… │\n",
              "│ (\u001b[38;5;33mSequential\u001b[0m)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ encoder_0_ffn_drop… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m128\u001b[0m)  │          \u001b[38;5;34m0\u001b[0m │ encoder_0_ffn[\u001b[38;5;34m0\u001b[0m]… │\n",
              "│ (\u001b[38;5;33mDropout\u001b[0m)           │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ add_41 (\u001b[38;5;33mAdd\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m128\u001b[0m)  │          \u001b[38;5;34m0\u001b[0m │ encoder_0_att_la… │\n",
              "│                     │                   │            │ encoder_0_ffn_dr… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ encoder_0_ffn_laye… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m128\u001b[0m)  │        \u001b[38;5;34m256\u001b[0m │ add_41[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      │\n",
              "│ (\u001b[38;5;33mLayerNormalizatio…\u001b[0m │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ mlm_cls (\u001b[38;5;33mDense\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m,       │  \u001b[38;5;34m3,870,000\u001b[0m │ encoder_0_ffn_la… │\n",
              "│                     │ \u001b[38;5;34m30000\u001b[0m)            │            │                   │\n",
              "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">7,842,352</span> (29.92 MB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m7,842,352\u001b[0m (29.92 MB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">7,842,352</span> (29.92 MB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m7,842,352\u001b[0m (29.92 MB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "#Instancia o modelo\n",
        "bert_masked_model = create_masked_language_bert_model()\n",
        "bert_masked_model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "AU94FIq-anPD",
        "outputId": "5f421569-693f-4b4e-c65c-9f40e127ba59"
      },
      "outputs": [
        {
          "data": {
            "application/javascript": "\n    async function download(id, filename, size) {\n      if (!google.colab.kernel.accessAllowed) {\n        return;\n      }\n      const div = document.createElement('div');\n      const label = document.createElement('label');\n      label.textContent = `Downloading \"${filename}\": `;\n      div.appendChild(label);\n      const progress = document.createElement('progress');\n      progress.max = size;\n      div.appendChild(progress);\n      document.body.appendChild(div);\n\n      const buffers = [];\n      let downloaded = 0;\n\n      const channel = await google.colab.kernel.comms.open(id);\n      // Send a message to notify the kernel that we're ready.\n      channel.send({})\n\n      for await (const message of channel.messages) {\n        // Send a message to notify the kernel that we're ready.\n        channel.send({})\n        if (message.buffers) {\n          for (const buffer of message.buffers) {\n            buffers.push(buffer);\n            downloaded += buffer.byteLength;\n            progress.value = downloaded;\n          }\n        }\n      }\n      const blob = new Blob(buffers, {type: 'application/binary'});\n      const a = document.createElement('a');\n      a.href = window.URL.createObjectURL(blob);\n      a.download = filename;\n      div.appendChild(a);\n      a.click();\n      div.remove();\n    }\n  ",
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/javascript": "download(\"download_2bdd393b-4d53-411d-91c8-45d5608a8281\", \"bert_mlm_friends.keras\", 31435422)",
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "#Salvar o modelo\n",
        "bert_masked_model.save(\"bert_mlm_friends.keras\")\n",
        "from google.colab import files\n",
        "files.download(\"bert_mlm_friends.keras\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VjqvmzUBbi4V"
      },
      "source": [
        "### 6 Realizar Treinamento do Modelo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F53wCmWba5iP",
        "outputId": "584f10c6-9248-485f-cc46-10c5401d5e23"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 962ms/step\n",
            "{'input_text': 'going ii iim communicating',\n",
            " 'predicted mask token': np.str_('i'),\n",
            " 'prediction': 'going ii iim i',\n",
            " 'probability': np.float32(0.040982)}\n",
            "{'input_text': 'going ii iim communicating',\n",
            " 'predicted mask token': np.str_('you'),\n",
            " 'prediction': 'going ii iim you',\n",
            " 'probability': np.float32(0.024867315)}\n",
            "{'input_text': 'going ii iim communicating',\n",
            " 'predicted mask token': np.str_('to'),\n",
            " 'prediction': 'going ii iim to',\n",
            " 'probability': np.float32(0.023333289)}\n",
            "{'input_text': 'going ii iim communicating',\n",
            " 'predicted mask token': np.str_('the'),\n",
            " 'prediction': 'going ii iim the',\n",
            " 'probability': np.float32(0.023098402)}\n",
            "{'input_text': 'going ii iim communicating',\n",
            " 'predicted mask token': np.str_('[rachel]'),\n",
            " 'prediction': 'going ii iim [rachel]',\n",
            " 'probability': np.float32(0.0139482645)}\n",
            "\n",
            "Epoch 1: loss improved from inf to 6.40247, saving model to checkpoints_friends/bert_mlm_best.keras\n",
            "\u001b[1m1495/1495\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 17ms/step - loss: 6.7936\n",
            "Epoch 2/5\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step\n",
            "{'input_text': 'going ii iim communicating',\n",
            " 'predicted mask token': np.str_('to'),\n",
            " 'prediction': 'going ii iim to',\n",
            " 'probability': np.float32(0.041291494)}\n",
            "{'input_text': 'going ii iim communicating',\n",
            " 'predicted mask token': np.str_('was'),\n",
            " 'prediction': 'going ii iim was',\n",
            " 'probability': np.float32(0.02522082)}\n",
            "{'input_text': 'going ii iim communicating',\n",
            " 'predicted mask token': np.str_('you'),\n",
            " 'prediction': 'going ii iim you',\n",
            " 'probability': np.float32(0.021877205)}\n",
            "{'input_text': 'going ii iim communicating',\n",
            " 'predicted mask token': np.str_('in'),\n",
            " 'prediction': 'going ii iim in',\n",
            " 'probability': np.float32(0.01875844)}\n",
            "{'input_text': 'going ii iim communicating',\n",
            " 'predicted mask token': np.str_('of'),\n",
            " 'prediction': 'going ii iim of',\n",
            " 'probability': np.float32(0.018049035)}\n",
            "\n",
            "Epoch 2: loss improved from 6.40247 to 5.60381, saving model to checkpoints_friends/bert_mlm_best.keras\n",
            "\u001b[1m1495/1495\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 13ms/step - loss: 5.6835\n",
            "Epoch 3/5\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step\n",
            "{'input_text': 'going ii iim communicating',\n",
            " 'predicted mask token': np.str_('[ross]'),\n",
            " 'prediction': 'going ii iim [ross]',\n",
            " 'probability': np.float32(0.26840535)}\n",
            "{'input_text': 'going ii iim communicating',\n",
            " 'predicted mask token': np.str_('[rachel]'),\n",
            " 'prediction': 'going ii iim [rachel]',\n",
            " 'probability': np.float32(0.05109162)}\n",
            "{'input_text': 'going ii iim communicating',\n",
            " 'predicted mask token': np.str_('yknow'),\n",
            " 'prediction': 'going ii iim yknow',\n",
            " 'probability': np.float32(0.022359785)}\n",
            "{'input_text': 'going ii iim communicating',\n",
            " 'predicted mask token': np.str_('to'),\n",
            " 'prediction': 'going ii iim to',\n",
            " 'probability': np.float32(0.021113466)}\n",
            "{'input_text': 'going ii iim communicating',\n",
            " 'predicted mask token': np.str_('you'),\n",
            " 'prediction': 'going ii iim you',\n",
            " 'probability': np.float32(0.017963693)}\n",
            "\n",
            "Epoch 3: loss improved from 5.60381 to 4.94631, saving model to checkpoints_friends/bert_mlm_best.keras\n",
            "\u001b[1m1495/1495\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 13ms/step - loss: 5.0698\n",
            "Epoch 4/5\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step\n",
            "{'input_text': 'going ii iim communicating',\n",
            " 'predicted mask token': np.str_('[ross]'),\n",
            " 'prediction': 'going ii iim [ross]',\n",
            " 'probability': np.float32(0.18136786)}\n",
            "{'input_text': 'going ii iim communicating',\n",
            " 'predicted mask token': np.str_('is'),\n",
            " 'prediction': 'going ii iim is',\n",
            " 'probability': np.float32(0.06357376)}\n",
            "{'input_text': 'going ii iim communicating',\n",
            " 'predicted mask token': np.str_('[rachel]'),\n",
            " 'prediction': 'going ii iim [rachel]',\n",
            " 'probability': np.float32(0.04364338)}\n",
            "{'input_text': 'going ii iim communicating',\n",
            " 'predicted mask token': np.str_('yknow'),\n",
            " 'prediction': 'going ii iim yknow',\n",
            " 'probability': np.float32(0.034852993)}\n",
            "{'input_text': 'going ii iim communicating',\n",
            " 'predicted mask token': np.str_('this'),\n",
            " 'prediction': 'going ii iim this',\n",
            " 'probability': np.float32(0.030964695)}\n",
            "\n",
            "Epoch 4: loss improved from 4.94631 to 4.27023, saving model to checkpoints_friends/bert_mlm_best.keras\n",
            "\u001b[1m1495/1495\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 13ms/step - loss: 4.4003\n",
            "Epoch 5/5\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step\n",
            "{'input_text': 'going ii iim communicating',\n",
            " 'predicted mask token': np.str_('this'),\n",
            " 'prediction': 'going ii iim this',\n",
            " 'probability': np.float32(0.6741257)}\n",
            "{'input_text': 'going ii iim communicating',\n",
            " 'predicted mask token': np.str_('you'),\n",
            " 'prediction': 'going ii iim you',\n",
            " 'probability': np.float32(0.03570128)}\n",
            "{'input_text': 'going ii iim communicating',\n",
            " 'predicted mask token': np.str_('[ross]'),\n",
            " 'prediction': 'going ii iim [ross]',\n",
            " 'probability': np.float32(0.029033143)}\n",
            "{'input_text': 'going ii iim communicating',\n",
            " 'predicted mask token': np.str_('is'),\n",
            " 'prediction': 'going ii iim is',\n",
            " 'probability': np.float32(0.018998526)}\n",
            "{'input_text': 'going ii iim communicating',\n",
            " 'predicted mask token': np.str_('her'),\n",
            " 'prediction': 'going ii iim her',\n",
            " 'probability': np.float32(0.009932478)}\n",
            "\n",
            "Epoch 5: loss improved from 4.27023 to 3.62856, saving model to checkpoints_friends/bert_mlm_best.keras\n",
            "\u001b[1m1495/1495\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 13ms/step - loss: 3.7579\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x79917873e410>"
            ]
          },
          "execution_count": 73,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import os\n",
        "\n",
        "checkpoint_dir = \"checkpoints_friends\"\n",
        "os.makedirs(checkpoint_dir, exist_ok=True)\n",
        "\n",
        "checkpoint_cb = keras.callbacks.ModelCheckpoint(\n",
        "    filepath=os.path.join(checkpoint_dir, \"bert_mlm_best.keras\"),\n",
        "    monitor=\"loss\",\n",
        "    save_best_only=True,\n",
        "    save_weights_only=False,\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "bert_masked_model.fit(\n",
        "    mlm_ds,\n",
        "    epochs=5,\n",
        "    callbacks=[generator_callback, checkpoint_cb]\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I5H4ZfB2cCCQ",
        "outputId": "94560f4c-cd89-4d62-e715-4b3fd1ffc080"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 6/7\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step\n",
            "{'input_text': 'going ii iim communicating',\n",
            " 'predicted mask token': np.str_('this'),\n",
            " 'prediction': 'going ii iim this',\n",
            " 'probability': np.float32(0.6719368)}\n",
            "{'input_text': 'going ii iim communicating',\n",
            " 'predicted mask token': np.str_('is'),\n",
            " 'prediction': 'going ii iim is',\n",
            " 'probability': np.float32(0.042136025)}\n",
            "{'input_text': 'going ii iim communicating',\n",
            " 'predicted mask token': np.str_('you'),\n",
            " 'prediction': 'going ii iim you',\n",
            " 'probability': np.float32(0.037505284)}\n",
            "{'input_text': 'going ii iim communicating',\n",
            " 'predicted mask token': np.str_('mom'),\n",
            " 'prediction': 'going ii iim mom',\n",
            " 'probability': np.float32(0.023680525)}\n",
            "{'input_text': 'going ii iim communicating',\n",
            " 'predicted mask token': np.str_('harder'),\n",
            " 'prediction': 'going ii iim harder',\n",
            " 'probability': np.float32(0.02169537)}\n",
            "\n",
            "Epoch 6: loss improved from 3.62856 to 3.06527, saving model to checkpoints_friends/bert_mlm_best.keras\n",
            "\u001b[1m1495/1495\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 13ms/step - loss: 3.1877\n",
            "Epoch 7/7\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step\n",
            "{'input_text': 'going ii iim communicating',\n",
            " 'predicted mask token': np.str_('this'),\n",
            " 'prediction': 'going ii iim this',\n",
            " 'probability': np.float32(0.7977274)}\n",
            "{'input_text': 'going ii iim communicating',\n",
            " 'predicted mask token': np.str_('you'),\n",
            " 'prediction': 'going ii iim you',\n",
            " 'probability': np.float32(0.12842551)}\n",
            "{'input_text': 'going ii iim communicating',\n",
            " 'predicted mask token': np.str_('mom'),\n",
            " 'prediction': 'going ii iim mom',\n",
            " 'probability': np.float32(0.012770999)}\n",
            "{'input_text': 'going ii iim communicating',\n",
            " 'predicted mask token': np.str_('is'),\n",
            " 'prediction': 'going ii iim is',\n",
            " 'probability': np.float32(0.009073145)}\n",
            "{'input_text': 'going ii iim communicating',\n",
            " 'predicted mask token': np.str_('tribbiani'),\n",
            " 'prediction': 'going ii iim tribbiani',\n",
            " 'probability': np.float32(0.008830521)}\n",
            "\n",
            "Epoch 7: loss improved from 3.06527 to 2.56675, saving model to checkpoints_friends/bert_mlm_best.keras\n",
            "\u001b[1m1495/1495\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 13ms/step - loss: 2.6731\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x799109d12010>"
            ]
          },
          "execution_count": 74,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#rodar mais 2\n",
        "bert_masked_model.fit(\n",
        "    mlm_ds,\n",
        "    epochs=7,  # continua até a época 7\n",
        "    initial_epoch=5,  # começa da época 5\n",
        "    callbacks=[generator_callback, checkpoint_cb]\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UmgYZKBseXAf",
        "outputId": "4617abe8-a75a-4bf6-e9a9-10954aa0733b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 8/10\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step\n",
            "{'input_text': 'going ii iim communicating',\n",
            " 'predicted mask token': np.str_('this'),\n",
            " 'prediction': 'going ii iim this',\n",
            " 'probability': np.float32(0.40503013)}\n",
            "{'input_text': 'going ii iim communicating',\n",
            " 'predicted mask token': np.str_('seen'),\n",
            " 'prediction': 'going ii iim seen',\n",
            " 'probability': np.float32(0.17932491)}\n",
            "{'input_text': 'going ii iim communicating',\n",
            " 'predicted mask token': np.str_('harder'),\n",
            " 'prediction': 'going ii iim harder',\n",
            " 'probability': np.float32(0.087055266)}\n",
            "{'input_text': 'going ii iim communicating',\n",
            " 'predicted mask token': np.str_('you'),\n",
            " 'prediction': 'going ii iim you',\n",
            " 'probability': np.float32(0.05066796)}\n",
            "{'input_text': 'going ii iim communicating',\n",
            " 'predicted mask token': np.str_('7'),\n",
            " 'prediction': 'going ii iim 7',\n",
            " 'probability': np.float32(0.030557258)}\n",
            "\n",
            "Epoch 8: loss improved from 2.56675 to 2.16814, saving model to checkpoints_friends/bert_mlm_best.keras\n",
            "\u001b[1m1495/1495\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 13ms/step - loss: 2.2498\n",
            "Epoch 9/10\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step\n",
            "{'input_text': 'going ii iim communicating',\n",
            " 'predicted mask token': np.str_('this'),\n",
            " 'prediction': 'going ii iim this',\n",
            " 'probability': np.float32(0.6193705)}\n",
            "{'input_text': 'going ii iim communicating',\n",
            " 'predicted mask token': np.str_('you'),\n",
            " 'prediction': 'going ii iim you',\n",
            " 'probability': np.float32(0.3089942)}\n",
            "{'input_text': 'going ii iim communicating',\n",
            " 'predicted mask token': np.str_('im'),\n",
            " 'prediction': 'going ii iim im',\n",
            " 'probability': np.float32(0.014740978)}\n",
            "{'input_text': 'going ii iim communicating',\n",
            " 'predicted mask token': np.str_('is'),\n",
            " 'prediction': 'going ii iim is',\n",
            " 'probability': np.float32(0.008119493)}\n",
            "{'input_text': 'going ii iim communicating',\n",
            " 'predicted mask token': np.str_('her'),\n",
            " 'prediction': 'going ii iim her',\n",
            " 'probability': np.float32(0.004767828)}\n",
            "\n",
            "Epoch 9: loss improved from 2.16814 to 1.87671, saving model to checkpoints_friends/bert_mlm_best.keras\n",
            "\u001b[1m1495/1495\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 13ms/step - loss: 1.9397\n",
            "Epoch 10/10\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step\n",
            "{'input_text': 'going ii iim communicating',\n",
            " 'predicted mask token': np.str_('this'),\n",
            " 'prediction': 'going ii iim this',\n",
            " 'probability': np.float32(0.844412)}\n",
            "{'input_text': 'going ii iim communicating',\n",
            " 'predicted mask token': np.str_('you'),\n",
            " 'prediction': 'going ii iim you',\n",
            " 'probability': np.float32(0.059979826)}\n",
            "{'input_text': 'going ii iim communicating',\n",
            " 'predicted mask token': np.str_('im'),\n",
            " 'prediction': 'going ii iim im',\n",
            " 'probability': np.float32(0.021914184)}\n",
            "{'input_text': 'going ii iim communicating',\n",
            " 'predicted mask token': np.str_('looked'),\n",
            " 'prediction': 'going ii iim looked',\n",
            " 'probability': np.float32(0.017049963)}\n",
            "{'input_text': 'going ii iim communicating',\n",
            " 'predicted mask token': np.str_('harder'),\n",
            " 'prediction': 'going ii iim harder',\n",
            " 'probability': np.float32(0.00630016)}\n",
            "\n",
            "Epoch 10: loss improved from 1.87671 to 1.65084, saving model to checkpoints_friends/bert_mlm_best.keras\n",
            "\u001b[1m1495/1495\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 13ms/step - loss: 1.6978\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x799109c7b410>"
            ]
          },
          "execution_count": 75,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#rodar mais 2\n",
        "bert_masked_model.fit(\n",
        "    mlm_ds,\n",
        "    epochs=10,  # continua até a época 7\n",
        "    initial_epoch=7,  # começa da época 5\n",
        "    callbacks=[generator_callback, checkpoint_cb]\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mNjzBuyMexf2",
        "outputId": "02121b1d-dd3b-4048-cda1-4d9a6bf183e2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 11/12\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step\n",
            "{'input_text': 'going ii iim communicating',\n",
            " 'predicted mask token': np.str_('this'),\n",
            " 'prediction': 'going ii iim this',\n",
            " 'probability': np.float32(0.64479685)}\n",
            "{'input_text': 'going ii iim communicating',\n",
            " 'predicted mask token': np.str_('seen'),\n",
            " 'prediction': 'going ii iim seen',\n",
            " 'probability': np.float32(0.11941394)}\n",
            "{'input_text': 'going ii iim communicating',\n",
            " 'predicted mask token': np.str_('im'),\n",
            " 'prediction': 'going ii iim im',\n",
            " 'probability': np.float32(0.04871526)}\n",
            "{'input_text': 'going ii iim communicating',\n",
            " 'predicted mask token': np.str_('you'),\n",
            " 'prediction': 'going ii iim you',\n",
            " 'probability': np.float32(0.04315217)}\n",
            "{'input_text': 'going ii iim communicating',\n",
            " 'predicted mask token': np.str_('ursula'),\n",
            " 'prediction': 'going ii iim ursula',\n",
            " 'probability': np.float32(0.023290662)}\n",
            "\n",
            "Epoch 11: loss improved from 1.65084 to 1.48229, saving model to checkpoints_friends/bert_mlm_best.keras\n",
            "\u001b[1m1495/1495\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 13ms/step - loss: 1.5227\n",
            "Epoch 12/12\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step\n",
            "{'input_text': 'going ii iim communicating',\n",
            " 'predicted mask token': np.str_('this'),\n",
            " 'prediction': 'going ii iim this',\n",
            " 'probability': np.float32(0.8396721)}\n",
            "{'input_text': 'going ii iim communicating',\n",
            " 'predicted mask token': np.str_('you'),\n",
            " 'prediction': 'going ii iim you',\n",
            " 'probability': np.float32(0.12527715)}\n",
            "{'input_text': 'going ii iim communicating',\n",
            " 'predicted mask token': np.str_('im'),\n",
            " 'prediction': 'going ii iim im',\n",
            " 'probability': np.float32(0.008350993)}\n",
            "{'input_text': 'going ii iim communicating',\n",
            " 'predicted mask token': np.str_('seen'),\n",
            " 'prediction': 'going ii iim seen',\n",
            " 'probability': np.float32(0.0061217607)}\n",
            "{'input_text': 'going ii iim communicating',\n",
            " 'predicted mask token': np.str_('exactly'),\n",
            " 'prediction': 'going ii iim exactly',\n",
            " 'probability': np.float32(0.0039449595)}\n",
            "\n",
            "Epoch 12: loss improved from 1.48229 to 1.33854, saving model to checkpoints_friends/bert_mlm_best.keras\n",
            "\u001b[1m1495/1495\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 13ms/step - loss: 1.3678\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x7991783f4410>"
            ]
          },
          "execution_count": 76,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#rodar mais 2\n",
        "bert_masked_model.fit(\n",
        "    mlm_ds,\n",
        "    epochs=12,  # continua até a época 7\n",
        "    initial_epoch=10,  # começa da época 5\n",
        "    callbacks=[generator_callback, checkpoint_cb]\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AmfIWQO5fVpy",
        "outputId": "c5f62762-7377-42bc-cd28-8e3b69c0514d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 13/15\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step\n",
            "{'input_text': 'going ii iim communicating',\n",
            " 'predicted mask token': np.str_('this'),\n",
            " 'prediction': 'going ii iim this',\n",
            " 'probability': np.float32(0.7591521)}\n",
            "{'input_text': 'going ii iim communicating',\n",
            " 'predicted mask token': np.str_('seen'),\n",
            " 'prediction': 'going ii iim seen',\n",
            " 'probability': np.float32(0.11133392)}\n",
            "{'input_text': 'going ii iim communicating',\n",
            " 'predicted mask token': np.str_('you'),\n",
            " 'prediction': 'going ii iim you',\n",
            " 'probability': np.float32(0.060507078)}\n",
            "{'input_text': 'going ii iim communicating',\n",
            " 'predicted mask token': np.str_('im'),\n",
            " 'prediction': 'going ii iim im',\n",
            " 'probability': np.float32(0.018963253)}\n",
            "{'input_text': 'going ii iim communicating',\n",
            " 'predicted mask token': np.str_('exactly'),\n",
            " 'prediction': 'going ii iim exactly',\n",
            " 'probability': np.float32(0.00856397)}\n",
            "\n",
            "Epoch 13: loss improved from 1.33854 to 1.21694, saving model to checkpoints_friends/bert_mlm_best.keras\n",
            "\u001b[1m1495/1495\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 13ms/step - loss: 1.2394\n",
            "Epoch 14/15\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step\n",
            "{'input_text': 'going ii iim communicating',\n",
            " 'predicted mask token': np.str_('this'),\n",
            " 'prediction': 'going ii iim this',\n",
            " 'probability': np.float32(0.894959)}\n",
            "{'input_text': 'going ii iim communicating',\n",
            " 'predicted mask token': np.str_('you'),\n",
            " 'prediction': 'going ii iim you',\n",
            " 'probability': np.float32(0.04451194)}\n",
            "{'input_text': 'going ii iim communicating',\n",
            " 'predicted mask token': np.str_('seen'),\n",
            " 'prediction': 'going ii iim seen',\n",
            " 'probability': np.float32(0.028446509)}\n",
            "{'input_text': 'going ii iim communicating',\n",
            " 'predicted mask token': np.str_('im'),\n",
            " 'prediction': 'going ii iim im',\n",
            " 'probability': np.float32(0.005462026)}\n",
            "{'input_text': 'going ii iim communicating',\n",
            " 'predicted mask token': np.str_('ago'),\n",
            " 'prediction': 'going ii iim ago',\n",
            " 'probability': np.float32(0.003855118)}\n",
            "\n",
            "Epoch 14: loss improved from 1.21694 to 1.11291, saving model to checkpoints_friends/bert_mlm_best.keras\n",
            "\u001b[1m1495/1495\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 13ms/step - loss: 1.1269\n",
            "Epoch 15/15\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step\n",
            "{'input_text': 'going ii iim communicating',\n",
            " 'predicted mask token': np.str_('this'),\n",
            " 'prediction': 'going ii iim this',\n",
            " 'probability': np.float32(0.7695941)}\n",
            "{'input_text': 'going ii iim communicating',\n",
            " 'predicted mask token': np.str_('im'),\n",
            " 'prediction': 'going ii iim im',\n",
            " 'probability': np.float32(0.073584676)}\n",
            "{'input_text': 'going ii iim communicating',\n",
            " 'predicted mask token': np.str_('seen'),\n",
            " 'prediction': 'going ii iim seen',\n",
            " 'probability': np.float32(0.063273124)}\n",
            "{'input_text': 'going ii iim communicating',\n",
            " 'predicted mask token': np.str_('7'),\n",
            " 'prediction': 'going ii iim 7',\n",
            " 'probability': np.float32(0.0148141105)}\n",
            "{'input_text': 'going ii iim communicating',\n",
            " 'predicted mask token': np.str_('ago'),\n",
            " 'prediction': 'going ii iim ago',\n",
            " 'probability': np.float32(0.0146324895)}\n",
            "\n",
            "Epoch 15: loss improved from 1.11291 to 1.02732, saving model to checkpoints_friends/bert_mlm_best.keras\n",
            "\u001b[1m1495/1495\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 13ms/step - loss: 1.0374\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x799148686390>"
            ]
          },
          "execution_count": 77,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#rodar mais 2\n",
        "bert_masked_model.fit(\n",
        "    mlm_ds,\n",
        "    epochs=15,  # continua até a época 7\n",
        "    initial_epoch=12,  # começa da época 5\n",
        "    callbacks=[generator_callback, checkpoint_cb]\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-jy5Q2RxfmEa",
        "outputId": "fc532518-dc78-440a-d925-c446dd300f02"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 16/17\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step\n",
            "{'input_text': 'going ii iim communicating',\n",
            " 'predicted mask token': np.str_('this'),\n",
            " 'prediction': 'going ii iim this',\n",
            " 'probability': np.float32(0.7054083)}\n",
            "{'input_text': 'going ii iim communicating',\n",
            " 'predicted mask token': np.str_('isnt'),\n",
            " 'prediction': 'going ii iim isnt',\n",
            " 'probability': np.float32(0.07002288)}\n",
            "{'input_text': 'going ii iim communicating',\n",
            " 'predicted mask token': np.str_('seen'),\n",
            " 'prediction': 'going ii iim seen',\n",
            " 'probability': np.float32(0.059161764)}\n",
            "{'input_text': 'going ii iim communicating',\n",
            " 'predicted mask token': np.str_('7'),\n",
            " 'prediction': 'going ii iim 7',\n",
            " 'probability': np.float32(0.030903662)}\n",
            "{'input_text': 'going ii iim communicating',\n",
            " 'predicted mask token': np.str_('ago'),\n",
            " 'prediction': 'going ii iim ago',\n",
            " 'probability': np.float32(0.017364075)}\n",
            "\n",
            "Epoch 16: loss improved from 1.02732 to 0.94614, saving model to checkpoints_friends/bert_mlm_best.keras\n",
            "\u001b[1m1495/1495\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 13ms/step - loss: 0.9556\n",
            "Epoch 17/17\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step\n",
            "{'input_text': 'going ii iim communicating',\n",
            " 'predicted mask token': np.str_('this'),\n",
            " 'prediction': 'going ii iim this',\n",
            " 'probability': np.float32(0.5622679)}\n",
            "{'input_text': 'going ii iim communicating',\n",
            " 'predicted mask token': np.str_('nancy'),\n",
            " 'prediction': 'going ii iim nancy',\n",
            " 'probability': np.float32(0.0793631)}\n",
            "{'input_text': 'going ii iim communicating',\n",
            " 'predicted mask token': np.str_('7'),\n",
            " 'prediction': 'going ii iim 7',\n",
            " 'probability': np.float32(0.052701253)}\n",
            "{'input_text': 'going ii iim communicating',\n",
            " 'predicted mask token': np.str_('isnt'),\n",
            " 'prediction': 'going ii iim isnt',\n",
            " 'probability': np.float32(0.047148835)}\n",
            "{'input_text': 'going ii iim communicating',\n",
            " 'predicted mask token': np.str_('pretty'),\n",
            " 'prediction': 'going ii iim pretty',\n",
            " 'probability': np.float32(0.021057907)}\n",
            "\n",
            "Epoch 17: loss improved from 0.94614 to 0.88186, saving model to checkpoints_friends/bert_mlm_best.keras\n",
            "\u001b[1m1495/1495\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 13ms/step - loss: 0.8946\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x799210743450>"
            ]
          },
          "execution_count": 78,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#rodar mais 2\n",
        "bert_masked_model.fit(\n",
        "    mlm_ds,\n",
        "    epochs=17,  # continua até a época 7\n",
        "    initial_epoch=15,  # começa da época 5\n",
        "    callbacks=[generator_callback, checkpoint_cb]\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "9i75oNptggHg",
        "outputId": "ad229a6b-9b45-48ba-d43c-01c728e5ee7e"
      },
      "outputs": [
        {
          "data": {
            "application/javascript": "\n    async function download(id, filename, size) {\n      if (!google.colab.kernel.accessAllowed) {\n        return;\n      }\n      const div = document.createElement('div');\n      const label = document.createElement('label');\n      label.textContent = `Downloading \"${filename}\": `;\n      div.appendChild(label);\n      const progress = document.createElement('progress');\n      progress.max = size;\n      div.appendChild(progress);\n      document.body.appendChild(div);\n\n      const buffers = [];\n      let downloaded = 0;\n\n      const channel = await google.colab.kernel.comms.open(id);\n      // Send a message to notify the kernel that we're ready.\n      channel.send({})\n\n      for await (const message of channel.messages) {\n        // Send a message to notify the kernel that we're ready.\n        channel.send({})\n        if (message.buffers) {\n          for (const buffer of message.buffers) {\n            buffers.push(buffer);\n            downloaded += buffer.byteLength;\n            progress.value = downloaded;\n          }\n        }\n      }\n      const blob = new Blob(buffers, {type: 'application/binary'});\n      const a = document.createElement('a');\n      a.href = window.URL.createObjectURL(blob);\n      a.download = filename;\n      div.appendChild(a);\n      a.click();\n      div.remove();\n    }\n  ",
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/javascript": "download(\"download_d4a88bcb-9445-4e05-863d-e772b61ee684\", \"bert_mlm_friends_final.keras\", 94188974)",
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/javascript": "\n    async function download(id, filename, size) {\n      if (!google.colab.kernel.accessAllowed) {\n        return;\n      }\n      const div = document.createElement('div');\n      const label = document.createElement('label');\n      label.textContent = `Downloading \"${filename}\": `;\n      div.appendChild(label);\n      const progress = document.createElement('progress');\n      progress.max = size;\n      div.appendChild(progress);\n      document.body.appendChild(div);\n\n      const buffers = [];\n      let downloaded = 0;\n\n      const channel = await google.colab.kernel.comms.open(id);\n      // Send a message to notify the kernel that we're ready.\n      channel.send({})\n\n      for await (const message of channel.messages) {\n        // Send a message to notify the kernel that we're ready.\n        channel.send({})\n        if (message.buffers) {\n          for (const buffer of message.buffers) {\n            buffers.push(buffer);\n            downloaded += buffer.byteLength;\n            progress.value = downloaded;\n          }\n        }\n      }\n      const blob = new Blob(buffers, {type: 'application/binary'});\n      const a = document.createElement('a');\n      a.href = window.URL.createObjectURL(blob);\n      a.download = filename;\n      div.appendChild(a);\n      a.click();\n      div.remove();\n    }\n  ",
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/javascript": "download(\"download_ee47da21-a56a-4395-acd5-a6b99006eb28\", \"bert_mlm_best.keras\", 94188974)",
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "bert_masked_model.save(\"bert_mlm_friends_final.keras\")\n",
        "from google.colab import files\n",
        "files.download(\"bert_mlm_friends_final.keras\")\n",
        "files.download(\"checkpoints_friends/bert_mlm_best.keras\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EdkbudLxiRg4"
      },
      "source": [
        "#### Fine-tune - completar frases ao estilo Friends"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jmhoP_sYglQv"
      },
      "outputs": [],
      "source": [
        "from tensorflow import keras\n",
        "\n",
        "# Carrega o modelo salvo com MLM\n",
        "mlm_model = keras.models.load_model(\n",
        "    \"bert_mlm_friends_final.keras\",\n",
        "    custom_objects={\"MaskedLanguageModel\": MaskedLanguageModel}\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AXFNxbSGiwy0"
      },
      "outputs": [],
      "source": [
        "#Extrair apenas o encoder\n",
        "pretrained_bert_model = keras.Model(\n",
        "    mlm_model.input,\n",
        "    mlm_model.get_layer(\"encoder_0_ffn_layernormalization\").output\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BxvUp0BKjJ9u"
      },
      "outputs": [],
      "source": [
        "#Congelar o encoder\n",
        "pretrained_bert_model.trainable = False"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oQc9Kl5NjGC4",
        "outputId": "688f3d9c-82ce-480a-ddfa-a6aca0c4172c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 18/20\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step\n",
            "{'input_text': 'going ii iim communicating',\n",
            " 'predicted mask token': np.str_('ursula'),\n",
            " 'prediction': 'going ii iim ursula',\n",
            " 'probability': np.float32(0.30931404)}\n",
            "{'input_text': 'going ii iim communicating',\n",
            " 'predicted mask token': np.str_('this'),\n",
            " 'prediction': 'going ii iim this',\n",
            " 'probability': np.float32(0.20557728)}\n",
            "{'input_text': 'going ii iim communicating',\n",
            " 'predicted mask token': np.str_('isnt'),\n",
            " 'prediction': 'going ii iim isnt',\n",
            " 'probability': np.float32(0.09847512)}\n",
            "{'input_text': 'going ii iim communicating',\n",
            " 'predicted mask token': np.str_('is'),\n",
            " 'prediction': 'going ii iim is',\n",
            " 'probability': np.float32(0.034164406)}\n",
            "{'input_text': 'going ii iim communicating',\n",
            " 'predicted mask token': np.str_('grab'),\n",
            " 'prediction': 'going ii iim grab',\n",
            " 'probability': np.float32(0.033887226)}\n",
            "\n",
            "Epoch 18: loss improved from 0.88186 to 0.76170, saving model to checkpoints_friends/bert_mlm_best.keras\n",
            "\u001b[1m1495/1495\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 13ms/step - loss: 0.8430\n",
            "Epoch 19/20\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step\n",
            "{'input_text': 'going ii iim communicating',\n",
            " 'predicted mask token': np.str_('this'),\n",
            " 'prediction': 'going ii iim this',\n",
            " 'probability': np.float32(0.28697893)}\n",
            "{'input_text': 'going ii iim communicating',\n",
            " 'predicted mask token': np.str_('ursula'),\n",
            " 'prediction': 'going ii iim ursula',\n",
            " 'probability': np.float32(0.25313005)}\n",
            "{'input_text': 'going ii iim communicating',\n",
            " 'predicted mask token': np.str_('isnt'),\n",
            " 'prediction': 'going ii iim isnt',\n",
            " 'probability': np.float32(0.13370131)}\n",
            "{'input_text': 'going ii iim communicating',\n",
            " 'predicted mask token': np.str_('pretty'),\n",
            " 'prediction': 'going ii iim pretty',\n",
            " 'probability': np.float32(0.037180446)}\n",
            "{'input_text': 'going ii iim communicating',\n",
            " 'predicted mask token': np.str_('boxes'),\n",
            " 'prediction': 'going ii iim boxes',\n",
            " 'probability': np.float32(0.028601186)}\n",
            "\n",
            "Epoch 19: loss improved from 0.76170 to 0.65616, saving model to checkpoints_friends/bert_mlm_best.keras\n",
            "\u001b[1m1495/1495\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 10ms/step - loss: 0.7091\n",
            "Epoch 20/20\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step\n",
            "{'input_text': 'going ii iim communicating',\n",
            " 'predicted mask token': np.str_('isnt'),\n",
            " 'prediction': 'going ii iim isnt',\n",
            " 'probability': np.float32(0.3770971)}\n",
            "{'input_text': 'going ii iim communicating',\n",
            " 'predicted mask token': np.str_('this'),\n",
            " 'prediction': 'going ii iim this',\n",
            " 'probability': np.float32(0.29066142)}\n",
            "{'input_text': 'going ii iim communicating',\n",
            " 'predicted mask token': np.str_('boxes'),\n",
            " 'prediction': 'going ii iim boxes',\n",
            " 'probability': np.float32(0.12866093)}\n",
            "{'input_text': 'going ii iim communicating',\n",
            " 'predicted mask token': np.str_('ursula'),\n",
            " 'prediction': 'going ii iim ursula',\n",
            " 'probability': np.float32(0.029918713)}\n",
            "{'input_text': 'going ii iim communicating',\n",
            " 'predicted mask token': np.str_('herself'),\n",
            " 'prediction': 'going ii iim herself',\n",
            " 'probability': np.float32(0.019728236)}\n",
            "\n",
            "Epoch 20: loss improved from 0.65616 to 0.62559, saving model to checkpoints_friends/bert_mlm_best.keras\n",
            "\u001b[1m1495/1495\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 10ms/step - loss: 0.6731\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x7991083686d0>"
            ]
          },
          "execution_count": 85,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#Refinar o treinamento\n",
        "mlm_model.fit(\n",
        "    mlm_ds,\n",
        "    epochs=20,               # ex: vamos até a época 20\n",
        "    initial_epoch=17,        # porque você já treinou até a 17\n",
        "    callbacks=[generator_callback, checkpoint_cb]\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "aoVaiQiamC9Z",
        "outputId": "b7d1c297-9101-4ac6-bb8f-b07450d73dbe"
      },
      "outputs": [
        {
          "data": {
            "application/javascript": "\n    async function download(id, filename, size) {\n      if (!google.colab.kernel.accessAllowed) {\n        return;\n      }\n      const div = document.createElement('div');\n      const label = document.createElement('label');\n      label.textContent = `Downloading \"${filename}\": `;\n      div.appendChild(label);\n      const progress = document.createElement('progress');\n      progress.max = size;\n      div.appendChild(progress);\n      document.body.appendChild(div);\n\n      const buffers = [];\n      let downloaded = 0;\n\n      const channel = await google.colab.kernel.comms.open(id);\n      // Send a message to notify the kernel that we're ready.\n      channel.send({})\n\n      for await (const message of channel.messages) {\n        // Send a message to notify the kernel that we're ready.\n        channel.send({})\n        if (message.buffers) {\n          for (const buffer of message.buffers) {\n            buffers.push(buffer);\n            downloaded += buffer.byteLength;\n            progress.value = downloaded;\n          }\n        }\n      }\n      const blob = new Blob(buffers, {type: 'application/binary'});\n      const a = document.createElement('a');\n      a.href = window.URL.createObjectURL(blob);\n      a.download = filename;\n      div.appendChild(a);\n      a.click();\n      div.remove();\n    }\n  ",
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/javascript": "download(\"download_d544c119-4f68-418c-8939-cb208301cfb9\", \"bert_mlm_friends_final.keras\", 94188974)",
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/javascript": "\n    async function download(id, filename, size) {\n      if (!google.colab.kernel.accessAllowed) {\n        return;\n      }\n      const div = document.createElement('div');\n      const label = document.createElement('label');\n      label.textContent = `Downloading \"${filename}\": `;\n      div.appendChild(label);\n      const progress = document.createElement('progress');\n      progress.max = size;\n      div.appendChild(progress);\n      document.body.appendChild(div);\n\n      const buffers = [];\n      let downloaded = 0;\n\n      const channel = await google.colab.kernel.comms.open(id);\n      // Send a message to notify the kernel that we're ready.\n      channel.send({})\n\n      for await (const message of channel.messages) {\n        // Send a message to notify the kernel that we're ready.\n        channel.send({})\n        if (message.buffers) {\n          for (const buffer of message.buffers) {\n            buffers.push(buffer);\n            downloaded += buffer.byteLength;\n            progress.value = downloaded;\n          }\n        }\n      }\n      const blob = new Blob(buffers, {type: 'application/binary'});\n      const a = document.createElement('a');\n      a.href = window.URL.createObjectURL(blob);\n      a.download = filename;\n      div.appendChild(a);\n      a.click();\n      div.remove();\n    }\n  ",
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/javascript": "download(\"download_4f4e8c60-588c-4eb5-9780-1fd16c97ad60\", \"bert_mlm_best.keras\", 94188614)",
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "bert_masked_model.save(\"bert_mlm_friends_final.keras\")\n",
        "from google.colab import files\n",
        "files.download(\"bert_mlm_friends_final.keras\")\n",
        "files.download(\"checkpoints_friends/bert_mlm_best.keras\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OlETeTzmlJXY"
      },
      "source": [
        "### 7 Avaliação do Modelo e Realização de Testes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KH0_lUYKkSO6"
      },
      "outputs": [],
      "source": [
        "#testar várias frases com [MASK] e ver o modelo treinado completa cada uma\n",
        "\n",
        "def completar_frases_friends(frases_com_mask, top_k=5):\n",
        "    for frase in frases_com_mask:\n",
        "        print(f\"\\nInput: {frase}\")\n",
        "\n",
        "        sample_tokens = vectorize_layer([frase]).numpy()\n",
        "        prediction = mlm_model.predict(sample_tokens)\n",
        "\n",
        "        masked_index = np.where(sample_tokens == mask_token_id)[1]\n",
        "        mask_prediction = prediction[0][masked_index]\n",
        "\n",
        "        #Top-K predições\n",
        "        top_indices = mask_prediction[0].argsort()[-top_k:][::-1]\n",
        "        for i in range(top_k):\n",
        "            predicted_token_id = top_indices[i]\n",
        "            probability = mask_prediction[0][predicted_token_id]\n",
        "\n",
        "            completado = np.copy(sample_tokens[0])\n",
        "            completado[masked_index[0]] = predicted_token_id\n",
        "            frase_completada = \" \".join([id2token[t] for t in completado if t != 0])\n",
        "\n",
        "            print(f\"  {i+1}. {frase_completada}  (prob: {probability:.4f})\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7NQxVLqtl_eJ",
        "outputId": "668d9a71-85a0-458f-dfa4-7d7a03302635"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Input: Joey doesn't share [mask]!\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step\n",
            "  1. going ii iim isnt  (prob: 0.3771)\n",
            "  2. going ii iim this  (prob: 0.2907)\n",
            "  3. going ii iim boxes  (prob: 0.1287)\n",
            "  4. going ii iim ursula  (prob: 0.0299)\n",
            "  5. going ii iim herself  (prob: 0.0197)\n",
            "\n",
            "Input: How you [mask]?\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step\n",
            "  1. think i between  (prob: 0.0835)\n",
            "  2. think i your  (prob: 0.0660)\n",
            "  3. think i gonna  (prob: 0.0607)\n",
            "  4. think i no  (prob: 0.0605)\n",
            "  5. think i check  (prob: 0.0535)\n",
            "\n",
            "Input: Could I *be* wearing any more [mask]?\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step\n",
            "  1. hi [MASK] dont must has believe wanted  (prob: 0.8053)\n",
            "  2. hi [MASK] dont must has believe he  (prob: 0.0578)\n",
            "  3. hi [MASK] dont must has believe [sees  (prob: 0.0508)\n",
            "  4. hi [MASK] dont must has believe ten  (prob: 0.0155)\n",
            "  5. hi [MASK] dont must has believe then  (prob: 0.0155)\n",
            "\n",
            "Input: Welcome to the real [mask]!\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step\n",
            "  1. forever the you year maid  (prob: 0.9891)\n",
            "  2. forever the you year walking  (prob: 0.0068)\n",
            "  3. forever the you year keep  (prob: 0.0024)\n",
            "  4. forever the you year hundred  (prob: 0.0003)\n",
            "  5. forever the you year then  (prob: 0.0003)\n",
            "\n",
            "Input: I got off the [mask]!\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step\n",
            "  1. [MASK] mean man you save  (prob: 0.7655)\n",
            "  2. [MASK] mean man you neither  (prob: 0.0809)\n",
            "  3. [MASK] mean man you porn  (prob: 0.0355)\n",
            "  4. [MASK] mean man you years  (prob: 0.0250)\n",
            "  5. [MASK] mean man you help  (prob: 0.0187)\n",
            "\n",
            "Input: Smelly [mask], smelly [mask], what are they feeding you?\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step\n",
            "  1. inside suggestion inside communicating and we good fifty i  (prob: 0.4357)\n",
            "  2. inside cant inside communicating and we good fifty i  (prob: 0.3389)\n",
            "  3. inside umm inside communicating and we good fifty i  (prob: 0.0952)\n",
            "  4. inside naked inside communicating and we good fifty i  (prob: 0.0312)\n",
            "  5. inside together inside communicating and we good fifty i  (prob: 0.0244)\n"
          ]
        }
      ],
      "source": [
        "frases = [\n",
        "    \"Joey doesn't share [mask]!\",\n",
        "    \"How you [mask]?\",\n",
        "    \"Could I *be* wearing any more [mask]?\",\n",
        "    \"Welcome to the real [mask]!\",\n",
        "    \"I got off the [mask]!\",\n",
        "    \"Smelly [mask], smelly [mask], what are they feeding you?\"\n",
        "]\n",
        "\n",
        "completar_frases_friends(frases)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yzy6Zhe9oVCr"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RdmJbXtLyDq5"
      },
      "source": [
        "## 🌦️ Implementação do Modelo Oculto de Markov"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LqnEXVSx27gm"
      },
      "source": [
        "### Dependências"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dwKTdmjhydEc"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import re\n",
        "from collections import defaultdict, Counter\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Uzj3Ios427gm"
      },
      "source": [
        "### Carregamento da Base de Dados"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 252
        },
        "id": "4tioJHILywYZ",
        "outputId": "ce27aa4f-90b6-4912-e63a-1f0cf5dacf12"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-938b2308-e1b5-4f7d-bd49-ba44fcbd70e7\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-938b2308-e1b5-4f7d-bd49-ba44fcbd70e7\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saving falas_chandler.txt to falas_chandler.txt\n",
            "Saving falas_joey.txt to falas_joey.txt\n",
            "Saving falas_monica.txt to falas_monica.txt\n",
            "Saving falas_phoebe.txt to falas_phoebe.txt\n",
            "Saving falas_rachel.txt to falas_rachel.txt\n",
            "Saving falas_ross.txt to falas_ross.txt\n"
          ]
        }
      ],
      "source": [
        "#Upload dos arquivos\n",
        "from google.colab import files\n",
        "uploaded = files.upload()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FWOUgb5b27gm"
      },
      "source": [
        "### Limpeza dos Dados\n",
        "Nesta estapa realizamos para cada fala carregada de todos os personagens:\n",
        "* Remoção de texto entre colchetes, parenteses;\n",
        "* Remoção de todos os caracteres, exceto letras, números, espaços e apóstrofos, garantindo que apenas texto limpo e legível permaneça;\n",
        "* Subtituição de várias espaços em branco por apenas um único espaço em branco;\n",
        "* Remoção de espaços iniciais/finais;\n",
        "* Converção do texto para minúsculas."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SkBnbhWIyyWd"
      },
      "outputs": [],
      "source": [
        "#Ler e limpar os dados\n",
        "arquivos = [\n",
        "    \"falas_joey.txt\", \"falas_chandler.txt\", \"falas_rachel.txt\",\n",
        "    \"falas_monica.txt\", \"falas_phoebe.txt\", \"falas_ross.txt\"\n",
        "]\n",
        "\n",
        "def limpar_fala(fala):\n",
        "    fala = re.sub(r'\\[.*?\\]', '', fala)\n",
        "    fala = re.sub(r'\\(.*?\\)', '', fala)\n",
        "    fala = re.sub(r\"[^\\w\\s']\", '', fala)\n",
        "    fala = re.sub(r'\\s+', ' ', fala)\n",
        "    return fala.strip().lower()\n",
        "\n",
        "falas = []\n",
        "for arquivo in arquivos:\n",
        "    with open(arquivo, \"r\", encoding=\"utf-8\") as f:\n",
        "        for linha in f:\n",
        "            limpa = limpar_fala(linha)\n",
        "            if len(limpa.split()) >= 4:\n",
        "                falas.append(limpa)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZhayeCcI27gn"
      },
      "source": [
        "### Construção do Triagramas\n",
        "\n",
        "Realizamos a definição de um n-grams de 3 elementos para encontrar um padrõa linguíticos nas falas (ou seja, nosso _corpus_). Desta forma, definimos como podemos encontrar a próxima sequência dada uma sequência de 2 palavras (probabilidade condicional).\n",
        "\n",
        "Então, definimos a frequência para cada par de palavras (chave) contamos quantas vezes cada palavra apareceu depois (utilizando Counter).\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AVtWS9Dty8hF"
      },
      "outputs": [],
      "source": [
        "#Construir os trigramas\n",
        "from collections import defaultdict, Counter\n",
        "\n",
        "trigramas = defaultdict(list)\n",
        "for frase in falas:\n",
        "    tokens = frase.split()\n",
        "    for i in range(len(tokens) - 2):\n",
        "        chave = (tokens[i], tokens[i+1])\n",
        "        prox = tokens[i+2]\n",
        "        trigramas[chave].append(prox)\n",
        "\n",
        "# Frequências\n",
        "modelo_markov = {chave: Counter(palavras) for chave, palavras in trigramas.items()}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4zqAJhPJ27gn"
      },
      "source": [
        "### Modelagem do Modelo Oculto de Markov com Máscara\n",
        "\n",
        "Na última etapa criamos o método para completar as frases, onde dada uma frase com uma lacuna (representado por ` ____ `), o algoritmo tenta preencher com a palavra mais provável (novamente, baseando-se nas duas palavras anteriores à lacuna)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r-Mhcc3jzAnl"
      },
      "outputs": [],
      "source": [
        "#Função para completar frases\n",
        "\n",
        "def completar_frase_markov(frase, placeholder=\"___\"):\n",
        "    frase = frase.replace(\"'___'\", \"___\").replace('\"___\"', \"___\")  # normaliza\n",
        "    tokens = frase.lower().split()\n",
        "\n",
        "    if \"___\" not in tokens:\n",
        "        return \"A frase precisa conter '___'\"\n",
        "\n",
        "    idx = tokens.index(\"___\")\n",
        "    if idx < 2:\n",
        "        return \"São necessárias 2 palavras antes da lacuna.\"\n",
        "\n",
        "    contexto = (tokens[idx - 2], tokens[idx - 1])\n",
        "    if contexto not in modelo_markov:\n",
        "        return \"Contexto não encontrado no modelo.\"\n",
        "\n",
        "    palavra = modelo_markov[contexto].most_common(1)[0][0]\n",
        "    tokens[idx] = palavra\n",
        "    return \" \".join(tokens)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-y6_RK4C27gn"
      },
      "source": [
        "### Testando a previsibilidade do modelo\n",
        "\n",
        "Agora podemos testar com um conjunto de frases e que podem ser completadas."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GsCLtTwdzDMV",
        "outputId": "e6b165cb-e3c7-4788-d579-5d09f27badd1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Frase original: Joey doesn't share ___ !\n",
            "Frase completada: joey doesn't share food !\n",
            "\n",
            "Frase original: How you ___ ?\n",
            "Frase completada: how you doin ?\n",
            "\n",
            "Frase original: I got off the ___ !\n",
            "Frase completada: i got off the plane !\n",
            "\n",
            "Frase original: Could I be wearing any more ___ ?\n",
            "Frase completada: could i be wearing any more clothes ?\n"
          ]
        }
      ],
      "source": [
        "#Testando o modelo\n",
        "frases_teste = [\n",
        "    \"Joey doesn't share ___ !\",\n",
        "    \"How you ___ ?\",\n",
        "    \"I got off the ___ !\",\n",
        "    \"Could I be wearing any more ___ ?\"\n",
        "]\n",
        "\n",
        "for frase in frases_teste:\n",
        "    print(f\"\\nFrase original: {frase}\")\n",
        "    print(\"Frase completada:\", completar_frase_markov(frase))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FXmXP0RLzH_J"
      },
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L5YC6JvvzNo4"
      },
      "source": [
        "# **Comparação e análise dos resultados**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hxNQg34527gp"
      },
      "source": [
        "A implementação de ambos os modelos (BERT e HMM) mostram-se um desafio por algumas questões: tratar corretamente a base de dados para treiná-los corretamente (ou da melhor forma possível) para atingir o objetivo, mesmo que haja uma boa quantidade de dados para cada um dos 6 personagens principais da série; e pelo própria instigação de se implementar esses modelos.\n",
        "\n",
        "Trantando da implementação do modelo de BERT, realizamos duas implementações sendo a primeira com muitos problemas e a segunda como uma tentativa de realizar melhorias. Focando na primeira implementação, houve muito esforço no tratamento dos dados e na etapa de treinamento, pois os resultados obtidos após o treinamento não foram satisfatórios. A solução foi adicionar pesos, mas que mesmo assim gerou um overffiting. Numa outra tentativa (nesta mesma primeira implementação), foram feitos outros ajustes para obtermos um oversampling.\n",
        "\n",
        "No fim das contas, optamos por realizar uma segunda implementação do modelo de BERT ainda que com resultados não muito bons.\n",
        "\n",
        "Por outro lado, na implementação do Modelo Oculto de Markov, utilizamos uma abordagem mais simples porque simula apenas o componente de emissão de um HMM sem modelar explicitamente os estados ocultos.\n",
        "\n",
        "Em vez de usar bibliotecas como hmmlearn, que exigem a definição e o treinamento de uma estrutura completa com estados e probabilidades, ela utiliza trigramas para prever observações diretamente com base no contexto anterior. Foi uma abordagem mais leve devido a carga que tivemos na implementação do modelo de BERT.\n",
        "\n",
        "E ainda, com a simplicidade, conseguimos atingir o objetivo de completar as frases e ver que elas tem bastante sentido e que condizem com os diálogos dos roteiros originais da série.\n",
        "\n",
        "Concluímos que podemos meelhorar a modelagem do modelo BERT com a adição de mais planejamento e melhor tratamento da base de dados.  "
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Carregar modelo e classificador para apresentação"
      ],
      "metadata": {
        "id": "3ZRjqYuX3qQc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## BERT"
      ],
      "metadata": {
        "id": "8r7_jqPd3xFc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "files.download(\"bert_mlm_friends_final.keras\")\n",
        "files.download(\"vectorize_layer_model.keras\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "oYP9noD_3o7w",
        "outputId": "57a3115b-367a-4880-842b-016b3a76bf2d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_e60a2f7e-08e7-40e2-bed6-d9ae78f96320\", \"bert_mlm_friends_final.keras\", 94188974)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_9a25921b-e37c-40e3-a970-708a79adfd28\", \"vectorize_layer_model.keras\", 276669)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "frases = [\n",
        "    \"Joey doesnt share [mask]!\",\n",
        "    \"How you [mask]?\",\n",
        "    \"Could I *be* wearing any more [mask]?\",\n",
        "    \"Welcome to the real [mask]!\",\n",
        "    \"I got off the [mask]\"\n",
        "]"
      ],
      "metadata": {
        "id": "hBKOpbHF4N9P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Hiperparâmetros\n",
        "EMBED_DIM = 128\n",
        "NUM_HEAD = 4\n",
        "FF_DIM = 256\n",
        "NUM_LAYERS = 4\n",
        "VOCAB_SIZE = 30000\n",
        "MAX_LEN = 128\n",
        "LR = 1e-4\n",
        "\n",
        "\n",
        "#criação da vectorize_layer\n",
        "def get_vectorize_layer(texts, vocab_size=30000, max_seq_length=128, special_tokens=[\"[MASK]\"]):\n",
        "    vectorize_layer = TextVectorization(\n",
        "        max_tokens=vocab_size,\n",
        "        output_mode=\"int\",\n",
        "        standardize=custom_standardization,\n",
        "        output_sequence_length=max_seq_length,\n",
        "    )\n",
        "    vectorize_layer.adapt(texts)\n",
        "\n",
        "    # Ajuste do vocabulário\n",
        "    vocab = vectorize_layer.get_vocabulary()\n",
        "    vocab = [tok for tok in vocab if tok not in [\"\", \"[UNK]\"] + special_tokens]\n",
        "    vocab = vocab[:vocab_size - len(special_tokens) - 2]\n",
        "    vocab_final = [\"\", \"[UNK]\"] + special_tokens + vocab\n",
        "    vectorize_layer.set_vocabulary(vocab_final)\n",
        "\n",
        "    # Envolve em um modelo Keras e salva\n",
        "    vectorize_model = keras.Sequential([vectorize_layer])\n",
        "    vectorize_model(tf.constant([\"exemplo de frase\"]))  # força a construção\n",
        "\n",
        "    path = \"vectorize_layer_model.keras\"\n",
        "    vectorize_model.save(path)\n",
        "    #files.download(path)\n",
        "\n",
        "    return vectorize_layer\n",
        "\n",
        "#instanciar vectorize_layer\n",
        "vectorize_layer = get_vectorize_layer(\n",
        "    all_data.line.values.tolist(),\n",
        "    config.VOCAB_SIZE,\n",
        "    config.MAX_LEN,\n",
        "    special_tokens=[\"[mask]\"]\n",
        ")\n",
        "\n",
        "#testar várias frases com [MASK] e ver o modelo treinado completa cada uma\n",
        "def completar_frases_friends(frases_com_mask, top_k=5):\n",
        "    for frase in frases_com_mask:\n",
        "        print(f\"\\nInput: {frase}\")\n",
        "\n",
        "        sample_tokens = vectorize_layer([frase]).numpy()\n",
        "        prediction = mlm_model.predict(sample_tokens)\n",
        "\n",
        "        masked_index = np.where(sample_tokens == mask_token_id)[1]\n",
        "        mask_prediction = prediction[0][masked_index]\n",
        "\n",
        "        #Top-K predições\n",
        "        top_indices = mask_prediction[0].argsort()[-top_k:][::-1]\n",
        "        for i in range(top_k):\n",
        "            predicted_token_id = top_indices[i]\n",
        "            probability = mask_prediction[0][predicted_token_id]\n",
        "\n",
        "            completado = np.copy(sample_tokens[0])\n",
        "            completado[masked_index[0]] = predicted_token_id\n",
        "            frase_completada = \" \".join([id2token[t] for t in completado if t != 0])\n",
        "\n",
        "            print(f\"  {i+1}. {frase_completada}  (prob: {probability:.4f})\")\n",
        "\n",
        "completar_frases_friends(frases)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 390
        },
        "id": "ExNXmF5m4XgW",
        "outputId": "58c635ab-f094-474d-c482-56615642d64c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "Invalid dtype: object",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-20-c0435f41bb79>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[0;31m#instanciar vectorize_layer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m vectorize_layer = get_vectorize_layer(\n\u001b[0m\u001b[1;32m     40\u001b[0m     \u001b[0mall_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m     \u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mVOCAB_SIZE\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-20-c0435f41bb79>\u001b[0m in \u001b[0;36mget_vectorize_layer\u001b[0;34m(texts, vocab_size, max_seq_length, special_tokens)\u001b[0m\n\u001b[1;32m     28\u001b[0m     \u001b[0;31m# Envolve em um modelo Keras e salva\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m     \u001b[0mvectorize_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSequential\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mvectorize_layer\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m     \u001b[0mvectorize_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconstant\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"exemplo de frase\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# força a construção\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m     \u001b[0mpath\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"vectorize_layer_model.keras\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    120\u001b[0m             \u001b[0;31m# To get the full stack trace, call:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m             \u001b[0;31m# `keras.config.disable_traceback_filtering()`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 122\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    123\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m             \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/optree/ops.py\u001b[0m in \u001b[0;36mtree_map\u001b[0;34m(func, tree, is_leaf, none_is_leaf, namespace, *rests)\u001b[0m\n\u001b[1;32m    764\u001b[0m     \u001b[0mleaves\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtreespec\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtree\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_leaf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnone_is_leaf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnamespace\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    765\u001b[0m     \u001b[0mflat_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mleaves\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mtreespec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten_up_to\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mr\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrests\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 766\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtreespec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mflat_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    767\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    768\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Invalid dtype: object"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Markov"
      ],
      "metadata": {
        "id": "F3M4C-D33z1T"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "GAB4Qx8M33QG"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "A100",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}